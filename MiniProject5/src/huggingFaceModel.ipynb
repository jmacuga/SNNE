{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from torchmetrics.classification import MulticlassAccuracy\n",
    "from sklearn.metrics import f1_score, confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_recall_fscore_support\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/SSNE-Pawel/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at j-hartmann/emotion-english-distilroberta-base and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([7, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([7]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
    "from transformers import BertForSequenceClassification\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"j-hartmann/emotion-english-distilroberta-base\")\n",
    "config = AutoConfig.from_pretrained(\"j-hartmann/emotion-english-distilroberta-base\", \n",
    "                                    num_labels=5, \n",
    "                                    hidden_dropout_prob=0.1,\n",
    "                                    attention_probs_dropout_prob=0.1, return_dict=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"j-hartmann/emotion-english-distilroberta-base\", \n",
    "                                                           config=config,\n",
    "                                                           ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text  label\n",
      "0      location not palace excellent hotel booke dthe...      4\n",
      "1      respite definitely not place stay looking ultr...      3\n",
      "2      stunning truly memorable spot right beach nusa...      4\n",
      "3      solid business hotel near embassy stayed hotel...      3\n",
      "4      nice place make sure lock money warning money ...      3\n",
      "...                                                  ...    ...\n",
      "16387  great base explore new york stayed 4 nights en...      4\n",
      "16388  wonderful advert paris wonderful introduction ...      4\n",
      "16389  ideal relaxing holdiay rachel jay green liverp...      3\n",
      "16390  watch food, husband went resort 4 nights chris...      2\n",
      "16391  fantastic hotel central barcelona family just ...      4\n",
      "\n",
      "[16392 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/train_data.csv\")\n",
    "data[\"label\"] = data[\"rating\"]\n",
    "data.rename(columns={\"review\":\"text\"}, inplace=True)\n",
    "data.drop('rating', axis=1, inplace=True)\n",
    "train_data, val_data = train_test_split(data, test_size=0.1, random_state=42)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"../data/test_data.csv\")\n",
    "test_data.rename(columns={\"review\":\"text\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_data)\n",
    "val_df = pd.DataFrame(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mca_eval = MulticlassAccuracy(num_classes=5, average=None)\n",
    "mca_average = MulticlassAccuracy(num_classes=5, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loader(encodings, labels):\n",
    "    dataset = TensorDataset(encodings[\"input_ids\"], encodings[\"attention_mask\"], torch.tensor(labels.values))\n",
    "    loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-5)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, reviews, targets, tokenizer):\n",
    "        self.reviews = reviews\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.reviews)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        review = str(self.reviews[idx])\n",
    "        target = self.targets[idx]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            review,\n",
    "            add_special_tokens=True,\n",
    "            # max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'text': review,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(target, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewDatasetTest(Dataset):\n",
    "    def __init__(self, reviews, tokenizer):\n",
    "        self.reviews = reviews\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.reviews)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        review = str(self.reviews[idx])\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            review,\n",
    "            add_special_tokens=True,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'text': review,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ReviewDataset(\n",
    "    reviews=train_data['text'].to_numpy(),\n",
    "    targets=train_data['label'].to_numpy(),\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "test_dataset = ReviewDataset(\n",
    "    reviews=val_data['text'].to_numpy(),\n",
    "    targets=val_data['label'].to_numpy(),\n",
    "    tokenizer=tokenizer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_dataset = ReviewDatasetTest(\n",
    "    reviews=val_data['text'].to_numpy(),\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/SSNE-Pawel/.venv/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "output_dir = f\"results_{now}\"\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"../models/{output_dir}\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    save_strategy=\"epoch\",\n",
    "    \n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss(weight=torch.tensor([0.5, 0.4, 1.2, 0.5, 0.3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    def __init__(self, loss_fn=loss_function, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.loss_fn = loss_fn\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        loss = self.loss_fn(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tradycyjne podejście bez walidacji krzyzowej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 384.00 MiB. GPU 0 has a total capacity of 23.65 GiB of which 91.69 MiB is free. Process 1250512 has 15.51 GiB memory in use. Process 1543490 has 8.01 GiB memory in use. Of the allocated memory 7.50 GiB is allocated by PyTorch, and 61.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/transformers/trainer.py:1885\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1883\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1884\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1885\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/transformers/trainer.py:2216\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2213\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2215\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2216\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2219\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2220\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2221\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2222\u001b[0m ):\n\u001b[1;32m   2223\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2224\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/transformers/trainer.py:3238\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3237\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3238\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3240\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3241\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/transformers/trainer.py:3264\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3262\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3263\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 3264\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3265\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3266\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:1195\u001b[0m, in \u001b[0;36mRobertaForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1193\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1195\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1206\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1207\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:832\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    823\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    825\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m    826\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    827\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    830\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    831\u001b[0m )\n\u001b[0;32m--> 832\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    844\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    845\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:521\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    510\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    511\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    512\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    518\u001b[0m         output_attentions,\n\u001b[1;32m    519\u001b[0m     )\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 521\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:410\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    399\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    400\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    407\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    408\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    409\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 410\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    419\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:337\u001b[0m, in \u001b[0;36mRobertaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    329\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    335\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    336\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m--> 337\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[1;32m    347\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:250\u001b[0m, in \u001b[0;36mRobertaSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    247\u001b[0m         relative_position_scores_key \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbhrd,lrd->bhlr\u001b[39m\u001b[38;5;124m\"\u001b[39m, key_layer, positional_embedding)\n\u001b[1;32m    248\u001b[0m         attention_scores \u001b[38;5;241m=\u001b[39m attention_scores \u001b[38;5;241m+\u001b[39m relative_position_scores_query \u001b[38;5;241m+\u001b[39m relative_position_scores_key\n\u001b[0;32m--> 250\u001b[0m attention_scores \u001b[38;5;241m=\u001b[39m \u001b[43mattention_scores\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention_head_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;66;03m# Apply the attention mask is (precomputed for all layers in RobertaModel forward() function)\u001b[39;00m\n\u001b[1;32m    253\u001b[0m     attention_scores \u001b[38;5;241m=\u001b[39m attention_scores \u001b[38;5;241m+\u001b[39m attention_mask\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 384.00 MiB. GPU 0 has a total capacity of 23.65 GiB of which 91.69 MiB is free. Process 1250512 has 15.51 GiB memory in use. Process 1543490 has 8.01 GiB memory in use. Of the allocated memory 7.50 GiB is allocated by PyTorch, and 61.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "../models/./results_2024-06-16_11-42-29 does not appear to have a file named config.json. Checkout 'https://huggingface.co/../models/./results_2024-06-16_11-42-29/tree/None' for available files.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_eval \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForSequenceClassification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../models/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43moutput_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m eval_trainer \u001b[38;5;241m=\u001b[39m Trainer(model\u001b[38;5;241m=\u001b[39mmodel)\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:523\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    521\u001b[0m     _ \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization_config\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 523\u001b[0m config, kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mAutoConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_unused_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcode_revision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode_revision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;66;03m# if torch_dtype=auto was passed here, ensure to pass it on\u001b[39;00m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs_orig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch_dtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:934\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    931\u001b[0m trust_remote_code \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrust_remote_code\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    932\u001b[0m code_revision \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_revision\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 934\u001b[0m config_dict, unused_kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mPretrainedConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    935\u001b[0m has_remote_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    936\u001b[0m has_local_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m CONFIG_MAPPING\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/transformers/configuration_utils.py:632\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m original_kwargs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(kwargs)\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[0;32m--> 632\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict:\n\u001b[1;32m    634\u001b[0m     original_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/transformers/configuration_utils.py:689\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    685\u001b[0m configuration_file \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_configuration_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, CONFIG_NAME) \u001b[38;5;28;01mif\u001b[39;00m gguf_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m gguf_file\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[0;32m--> 689\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfiguration_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    703\u001b[0m     commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;66;03m# Raise any environment error raise by `cached_file`. It will have a helpful error message adapted to\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;66;03m# the original exception.\u001b[39;00m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/transformers/utils/hub.py:370\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(resolved_file):\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _raise_exceptions_for_missing_entries:\n\u001b[0;32m--> 370\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    371\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not appear to have a file named \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Checkout \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    372\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/tree/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for available files.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    373\u001b[0m         )\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    375\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: ../models/./results_2024-06-16_11-42-29 does not appear to have a file named config.json. Checkout 'https://huggingface.co/../models/./results_2024-06-16_11-42-29/tree/None' for available files."
     ]
    }
   ],
   "source": [
    "# model_eval = AutoModelForSequenceClassification.from_pretrained(f\"../models/{output_dir}\")\n",
    "# eval_trainer = Trainer(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 23.65 GiB of which 41.69 MiB is free. Process 1250512 has 15.51 GiB memory in use. Process 1543490 has 8.05 GiB memory in use. Of the allocated memory 7.55 GiB is allocated by PyTorch, and 63.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m predictions_argmax \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(torch\u001b[38;5;241m.\u001b[39mtensor(predictions\u001b[38;5;241m.\u001b[39mpredictions), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/transformers/trainer.py:3648\u001b[0m, in \u001b[0;36mTrainer.predict\u001b[0;34m(self, test_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3645\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3647\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3648\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPrediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\n\u001b[1;32m   3650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3651\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3652\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/transformers/trainer.py:3757\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3754\u001b[0m         batch_size \u001b[38;5;241m=\u001b[39m observed_batch_size\n\u001b[1;32m   3756\u001b[0m \u001b[38;5;66;03m# Prediction step\u001b[39;00m\n\u001b[0;32m-> 3757\u001b[0m loss, logits, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3758\u001b[0m main_input_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain_input_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3759\u001b[0m inputs_decode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_input(inputs[main_input_name]) \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39minclude_inputs_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/transformers/trainer.py:3971\u001b[0m, in \u001b[0;36mTrainer.prediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[1;32m   3969\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_labels \u001b[38;5;129;01mor\u001b[39;00m loss_without_labels:\n\u001b[1;32m   3970\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3971\u001b[0m         loss, outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3972\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m   3974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/transformers/trainer.py:3264\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3262\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3263\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 3264\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3265\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3266\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:1195\u001b[0m, in \u001b[0;36mRobertaForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1193\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1195\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1206\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1207\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:825\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m    820\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m    823\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m--> 825\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    832\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[1;32m    833\u001b[0m     embedding_output,\n\u001b[1;32m    834\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mextended_attention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    842\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m    843\u001b[0m )\n\u001b[1;32m    844\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:116\u001b[0m, in \u001b[0;36mRobertaEmbeddings.forward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    115\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mword_embeddings(input_ids)\n\u001b[0;32m--> 116\u001b[0m token_type_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken_type_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m inputs_embeds \u001b[38;5;241m+\u001b[39m token_type_embeddings\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embedding_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabsolute\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/torch/nn/modules/sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/torch/nn/functional.py:2237\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2231\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2232\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2233\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2234\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2235\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2236\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 23.65 GiB of which 41.69 MiB is free. Process 1250512 has 15.51 GiB memory in use. Process 1543490 has 8.05 GiB memory in use. Of the allocated memory 7.55 GiB is allocated by PyTorch, and 63.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(test_dataset)\n",
    "predictions_argmax = torch.argmax(torch.tensor(predictions.predictions), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_matrix_train = confusion_matrix(test_dataset.targets , predictions_argmax)\n",
    "ConfusionMatrixDisplay(confusion_matrix_train).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7054, 0.4961, 0.4565, 0.5849, 0.8415])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mca_eval(predictions_argmax, torch.tensor(test_dataset.targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6872)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mca_average(predictions_argmax, torch.tensor(test_dataset.targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model ma tendencje do przetrenowywania, więc naturalnym krokiem będzie dobranie odpowiedniej strategi niwelującej przetrenowanie. W naszym przypadku zastosujemy skrośną walidacje."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wagi dobrane ze względu na ilości i accuracy dla kazdej z klas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/SSNE-Pawel/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at j-hartmann/emotion-english-distilroberta-base and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([7, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([7]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(\"j-hartmann/emotion-english-distilroberta-base\", \n",
    "                                    num_labels=5, \n",
    "                                    hidden_dropout_prob=0.1,\n",
    "                                    attention_probs_dropout_prob=0.1, return_dict=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"j-hartmann/emotion-english-distilroberta-base\", \n",
    "                                                           config=config,\n",
    "                                                           ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss(weight=torch.tensor([0.5, 0.7, 1.2, 0.5, 0.3]).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/SSNE-Pawel/.venv/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"../models/{output_dir}\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    save_strategy=\"epoch\",\n",
    "    \n",
    ")\n",
    "loss_modified_trainer = CustomTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        loss_fn = loss_function\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 768.00 MiB. GPU 0 has a total capacity of 23.65 GiB of which 149.69 MiB is free. Process 1156929 has 23.09 GiB memory in use. Process 1191891 has 386.00 MiB memory in use. Of the allocated memory 22.27 GiB is allocated by PyTorch, and 375.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[106], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mloss_modified_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/transformers/trainer.py:1885\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1883\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1884\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1885\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/transformers/trainer.py:2216\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2213\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2215\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2216\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2219\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2220\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2221\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2222\u001b[0m ):\n\u001b[1;32m   2223\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2224\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/transformers/trainer.py:3238\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3237\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3238\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3240\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3241\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "Cell \u001b[0;32mIn[89], line 7\u001b[0m, in \u001b[0;36mCustomTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_loss\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, inputs, return_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m      6\u001b[0m     labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits\n\u001b[1;32m      9\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn(logits, labels)\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:1195\u001b[0m, in \u001b[0;36mRobertaForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1193\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1195\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1206\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1207\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:832\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    823\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    825\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m    826\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    827\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    830\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    831\u001b[0m )\n\u001b[0;32m--> 832\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    844\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    845\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:521\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    510\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    511\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    512\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    518\u001b[0m         output_attentions,\n\u001b[1;32m    519\u001b[0m     )\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 521\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:410\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    399\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    400\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    407\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    408\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    409\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 410\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    419\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:337\u001b[0m, in \u001b[0;36mRobertaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    329\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    335\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    336\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m--> 337\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[1;32m    347\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:260\u001b[0m, in \u001b[0;36mRobertaSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    256\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(attention_scores, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# This is actually dropping out entire tokens to attend to, which might\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# seem a bit unusual, but is taken from the original Transformer paper.\u001b[39;00m\n\u001b[0;32m--> 260\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_probs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m# Mask heads if we want to\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/torch/nn/modules/dropout.py:59\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/torch/nn/functional.py:1268\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[1;32m   1267\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1268\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 768.00 MiB. GPU 0 has a total capacity of 23.65 GiB of which 149.69 MiB is free. Process 1156929 has 23.09 GiB memory in use. Process 1191891 has 386.00 MiB memory in use. Of the allocated memory 22.27 GiB is allocated by PyTorch, and 375.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mJądro Kernel uległo awarii podczas wykonywania kodu w bieżącej komórce lub w poprzedniej komórce. \n",
      "\u001b[1;31mPrzejrzyj kod w komórkach, aby zidentyfikować możliwą przyczynę awarii. \n",
      "\u001b[1;31mKliknij <a href='https://aka.ms/vscodeJupyterKernelCrash'>tutaj</a>, aby uzyskać więcej informacji. \n",
      "\u001b[1;31mAby uzyskać dalsze szczegóły, wyświetl <a href='command:jupyter.viewOutput'>dziennik</a> Jupyter."
     ]
    }
   ],
   "source": [
    "loss_modified_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 1/52 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = loss_modified_trainer.predict(test_dataset)\n",
    "predictions_argmax = torch.argmax(torch.tensor(predictions.predictions), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_matrix_train = confusion_matrix(test_dataset.targets , predictions_argmax)\n",
    "ConfusionMatrixDisplay(confusion_matrix_train).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6786, 0.5426, 0.6359, 0.5514, 0.7967])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mca_eval(predictions_argmax, torch.tensor(test_dataset.targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6793)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mca_average(predictions_argmax, torch.tensor(test_dataset.targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rozkład według ilości klas w zbiorze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/SSNE-Pawel/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at j-hartmann/emotion-english-distilroberta-base and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([7, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([7]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(\"j-hartmann/emotion-english-distilroberta-base\", \n",
    "                                    num_labels=5, \n",
    "                                    hidden_dropout_prob=0.1,\n",
    "                                    attention_probs_dropout_prob=0.1, return_dict=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"j-hartmann/emotion-english-distilroberta-base\", \n",
    "                                                           config=config,\n",
    "                                                           ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_classes = np.unique(data[\"label\"].values)\n",
    "y = data[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight(class_weight='balanced', classes = unique_classes, y = y)\n",
    "class_weights = torch.tensor(class_weights).to(device)\n",
    "loss_function = torch.nn.CrossEntropyLoss(weight=class_weights.to(torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/SSNE-Pawel/.venv/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"../models/{output_dir}\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=15,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    save_strategy=\"epoch\",\n",
    "    \n",
    ")\n",
    "loss_distribution_trainer = CustomTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        loss_fn = loss_function\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6915' max='6915' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6915/6915 26:00, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.890077</td>\n",
       "      <td>0.638415</td>\n",
       "      <td>0.581348</td>\n",
       "      <td>0.568395</td>\n",
       "      <td>0.607017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.005500</td>\n",
       "      <td>0.882662</td>\n",
       "      <td>0.639024</td>\n",
       "      <td>0.594527</td>\n",
       "      <td>0.582708</td>\n",
       "      <td>0.609481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.806700</td>\n",
       "      <td>0.879234</td>\n",
       "      <td>0.650610</td>\n",
       "      <td>0.612691</td>\n",
       "      <td>0.607091</td>\n",
       "      <td>0.626942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.704900</td>\n",
       "      <td>0.970423</td>\n",
       "      <td>0.664024</td>\n",
       "      <td>0.629566</td>\n",
       "      <td>0.632732</td>\n",
       "      <td>0.637850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.607400</td>\n",
       "      <td>1.019514</td>\n",
       "      <td>0.657317</td>\n",
       "      <td>0.609843</td>\n",
       "      <td>0.595953</td>\n",
       "      <td>0.629184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.512000</td>\n",
       "      <td>1.135569</td>\n",
       "      <td>0.671341</td>\n",
       "      <td>0.633066</td>\n",
       "      <td>0.640428</td>\n",
       "      <td>0.634545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.449600</td>\n",
       "      <td>1.250666</td>\n",
       "      <td>0.632927</td>\n",
       "      <td>0.612658</td>\n",
       "      <td>0.612537</td>\n",
       "      <td>0.626435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.386200</td>\n",
       "      <td>1.292830</td>\n",
       "      <td>0.647561</td>\n",
       "      <td>0.618729</td>\n",
       "      <td>0.609506</td>\n",
       "      <td>0.633831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.343700</td>\n",
       "      <td>1.499364</td>\n",
       "      <td>0.670122</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.631327</td>\n",
       "      <td>0.609470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.305800</td>\n",
       "      <td>1.522177</td>\n",
       "      <td>0.670732</td>\n",
       "      <td>0.625497</td>\n",
       "      <td>0.632884</td>\n",
       "      <td>0.623369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.273600</td>\n",
       "      <td>1.609794</td>\n",
       "      <td>0.661585</td>\n",
       "      <td>0.626845</td>\n",
       "      <td>0.632007</td>\n",
       "      <td>0.628392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.248200</td>\n",
       "      <td>1.655223</td>\n",
       "      <td>0.664024</td>\n",
       "      <td>0.636435</td>\n",
       "      <td>0.646775</td>\n",
       "      <td>0.636532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.248200</td>\n",
       "      <td>1.709239</td>\n",
       "      <td>0.660976</td>\n",
       "      <td>0.611257</td>\n",
       "      <td>0.612410</td>\n",
       "      <td>0.611453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.225200</td>\n",
       "      <td>1.696425</td>\n",
       "      <td>0.660366</td>\n",
       "      <td>0.630315</td>\n",
       "      <td>0.632182</td>\n",
       "      <td>0.633827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.205900</td>\n",
       "      <td>1.715907</td>\n",
       "      <td>0.657927</td>\n",
       "      <td>0.621492</td>\n",
       "      <td>0.621084</td>\n",
       "      <td>0.624146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6915, training_loss=0.4511134933063455, metrics={'train_runtime': 1561.1964, 'train_samples_per_second': 141.737, 'train_steps_per_second': 4.429, 'total_flos': 2.93139542089728e+16, 'train_loss': 0.4511134933063455, 'epoch': 15.0})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_distribution_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = loss_distribution_trainer.predict(test_dataset)\n",
    "predictions_argmax = torch.argmax(torch.tensor(predictions.predictions), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_train = confusion_matrix(test_dataset.targets , predictions_argmax)\n",
    "ConfusionMatrixDisplay(confusion_matrix_train).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mca_eval(predictions_argmax, torch.tensor(test_dataset.targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mca_average(predictions_argmax, torch.tensor(test_dataset.targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Walidacja skrośna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 10\n",
    "kf = KFold(n_splits=n_splits)\n",
    "\n",
    "reviews = train_data['text'].to_numpy()\n",
    "targets = train_data['label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2075' max='2075' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2075/2075 07:54, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.805672</td>\n",
       "      <td>0.647696</td>\n",
       "      <td>0.575965</td>\n",
       "      <td>0.583624</td>\n",
       "      <td>0.578070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.857400</td>\n",
       "      <td>0.782911</td>\n",
       "      <td>0.660569</td>\n",
       "      <td>0.597669</td>\n",
       "      <td>0.615448</td>\n",
       "      <td>0.591337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.712000</td>\n",
       "      <td>0.783300</td>\n",
       "      <td>0.668699</td>\n",
       "      <td>0.592128</td>\n",
       "      <td>0.607585</td>\n",
       "      <td>0.587453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.630900</td>\n",
       "      <td>0.794953</td>\n",
       "      <td>0.668699</td>\n",
       "      <td>0.610219</td>\n",
       "      <td>0.609189</td>\n",
       "      <td>0.611773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.582600</td>\n",
       "      <td>0.805128</td>\n",
       "      <td>0.672087</td>\n",
       "      <td>0.606198</td>\n",
       "      <td>0.612250</td>\n",
       "      <td>0.603020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2075' max='2075' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2075/2075 07:55, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.549952</td>\n",
       "      <td>0.765583</td>\n",
       "      <td>0.711007</td>\n",
       "      <td>0.709899</td>\n",
       "      <td>0.726720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.569500</td>\n",
       "      <td>0.527761</td>\n",
       "      <td>0.772358</td>\n",
       "      <td>0.724946</td>\n",
       "      <td>0.739545</td>\n",
       "      <td>0.714292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.455500</td>\n",
       "      <td>0.534189</td>\n",
       "      <td>0.790650</td>\n",
       "      <td>0.758230</td>\n",
       "      <td>0.765205</td>\n",
       "      <td>0.753987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.388700</td>\n",
       "      <td>0.548305</td>\n",
       "      <td>0.790650</td>\n",
       "      <td>0.760653</td>\n",
       "      <td>0.764960</td>\n",
       "      <td>0.757225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.366600</td>\n",
       "      <td>0.545580</td>\n",
       "      <td>0.789295</td>\n",
       "      <td>0.757801</td>\n",
       "      <td>0.763352</td>\n",
       "      <td>0.752834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2075' max='2075' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2075/2075 07:55, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.348728</td>\n",
       "      <td>0.871186</td>\n",
       "      <td>0.868748</td>\n",
       "      <td>0.878196</td>\n",
       "      <td>0.860574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.483700</td>\n",
       "      <td>0.358215</td>\n",
       "      <td>0.854915</td>\n",
       "      <td>0.849485</td>\n",
       "      <td>0.855168</td>\n",
       "      <td>0.847790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.390300</td>\n",
       "      <td>0.358081</td>\n",
       "      <td>0.869831</td>\n",
       "      <td>0.861023</td>\n",
       "      <td>0.862961</td>\n",
       "      <td>0.860438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.323500</td>\n",
       "      <td>0.354665</td>\n",
       "      <td>0.865085</td>\n",
       "      <td>0.857516</td>\n",
       "      <td>0.864430</td>\n",
       "      <td>0.851218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.258800</td>\n",
       "      <td>0.353827</td>\n",
       "      <td>0.875254</td>\n",
       "      <td>0.871269</td>\n",
       "      <td>0.873888</td>\n",
       "      <td>0.869313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2075' max='2075' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2075/2075 07:55, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.168454</td>\n",
       "      <td>0.943729</td>\n",
       "      <td>0.937055</td>\n",
       "      <td>0.928626</td>\n",
       "      <td>0.946808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.218700</td>\n",
       "      <td>0.139871</td>\n",
       "      <td>0.947119</td>\n",
       "      <td>0.941280</td>\n",
       "      <td>0.945818</td>\n",
       "      <td>0.937376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.176000</td>\n",
       "      <td>0.153678</td>\n",
       "      <td>0.952542</td>\n",
       "      <td>0.950456</td>\n",
       "      <td>0.954535</td>\n",
       "      <td>0.947482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.135700</td>\n",
       "      <td>0.121471</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.956687</td>\n",
       "      <td>0.959991</td>\n",
       "      <td>0.953786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.133000</td>\n",
       "      <td>0.121851</td>\n",
       "      <td>0.960678</td>\n",
       "      <td>0.957756</td>\n",
       "      <td>0.959463</td>\n",
       "      <td>0.956515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2075' max='2075' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2075/2075 07:57, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.104087</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.961966</td>\n",
       "      <td>0.967207</td>\n",
       "      <td>0.959019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.135700</td>\n",
       "      <td>0.051345</td>\n",
       "      <td>0.981017</td>\n",
       "      <td>0.977571</td>\n",
       "      <td>0.979747</td>\n",
       "      <td>0.975800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.106100</td>\n",
       "      <td>0.089372</td>\n",
       "      <td>0.970169</td>\n",
       "      <td>0.973098</td>\n",
       "      <td>0.975023</td>\n",
       "      <td>0.972505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.025264</td>\n",
       "      <td>0.991864</td>\n",
       "      <td>0.994034</td>\n",
       "      <td>0.995522</td>\n",
       "      <td>0.992586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.087600</td>\n",
       "      <td>0.018861</td>\n",
       "      <td>0.993220</td>\n",
       "      <td>0.994773</td>\n",
       "      <td>0.994630</td>\n",
       "      <td>0.994939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2075' max='2075' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2075/2075 07:55, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.094406</td>\n",
       "      <td>0.966102</td>\n",
       "      <td>0.967037</td>\n",
       "      <td>0.972988</td>\n",
       "      <td>0.961675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.118000</td>\n",
       "      <td>0.054872</td>\n",
       "      <td>0.985085</td>\n",
       "      <td>0.985141</td>\n",
       "      <td>0.987223</td>\n",
       "      <td>0.983130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.093300</td>\n",
       "      <td>0.059220</td>\n",
       "      <td>0.983051</td>\n",
       "      <td>0.980229</td>\n",
       "      <td>0.984212</td>\n",
       "      <td>0.976653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.053800</td>\n",
       "      <td>0.043497</td>\n",
       "      <td>0.990508</td>\n",
       "      <td>0.988435</td>\n",
       "      <td>0.987799</td>\n",
       "      <td>0.989184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.059200</td>\n",
       "      <td>0.027694</td>\n",
       "      <td>0.991864</td>\n",
       "      <td>0.991063</td>\n",
       "      <td>0.990718</td>\n",
       "      <td>0.991422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2075' max='2075' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2075/2075 07:55, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.040235</td>\n",
       "      <td>0.987119</td>\n",
       "      <td>0.986318</td>\n",
       "      <td>0.984143</td>\n",
       "      <td>0.988798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.100700</td>\n",
       "      <td>0.052885</td>\n",
       "      <td>0.984407</td>\n",
       "      <td>0.986790</td>\n",
       "      <td>0.983087</td>\n",
       "      <td>0.990841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.071000</td>\n",
       "      <td>0.041052</td>\n",
       "      <td>0.987119</td>\n",
       "      <td>0.985691</td>\n",
       "      <td>0.986089</td>\n",
       "      <td>0.985427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.045600</td>\n",
       "      <td>0.043328</td>\n",
       "      <td>0.988475</td>\n",
       "      <td>0.986680</td>\n",
       "      <td>0.983207</td>\n",
       "      <td>0.990304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.043900</td>\n",
       "      <td>0.017471</td>\n",
       "      <td>0.993898</td>\n",
       "      <td>0.992593</td>\n",
       "      <td>0.991459</td>\n",
       "      <td>0.993845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2075' max='2075' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2075/2075 07:55, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.045160</td>\n",
       "      <td>0.987119</td>\n",
       "      <td>0.983594</td>\n",
       "      <td>0.982828</td>\n",
       "      <td>0.984477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.115500</td>\n",
       "      <td>0.031962</td>\n",
       "      <td>0.988475</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.989094</td>\n",
       "      <td>0.991567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.053600</td>\n",
       "      <td>0.019188</td>\n",
       "      <td>0.993898</td>\n",
       "      <td>0.992187</td>\n",
       "      <td>0.993361</td>\n",
       "      <td>0.991165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.035300</td>\n",
       "      <td>0.011188</td>\n",
       "      <td>0.996610</td>\n",
       "      <td>0.994610</td>\n",
       "      <td>0.994610</td>\n",
       "      <td>0.994610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.035200</td>\n",
       "      <td>0.008845</td>\n",
       "      <td>0.997288</td>\n",
       "      <td>0.996257</td>\n",
       "      <td>0.996502</td>\n",
       "      <td>0.996029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2075' max='2075' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2075/2075 07:55, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.068416</td>\n",
       "      <td>0.981695</td>\n",
       "      <td>0.983625</td>\n",
       "      <td>0.985628</td>\n",
       "      <td>0.982069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.098300</td>\n",
       "      <td>0.032772</td>\n",
       "      <td>0.992542</td>\n",
       "      <td>0.992375</td>\n",
       "      <td>0.991132</td>\n",
       "      <td>0.993663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.048200</td>\n",
       "      <td>0.027192</td>\n",
       "      <td>0.993220</td>\n",
       "      <td>0.991858</td>\n",
       "      <td>0.991038</td>\n",
       "      <td>0.992739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.035100</td>\n",
       "      <td>0.023014</td>\n",
       "      <td>0.995932</td>\n",
       "      <td>0.995988</td>\n",
       "      <td>0.996020</td>\n",
       "      <td>0.995977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.026800</td>\n",
       "      <td>0.018810</td>\n",
       "      <td>0.996610</td>\n",
       "      <td>0.997623</td>\n",
       "      <td>0.997838</td>\n",
       "      <td>0.997416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2075' max='2075' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2075/2075 07:55, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.071473</td>\n",
       "      <td>0.980339</td>\n",
       "      <td>0.977182</td>\n",
       "      <td>0.976756</td>\n",
       "      <td>0.977951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>0.038516</td>\n",
       "      <td>0.986441</td>\n",
       "      <td>0.987414</td>\n",
       "      <td>0.990691</td>\n",
       "      <td>0.984470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.056200</td>\n",
       "      <td>0.017780</td>\n",
       "      <td>0.993898</td>\n",
       "      <td>0.995108</td>\n",
       "      <td>0.994280</td>\n",
       "      <td>0.995956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>0.008918</td>\n",
       "      <td>0.997288</td>\n",
       "      <td>0.997114</td>\n",
       "      <td>0.997067</td>\n",
       "      <td>0.997184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>0.006926</td>\n",
       "      <td>0.997966</td>\n",
       "      <td>0.996156</td>\n",
       "      <td>0.995585</td>\n",
       "      <td>0.996789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for train_index, val_index in kf.split(reviews):\n",
    "    train_reviews, val_reviews = reviews[train_index], reviews[val_index]\n",
    "    train_targets, val_targets = targets[train_index], targets[val_index]\n",
    "\n",
    "    train_dataset = ReviewDataset(train_reviews, train_targets, tokenizer, 128)\n",
    "    val_dataset = ReviewDataset(val_reviews, val_targets, tokenizer, 128)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 1/52 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = trainer.predict(test_dataset)\n",
    "predictions_argmax = torch.argmax(torch.tensor(predictions.predictions), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_matrix_train = confusion_matrix(test_dataset.targets , predictions_argmax)\n",
    "ConfusionMatrixDisplay(confusion_matrix_train).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6429, 0.5659, 0.4946, 0.5409, 0.7520])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mca_eval(predictions_argmax, torch.tensor(test_dataset.targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6396)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mca_average(predictions_argmax, torch.tensor(test_dataset.targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Walidacja skrośna pozwala na ograniczenie przetrenowania, ale w obecnej formie nie neguje problemów związanych z nierówną dystrybucją danych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Walidacja skrośna z wykorzystaniem podziału z równą dystrybucją klas w poszczególnych foldach i funkcji strat z wagami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at j-hartmann/emotion-english-distilroberta-base and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([7, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([7]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"j-hartmann/emotion-english-distilroberta-base\")\n",
    "config = AutoConfig.from_pretrained(\"j-hartmann/emotion-english-distilroberta-base\", \n",
    "                                    num_labels=5, \n",
    "                                    hidden_dropout_prob=0.1,\n",
    "                                    attention_probs_dropout_prob=0.1, return_dict=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"j-hartmann/emotion-english-distilroberta-base\", \n",
    "                                                           config=config,\n",
    "                                                           ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_classes = np.unique(data[\"label\"].values)\n",
    "y = data[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight(class_weight='balanced', classes = unique_classes, y = y)\n",
    "class_weights = torch.tensor(class_weights).to(device)\n",
    "loss_function = torch.nn.CrossEntropyLoss(weight=class_weights.to(torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        loss = loss_function(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 10\n",
    "kf = StratifiedKFold(n_splits=n_splits)\n",
    "\n",
    "reviews = train_data['text'].to_numpy()\n",
    "targets = train_data['label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2075' max='2075' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2075/2075 07:51, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.948584</td>\n",
       "      <td>0.586721</td>\n",
       "      <td>0.561723</td>\n",
       "      <td>0.552416</td>\n",
       "      <td>0.589404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.006200</td>\n",
       "      <td>0.918168</td>\n",
       "      <td>0.615176</td>\n",
       "      <td>0.577807</td>\n",
       "      <td>0.572593</td>\n",
       "      <td>0.592146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.802400</td>\n",
       "      <td>0.934260</td>\n",
       "      <td>0.638211</td>\n",
       "      <td>0.589312</td>\n",
       "      <td>0.581052</td>\n",
       "      <td>0.602880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.691300</td>\n",
       "      <td>0.962359</td>\n",
       "      <td>0.615176</td>\n",
       "      <td>0.579376</td>\n",
       "      <td>0.565896</td>\n",
       "      <td>0.603173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.621800</td>\n",
       "      <td>1.012782</td>\n",
       "      <td>0.636856</td>\n",
       "      <td>0.589002</td>\n",
       "      <td>0.580502</td>\n",
       "      <td>0.599839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2075' max='2075' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2075/2075 07:54, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.714523</td>\n",
       "      <td>0.701897</td>\n",
       "      <td>0.673309</td>\n",
       "      <td>0.653342</td>\n",
       "      <td>0.711215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.657300</td>\n",
       "      <td>0.641787</td>\n",
       "      <td>0.733740</td>\n",
       "      <td>0.731169</td>\n",
       "      <td>0.728078</td>\n",
       "      <td>0.743910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.512900</td>\n",
       "      <td>0.690727</td>\n",
       "      <td>0.728997</td>\n",
       "      <td>0.719671</td>\n",
       "      <td>0.709340</td>\n",
       "      <td>0.737977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.475500</td>\n",
       "      <td>0.693832</td>\n",
       "      <td>0.717480</td>\n",
       "      <td>0.706121</td>\n",
       "      <td>0.687922</td>\n",
       "      <td>0.730216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.447600</td>\n",
       "      <td>0.694084</td>\n",
       "      <td>0.737805</td>\n",
       "      <td>0.739088</td>\n",
       "      <td>0.732423</td>\n",
       "      <td>0.747490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2075' max='2075' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2075/2075 07:52, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.381207</td>\n",
       "      <td>0.797966</td>\n",
       "      <td>0.841894</td>\n",
       "      <td>0.833996</td>\n",
       "      <td>0.852244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.522100</td>\n",
       "      <td>0.398222</td>\n",
       "      <td>0.788475</td>\n",
       "      <td>0.831246</td>\n",
       "      <td>0.818154</td>\n",
       "      <td>0.846861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.425400</td>\n",
       "      <td>0.407574</td>\n",
       "      <td>0.792542</td>\n",
       "      <td>0.837203</td>\n",
       "      <td>0.840003</td>\n",
       "      <td>0.835478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.366500</td>\n",
       "      <td>0.368789</td>\n",
       "      <td>0.803390</td>\n",
       "      <td>0.849560</td>\n",
       "      <td>0.840438</td>\n",
       "      <td>0.862066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.312900</td>\n",
       "      <td>0.375866</td>\n",
       "      <td>0.797966</td>\n",
       "      <td>0.846515</td>\n",
       "      <td>0.835290</td>\n",
       "      <td>0.861880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2075' max='2075' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2075/2075 07:54, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.248421</td>\n",
       "      <td>0.809492</td>\n",
       "      <td>0.877541</td>\n",
       "      <td>0.875329</td>\n",
       "      <td>0.896178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.337600</td>\n",
       "      <td>0.254302</td>\n",
       "      <td>0.837288</td>\n",
       "      <td>0.887977</td>\n",
       "      <td>0.889642</td>\n",
       "      <td>0.892975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.266700</td>\n",
       "      <td>0.219202</td>\n",
       "      <td>0.865085</td>\n",
       "      <td>0.909996</td>\n",
       "      <td>0.902953</td>\n",
       "      <td>0.917912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.224300</td>\n",
       "      <td>0.223536</td>\n",
       "      <td>0.850169</td>\n",
       "      <td>0.900058</td>\n",
       "      <td>0.890141</td>\n",
       "      <td>0.914639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.219000</td>\n",
       "      <td>0.224515</td>\n",
       "      <td>0.859661</td>\n",
       "      <td>0.906133</td>\n",
       "      <td>0.895997</td>\n",
       "      <td>0.919468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2075' max='2075' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2075/2075 07:54, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.247880</td>\n",
       "      <td>0.877966</td>\n",
       "      <td>0.900632</td>\n",
       "      <td>0.906692</td>\n",
       "      <td>0.898294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.232500</td>\n",
       "      <td>0.165193</td>\n",
       "      <td>0.888814</td>\n",
       "      <td>0.930672</td>\n",
       "      <td>0.930769</td>\n",
       "      <td>0.935991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.180400</td>\n",
       "      <td>0.178006</td>\n",
       "      <td>0.897627</td>\n",
       "      <td>0.933990</td>\n",
       "      <td>0.935198</td>\n",
       "      <td>0.933975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.155600</td>\n",
       "      <td>0.153761</td>\n",
       "      <td>0.901017</td>\n",
       "      <td>0.937721</td>\n",
       "      <td>0.933521</td>\n",
       "      <td>0.942733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.179900</td>\n",
       "      <td>0.152943</td>\n",
       "      <td>0.899661</td>\n",
       "      <td>0.937111</td>\n",
       "      <td>0.935839</td>\n",
       "      <td>0.938638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2075' max='2075' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2075/2075 07:55, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.110194</td>\n",
       "      <td>0.947119</td>\n",
       "      <td>0.966561</td>\n",
       "      <td>0.971305</td>\n",
       "      <td>0.963927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.152700</td>\n",
       "      <td>0.108228</td>\n",
       "      <td>0.936949</td>\n",
       "      <td>0.958582</td>\n",
       "      <td>0.954380</td>\n",
       "      <td>0.964141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.121000</td>\n",
       "      <td>0.114028</td>\n",
       "      <td>0.953220</td>\n",
       "      <td>0.969068</td>\n",
       "      <td>0.971092</td>\n",
       "      <td>0.967276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.081100</td>\n",
       "      <td>0.091674</td>\n",
       "      <td>0.953220</td>\n",
       "      <td>0.969812</td>\n",
       "      <td>0.966794</td>\n",
       "      <td>0.973191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.132900</td>\n",
       "      <td>0.080599</td>\n",
       "      <td>0.960678</td>\n",
       "      <td>0.975330</td>\n",
       "      <td>0.974287</td>\n",
       "      <td>0.976418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2075' max='2075' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2075/2075 07:53, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.068279</td>\n",
       "      <td>0.961356</td>\n",
       "      <td>0.976461</td>\n",
       "      <td>0.974050</td>\n",
       "      <td>0.979683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.108900</td>\n",
       "      <td>0.057291</td>\n",
       "      <td>0.974915</td>\n",
       "      <td>0.982777</td>\n",
       "      <td>0.983106</td>\n",
       "      <td>0.982625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.074200</td>\n",
       "      <td>0.056928</td>\n",
       "      <td>0.972881</td>\n",
       "      <td>0.979937</td>\n",
       "      <td>0.976868</td>\n",
       "      <td>0.983442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.042160</td>\n",
       "      <td>0.979661</td>\n",
       "      <td>0.987051</td>\n",
       "      <td>0.985498</td>\n",
       "      <td>0.988648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.076800</td>\n",
       "      <td>0.028967</td>\n",
       "      <td>0.984407</td>\n",
       "      <td>0.991176</td>\n",
       "      <td>0.991250</td>\n",
       "      <td>0.991103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2075' max='2075' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2075/2075 07:55, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.059921</td>\n",
       "      <td>0.965424</td>\n",
       "      <td>0.974578</td>\n",
       "      <td>0.969264</td>\n",
       "      <td>0.981000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.106900</td>\n",
       "      <td>0.048907</td>\n",
       "      <td>0.981017</td>\n",
       "      <td>0.986800</td>\n",
       "      <td>0.986174</td>\n",
       "      <td>0.987525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.059500</td>\n",
       "      <td>0.036483</td>\n",
       "      <td>0.986441</td>\n",
       "      <td>0.988063</td>\n",
       "      <td>0.986080</td>\n",
       "      <td>0.990220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.032104</td>\n",
       "      <td>0.988475</td>\n",
       "      <td>0.991611</td>\n",
       "      <td>0.991994</td>\n",
       "      <td>0.991293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.058600</td>\n",
       "      <td>0.028150</td>\n",
       "      <td>0.991186</td>\n",
       "      <td>0.994518</td>\n",
       "      <td>0.994423</td>\n",
       "      <td>0.994633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2075' max='2075' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2075/2075 07:53, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.061561</td>\n",
       "      <td>0.975593</td>\n",
       "      <td>0.982026</td>\n",
       "      <td>0.985815</td>\n",
       "      <td>0.978820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.108300</td>\n",
       "      <td>0.033847</td>\n",
       "      <td>0.982373</td>\n",
       "      <td>0.987152</td>\n",
       "      <td>0.987475</td>\n",
       "      <td>0.986860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.056400</td>\n",
       "      <td>0.028215</td>\n",
       "      <td>0.987797</td>\n",
       "      <td>0.991222</td>\n",
       "      <td>0.992420</td>\n",
       "      <td>0.990140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.030200</td>\n",
       "      <td>0.029723</td>\n",
       "      <td>0.991186</td>\n",
       "      <td>0.995013</td>\n",
       "      <td>0.995088</td>\n",
       "      <td>0.994938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.031500</td>\n",
       "      <td>0.019780</td>\n",
       "      <td>0.993898</td>\n",
       "      <td>0.996545</td>\n",
       "      <td>0.996776</td>\n",
       "      <td>0.996320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2075' max='2075' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2075/2075 07:54, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.050598</td>\n",
       "      <td>0.979661</td>\n",
       "      <td>0.985533</td>\n",
       "      <td>0.988117</td>\n",
       "      <td>0.983271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.089600</td>\n",
       "      <td>0.096836</td>\n",
       "      <td>0.974237</td>\n",
       "      <td>0.979154</td>\n",
       "      <td>0.979763</td>\n",
       "      <td>0.979313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.056400</td>\n",
       "      <td>0.050354</td>\n",
       "      <td>0.984407</td>\n",
       "      <td>0.989059</td>\n",
       "      <td>0.988469</td>\n",
       "      <td>0.989883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>0.026806</td>\n",
       "      <td>0.989831</td>\n",
       "      <td>0.993293</td>\n",
       "      <td>0.992136</td>\n",
       "      <td>0.994476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.022700</td>\n",
       "      <td>0.024596</td>\n",
       "      <td>0.991864</td>\n",
       "      <td>0.994904</td>\n",
       "      <td>0.994897</td>\n",
       "      <td>0.994940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for train_index, val_index in kf.split(reviews, targets):\n",
    "    train_reviews, val_reviews = reviews[train_index], reviews[val_index]\n",
    "    train_targets, val_targets = targets[train_index], targets[val_index]\n",
    "\n",
    "    train_dataset = ReviewDataset(train_reviews, train_targets, tokenizer, 128)\n",
    "    val_dataset = ReviewDataset(val_reviews, val_targets, tokenizer, 128)\n",
    "\n",
    "    trainer = CustomTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = trainer.predict(test_dataset)\n",
    "predictions_argmax = torch.argmax(torch.tensor(predictions.predictions), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_matrix_train = confusion_matrix(test_dataset.targets , predictions_argmax)\n",
    "ConfusionMatrixDisplay(confusion_matrix_train).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6429, 0.5426, 0.4565, 0.5325, 0.7818])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mca_eval(predictions_argmax, torch.tensor(test_dataset.targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6445)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mca_average(predictions_argmax, torch.tensor(test_dataset.targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM + TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/train_data.csv\")\n",
    "data[\"label\"] = data[\"rating\"]\n",
    "data.rename(columns={\"review\":\"text\"}, inplace=True)\n",
    "data.drop('rating', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = data[\"text\"]\n",
    "label = data[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/SSNE-Pawel/.venv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    min_df=5, max_features=16000, strip_accents='unicode', lowercase=True,\n",
    "    analyzer='word', ngram_range=(1, 3), use_idf=True, \n",
    "    smooth_idf=True, sublinear_tf=True, tokenizer=TweetTokenizer().tokenize, stop_words='english'\n",
    ")\n",
    "X = vectorizer.fit_transform(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, label, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-8 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-8 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-8 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-8 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-8 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-8 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-8 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-8 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-8 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1, gamma=&#x27;auto&#x27;, kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;SVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(C=1, gamma=&#x27;auto&#x27;, kernel=&#x27;linear&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=1, gamma='auto', kernel='linear')"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
    "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
    "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "  tol=0.001, verbose=False)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    0           1           2           3           4  \\\n",
      "precision    0.769231    0.471014    0.450450    0.517312    0.740420   \n",
      "recall       0.625000    0.503876    0.271739    0.532495    0.811653   \n",
      "f1-score     0.689655    0.486891    0.338983    0.524793    0.774402   \n",
      "support    112.000000  129.000000  184.000000  477.000000  738.000000   \n",
      "\n",
      "           accuracy    macro avg  weighted avg  \n",
      "precision  0.632927     0.589686      0.623772  \n",
      "recall     0.632927     0.548953      0.632927  \n",
      "f1-score   0.632927     0.562945      0.624548  \n",
      "support    0.632927  1640.000000   1640.000000  \n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "df = pd.DataFrame(report)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6329268292682927"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mJądro Kernel uległo awarii podczas wykonywania kodu w bieżącej komórce lub w poprzedniej komórce. \n",
      "\u001b[1;31mPrzejrzyj kod w komórkach, aby zidentyfikować możliwą przyczynę awarii. \n",
      "\u001b[1;31mKliknij <a href='https://aka.ms/vscodeJupyterKernelCrash'>tutaj</a>, aby uzyskać więcej informacji. \n",
      "\u001b[1;31mAby uzyskać dalsze szczegóły, wyświetl <a href='command:jupyter.viewOutput'>dziennik</a> Jupyter."
     ]
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)\n",
    "ConfusionMatrixDisplay(confusion_matrix_train).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(class_weight='balanced')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    0           1           2           3           4  \\\n",
      "precision    0.763158    0.461538    0.625000    0.411972    0.546549   \n",
      "recall       0.517857    0.093023    0.027174    0.245283    0.922764   \n",
      "f1-score     0.617021    0.154839    0.052083    0.307490    0.686492   \n",
      "support    112.000000  129.000000  184.000000  477.000000  738.000000   \n",
      "\n",
      "           accuracy    macro avg  weighted avg  \n",
      "precision  0.532317     0.561643      0.524315  \n",
      "recall     0.532317     0.361220      0.532317  \n",
      "f1-score   0.532317     0.363585      0.458517  \n",
      "support    0.532317  1640.000000   1640.000000  \n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "df = pd.DataFrame(report)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5323170731707317"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "parameters = {\n",
    "    'n_estimators': [5,50,100],\n",
    "    'max_depth': [2,10,20,None],\n",
    "    'class_weight':['balanced', None, 'balanced_subsample']\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = GridSearchCV(rf,parameters)\n",
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = cv.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0        0.047219      0.002014         0.015260        0.000458   \n",
      "1        0.217694      0.002511         0.040255        0.001864   \n",
      "2        0.409343      0.005261         0.071774        0.007772   \n",
      "3        0.102393      0.005773         0.015420        0.000368   \n",
      "4        0.801351      0.010105         0.048487        0.004788   \n",
      "5        1.589737      0.018746         0.081609        0.007292   \n",
      "6        0.242185      0.019459         0.016209        0.000436   \n",
      "7        2.311811      0.036959         0.052460        0.005309   \n",
      "8        4.518989      0.050328         0.090383        0.003303   \n",
      "9        1.309193      0.014460         0.018880        0.000660   \n",
      "10      12.892660      0.082051         0.072341        0.005134   \n",
      "11      25.827511      0.157441         0.143559        0.009544   \n",
      "12       0.043161      0.000832         0.014937        0.000245   \n",
      "13       0.213590      0.001246         0.041862        0.002311   \n",
      "14       0.405572      0.001678         0.070338        0.003250   \n",
      "15       0.098910      0.002278         0.015560        0.000567   \n",
      "16       0.809246      0.007443         0.044245        0.003187   \n",
      "17       1.582959      0.009403         0.075979        0.006456   \n",
      "18       0.249293      0.015468         0.016132        0.000397   \n",
      "19       2.253152      0.032966         0.051274        0.004667   \n",
      "20       4.455998      0.041425         0.092755        0.007119   \n",
      "21       1.173267      0.020385         0.018394        0.000480   \n",
      "22      11.478863      0.044706         0.070958        0.002445   \n",
      "23      22.893757      0.055160         0.135442        0.010478   \n",
      "24       0.055063      0.000675         0.014845        0.000133   \n",
      "25       0.329420      0.003738         0.042839        0.001937   \n",
      "26       0.639750      0.010464         0.075434        0.005420   \n",
      "27       0.114328      0.002636         0.015710        0.000622   \n",
      "28       0.914154      0.008953         0.045199        0.004204   \n",
      "29       1.847816      0.011436         0.077681        0.004491   \n",
      "30       0.259241      0.013969         0.015916        0.000376   \n",
      "31       2.405164      0.050124         0.051567        0.002658   \n",
      "32       4.673710      0.082461         0.090076        0.007105   \n",
      "33       1.323040      0.016827         0.018513        0.000437   \n",
      "34      13.075389      0.070134         0.075144        0.004180   \n",
      "35      26.119067      0.094265         0.138217        0.004653   \n",
      "\n",
      "    param_class_weight param_max_depth param_n_estimators  \\\n",
      "0             balanced               2                  5   \n",
      "1             balanced               2                 50   \n",
      "2             balanced               2                100   \n",
      "3             balanced              10                  5   \n",
      "4             balanced              10                 50   \n",
      "5             balanced              10                100   \n",
      "6             balanced              20                  5   \n",
      "7             balanced              20                 50   \n",
      "8             balanced              20                100   \n",
      "9             balanced            None                  5   \n",
      "10            balanced            None                 50   \n",
      "11            balanced            None                100   \n",
      "12                None               2                  5   \n",
      "13                None               2                 50   \n",
      "14                None               2                100   \n",
      "15                None              10                  5   \n",
      "16                None              10                 50   \n",
      "17                None              10                100   \n",
      "18                None              20                  5   \n",
      "19                None              20                 50   \n",
      "20                None              20                100   \n",
      "21                None            None                  5   \n",
      "22                None            None                 50   \n",
      "23                None            None                100   \n",
      "24  balanced_subsample               2                  5   \n",
      "25  balanced_subsample               2                 50   \n",
      "26  balanced_subsample               2                100   \n",
      "27  balanced_subsample              10                  5   \n",
      "28  balanced_subsample              10                 50   \n",
      "29  balanced_subsample              10                100   \n",
      "30  balanced_subsample              20                  5   \n",
      "31  balanced_subsample              20                 50   \n",
      "32  balanced_subsample              20                100   \n",
      "33  balanced_subsample            None                  5   \n",
      "34  balanced_subsample            None                 50   \n",
      "35  balanced_subsample            None                100   \n",
      "\n",
      "                                               params  split0_test_score  \\\n",
      "0   {'class_weight': 'balanced', 'max_depth': 2, '...           0.313792   \n",
      "1   {'class_weight': 'balanced', 'max_depth': 2, '...           0.464927   \n",
      "2   {'class_weight': 'balanced', 'max_depth': 2, '...           0.496781   \n",
      "3   {'class_weight': 'balanced', 'max_depth': 10, ...           0.408336   \n",
      "4   {'class_weight': 'balanced', 'max_depth': 10, ...           0.537106   \n",
      "5   {'class_weight': 'balanced', 'max_depth': 10, ...           0.551339   \n",
      "6   {'class_weight': 'balanced', 'max_depth': 20, ...           0.430024   \n",
      "7   {'class_weight': 'balanced', 'max_depth': 20, ...           0.549644   \n",
      "8   {'class_weight': 'balanced', 'max_depth': 20, ...           0.564893   \n",
      "9   {'class_weight': 'balanced', 'max_depth': None...           0.451372   \n",
      "10  {'class_weight': 'balanced', 'max_depth': None...           0.536428   \n",
      "11  {'class_weight': 'balanced', 'max_depth': None...           0.543545   \n",
      "12  {'class_weight': None, 'max_depth': 2, 'n_esti...           0.440529   \n",
      "13  {'class_weight': None, 'max_depth': 2, 'n_esti...           0.440868   \n",
      "14  {'class_weight': None, 'max_depth': 2, 'n_esti...           0.440868   \n",
      "15  {'class_weight': None, 'max_depth': 10, 'n_est...           0.460183   \n",
      "16  {'class_weight': None, 'max_depth': 10, 'n_est...           0.443578   \n",
      "17  {'class_weight': None, 'max_depth': 10, 'n_est...           0.445273   \n",
      "18  {'class_weight': None, 'max_depth': 20, 'n_est...           0.462555   \n",
      "19  {'class_weight': None, 'max_depth': 20, 'n_est...           0.475093   \n",
      "20  {'class_weight': None, 'max_depth': 20, 'n_est...           0.469332   \n",
      "21  {'class_weight': None, 'max_depth': None, 'n_e...           0.478143   \n",
      "22  {'class_weight': None, 'max_depth': None, 'n_e...           0.536767   \n",
      "23  {'class_weight': None, 'max_depth': None, 'n_e...           0.537784   \n",
      "24  {'class_weight': 'balanced_subsample', 'max_de...           0.280244   \n",
      "25  {'class_weight': 'balanced_subsample', 'max_de...           0.437140   \n",
      "26  {'class_weight': 'balanced_subsample', 'max_de...           0.496781   \n",
      "27  {'class_weight': 'balanced_subsample', 'max_de...           0.401559   \n",
      "28  {'class_weight': 'balanced_subsample', 'max_de...           0.535073   \n",
      "29  {'class_weight': 'balanced_subsample', 'max_de...           0.556083   \n",
      "30  {'class_weight': 'balanced_subsample', 'max_de...           0.443578   \n",
      "31  {'class_weight': 'balanced_subsample', 'max_de...           0.547272   \n",
      "32  {'class_weight': 'balanced_subsample', 'max_de...           0.574720   \n",
      "33  {'class_weight': 'balanced_subsample', 'max_de...           0.464249   \n",
      "34  {'class_weight': 'balanced_subsample', 'max_de...           0.538800   \n",
      "35  {'class_weight': 'balanced_subsample', 'max_de...           0.545917   \n",
      "\n",
      "    split1_test_score  split2_test_score  split3_test_score  \\\n",
      "0            0.392070           0.261017           0.368136   \n",
      "1            0.460861           0.455932           0.505085   \n",
      "2            0.506269           0.508475           0.525763   \n",
      "3            0.397831           0.413220           0.342373   \n",
      "4            0.528973           0.546780           0.521356   \n",
      "5            0.548966           0.554915           0.559661   \n",
      "6            0.439173           0.419661           0.416949   \n",
      "7            0.557099           0.534576           0.544746   \n",
      "8            0.563199           0.568814           0.563051   \n",
      "9            0.452389           0.442712           0.461017   \n",
      "10           0.545578           0.538305           0.547458   \n",
      "11           0.535751           0.534576           0.530847   \n",
      "12           0.441206           0.441356           0.441017   \n",
      "13           0.440868           0.441017           0.441017   \n",
      "14           0.440868           0.441017           0.441017   \n",
      "15           0.447306           0.452881           0.449492   \n",
      "16           0.444256           0.444068           0.447458   \n",
      "17           0.443578           0.444068           0.443051   \n",
      "18           0.461538           0.468814           0.479661   \n",
      "19           0.477465           0.480000           0.480339   \n",
      "20           0.473060           0.473220           0.480339   \n",
      "21           0.486615           0.488814           0.473559   \n",
      "22           0.538462           0.535254           0.531525   \n",
      "23           0.543545           0.544407           0.532881   \n",
      "24           0.296171           0.434237           0.257627   \n",
      "25           0.458828           0.468475           0.458305   \n",
      "26           0.503219           0.485763           0.517627   \n",
      "27           0.384954           0.351525           0.410169   \n",
      "28           0.529651           0.535932           0.551186   \n",
      "29           0.548289           0.545085           0.558644   \n",
      "30           0.427313           0.421017           0.456271   \n",
      "31           0.549983           0.548475           0.552203   \n",
      "32           0.573365           0.577966           0.563390   \n",
      "33           0.460861           0.456271           0.447797   \n",
      "34           0.533040           0.540339           0.535254   \n",
      "35           0.537784           0.540000           0.532881   \n",
      "\n",
      "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
      "0            0.142034         0.295410        0.089081               36  \n",
      "1            0.476949         0.472751        0.017599               20  \n",
      "2            0.493220         0.506101        0.011358               15  \n",
      "3            0.406102         0.393572        0.026079               33  \n",
      "4            0.534237         0.533690        0.008458               14  \n",
      "5            0.558983         0.554773        0.004175                3  \n",
      "6            0.431186         0.427399        0.008111               32  \n",
      "7            0.544407         0.546094        0.007363                6  \n",
      "8            0.550508         0.562093        0.006154                2  \n",
      "9            0.454237         0.452346        0.005874               25  \n",
      "10           0.544746         0.542503        0.004326                7  \n",
      "11           0.541356         0.537215        0.004623               11  \n",
      "12           0.441695         0.441161        0.000386               28  \n",
      "13           0.441017         0.440957        0.000073               29  \n",
      "14           0.441017         0.440957        0.000073               29  \n",
      "15           0.453559         0.452684        0.004385               24  \n",
      "16           0.444407         0.444753        0.001381               26  \n",
      "17           0.445085         0.444211        0.000855               27  \n",
      "18           0.463051         0.467124        0.006763               21  \n",
      "19           0.476949         0.477969        0.001965               18  \n",
      "20           0.481695         0.475529        0.004711               19  \n",
      "21           0.475593         0.480545        0.006071               17  \n",
      "22           0.535593         0.535520        0.002291               13  \n",
      "23           0.538305         0.539384        0.004208                8  \n",
      "24           0.316610         0.316978        0.061733               35  \n",
      "25           0.499661         0.464482        0.020353               22  \n",
      "26           0.526102         0.505898        0.014433               16  \n",
      "27           0.414576         0.392557        0.022880               34  \n",
      "28           0.543390         0.539046        0.007483                9  \n",
      "29           0.549492         0.551518        0.005051                4  \n",
      "30           0.436610         0.436958        0.012362               31  \n",
      "31           0.537288         0.547044        0.005148                5  \n",
      "32           0.554576         0.568804        0.008620                1  \n",
      "33           0.455254         0.456886        0.005580               23  \n",
      "34           0.534237         0.536334        0.002776               12  \n",
      "35           0.531864         0.537689        0.005101               10  \n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(cv_results)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5323170731707317"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArtifficialNeuralNetworks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
