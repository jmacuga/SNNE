{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from torchmetrics.classification import MulticlassAccuracy\n",
    "from sklearn.metrics import f1_score, confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_recall_fscore_support\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold, Stratified\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/SSNE-Pawel/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at j-hartmann/emotion-english-distilroberta-base and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([7, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([7]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
    "from transformers import BertForSequenceClassification\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"j-hartmann/emotion-english-distilroberta-base\")\n",
    "config = AutoConfig.from_pretrained(\"j-hartmann/emotion-english-distilroberta-base\", \n",
    "                                    num_labels=5, \n",
    "                                    hidden_dropout_prob=0.1,\n",
    "                                    attention_probs_dropout_prob=0.1, return_dict=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"j-hartmann/emotion-english-distilroberta-base\", \n",
    "                                                           config=config,\n",
    "                                                           ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text  label\n",
      "0      location not palace excellent hotel booke dthe...      4\n",
      "1      respite definitely not place stay looking ultr...      3\n",
      "2      stunning truly memorable spot right beach nusa...      4\n",
      "3      solid business hotel near embassy stayed hotel...      3\n",
      "4      nice place make sure lock money warning money ...      3\n",
      "...                                                  ...    ...\n",
      "16387  great base explore new york stayed 4 nights en...      4\n",
      "16388  wonderful advert paris wonderful introduction ...      4\n",
      "16389  ideal relaxing holdiay rachel jay green liverp...      3\n",
      "16390  watch food, husband went resort 4 nights chris...      2\n",
      "16391  fantastic hotel central barcelona family just ...      4\n",
      "\n",
      "[16392 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/train_data.csv\")\n",
    "data[\"label\"] = data[\"rating\"]\n",
    "data.rename(columns={\"review\":\"text\"}, inplace=True)\n",
    "data.drop('rating', axis=1, inplace=True)\n",
    "train_data, val_data = train_test_split(data, test_size=0.1, random_state=42)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_data)\n",
    "val_df = pd.DataFrame(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1640"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_data[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loader(encodings, labels):\n",
    "    dataset = TensorDataset(encodings[\"input_ids\"], encodings[\"attention_mask\"], torch.tensor(labels.values))\n",
    "    loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-5)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, reviews, targets, tokenizer):\n",
    "        self.reviews = reviews\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.reviews)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        review = str(self.reviews[idx])\n",
    "        target = self.targets[idx]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            review,\n",
    "            add_special_tokens=True,\n",
    "            # max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'text': review,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(target, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ReviewDataset(\n",
    "    reviews=train_data['text'].to_numpy(),\n",
    "    targets=train_data['label'].to_numpy(),\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "test_dataset = ReviewDataset(\n",
    "    reviews=val_data['text'].to_numpy(),\n",
    "    targets=val_data['label'].to_numpy(),\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/SSNE-Pawel/.venv/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "output_dir = f\"./results_{now}\"\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../models/results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    save_strategy=\"epoch\",\n",
    "    \n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tradycyjne podejÅ›cie bez walidacji krzyzowej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='13830' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   28/13830 00:03 < 26:53, 8.55 it/s, Epoch 0.03/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[128], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/transformers/trainer.py:1885\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1883\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1884\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1885\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/transformers/trainer.py:2178\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2175\u001b[0m     rng_to_sync \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2177\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 2178\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(epoch_iterator):\n\u001b[1;32m   2179\u001b[0m     total_batched_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2181\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39minclude_num_input_tokens_seen:\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/accelerate/data_loader.py:464\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    463\u001b[0m     current_batch \u001b[38;5;241m=\u001b[39m send_to_device(current_batch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_non_blocking)\n\u001b[0;32m--> 464\u001b[0m next_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_batches:\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m current_batch\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[125], line 15\u001b[0m, in \u001b[0;36mReviewDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     12\u001b[0m review \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreviews[idx])\n\u001b[1;32m     13\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets[idx]\n\u001b[0;32m---> 15\u001b[0m encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreview\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# max_length=self.max_len,\u001b[39;49;00m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax_length\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     24\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m: review,\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m: encoding[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mflatten(),\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m: encoding[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mflatten(),\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m: torch\u001b[38;5;241m.\u001b[39mtensor(target, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m     31\u001b[0m }\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3062\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   3052\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   3053\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   3054\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m   3055\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3059\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3060\u001b[0m )\n\u001b[0;32m-> 3062\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3063\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3064\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3065\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3066\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3069\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3070\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3071\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3072\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3073\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3074\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3075\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3076\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3077\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3080\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3081\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/transformers/models/roberta/tokenization_roberta_fast.py:234\u001b[0m, in \u001b[0;36mRobertaTokenizerFast._encode_plus\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    227\u001b[0m is_split_into_words \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_split_into_words\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_prefix_space \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_split_into_words, (\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou need to instantiate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with add_prefix_space=True \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto use it with pretokenized inputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m )\n\u001b[0;32m--> 234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode_plus\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py:583\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_encode_plus\u001b[39m(\n\u001b[1;32m    562\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    563\u001b[0m     text: Union[TextInput, PreTokenizedInput],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    581\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BatchEncoding:\n\u001b[1;32m    582\u001b[0m     batched_input \u001b[38;5;241m=\u001b[39m [(text, text_pair)] \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;28;01melse\u001b[39;00m [text]\n\u001b[0;32m--> 583\u001b[0m     batched_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatched_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m     \u001b[38;5;66;03m# Return tensor is None, then we can remove the leading batch axis\u001b[39;00m\n\u001b[1;32m    604\u001b[0m     \u001b[38;5;66;03m# Overflowing tokens are returned as a batch of output so we keep them in this case\u001b[39;00m\n\u001b[1;32m    605\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m return_tensors \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_overflowing_tokens:\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/transformers/models/roberta/tokenization_roberta_fast.py:224\u001b[0m, in \u001b[0;36mRobertaTokenizerFast._batch_encode_plus\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m is_split_into_words \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_split_into_words\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_prefix_space \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_split_into_words, (\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou need to instantiate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with add_prefix_space=True \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto use it with pretokenized inputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    222\u001b[0m )\n\u001b[0;32m--> 224\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py:559\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m input_ids \u001b[38;5;129;01min\u001b[39;00m sanitized_tokens[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    558\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eventual_warn_about_too_long_sequence(input_ids, max_length, verbose)\n\u001b[0;32m--> 559\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBatchEncoding\u001b[49m\u001b[43m(\u001b[49m\u001b[43msanitized_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msanitized_encodings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:224\u001b[0m, in \u001b[0;36mBatchEncoding.__init__\u001b[0;34m(self, data, encoding, tensor_type, prepend_batch_axis, n_sequences)\u001b[0m\n\u001b[1;32m    220\u001b[0m     n_sequences \u001b[38;5;241m=\u001b[39m encoding[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_sequences\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_sequences \u001b[38;5;241m=\u001b[39m n_sequences\n\u001b[0;32m--> 224\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:759\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    756\u001b[0m     value \u001b[38;5;241m=\u001b[39m [value]\n\u001b[1;32m    758\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor(value):\n\u001b[0;32m--> 759\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m \u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    761\u001b[0m     \u001b[38;5;66;03m# Removing this for now in favor of controlling the shape with `prepend_batch_axis`\u001b[39;00m\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;66;03m# # at-least2d\u001b[39;00m\n\u001b[1;32m    763\u001b[0m     \u001b[38;5;66;03m# if tensor.ndim > 2:\u001b[39;00m\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;66;03m#     tensor = tensor.squeeze(0)\u001b[39;00m\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;66;03m# elif tensor.ndim < 2:\u001b[39;00m\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;66;03m#     tensor = tensor[None, :]\u001b[39;00m\n\u001b[1;32m    768\u001b[0m     \u001b[38;5;28mself\u001b[39m[key] \u001b[38;5;241m=\u001b[39m tensor\n",
      "File \u001b[0;32m~/SSNE-Pawel/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:721\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors.<locals>.as_tensor\u001b[0;34m(value, dtype)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value[\u001b[38;5;241m0\u001b[39m], np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m    720\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(np\u001b[38;5;241m.\u001b[39marray(value))\n\u001b[0;32m--> 721\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model ma tendencje do przetrenowywania, wiÄ™c naturalnym krokiem bÄ™dzie dobranie odpowiedniej strategi niwelujÄ…cej przetrenowanie. W naszym przypadku zastosujemy skroÅ›nÄ… walidacje."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Walidacja skroÅ›na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "n_splits = 10\n",
    "kf = KFold(n_splits=n_splits)\n",
    "\n",
    "reviews = train_data['text'].to_numpy()\n",
    "targets = train_data['label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2075' max='2075' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2075/2075 07:54, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.805672</td>\n",
       "      <td>0.647696</td>\n",
       "      <td>0.575965</td>\n",
       "      <td>0.583624</td>\n",
       "      <td>0.578070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.857400</td>\n",
       "      <td>0.782911</td>\n",
       "      <td>0.660569</td>\n",
       "      <td>0.597669</td>\n",
       "      <td>0.615448</td>\n",
       "      <td>0.591337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.712000</td>\n",
       "      <td>0.783300</td>\n",
       "      <td>0.668699</td>\n",
       "      <td>0.592128</td>\n",
       "      <td>0.607585</td>\n",
       "      <td>0.587453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.630900</td>\n",
       "      <td>0.794953</td>\n",
       "      <td>0.668699</td>\n",
       "      <td>0.610219</td>\n",
       "      <td>0.609189</td>\n",
       "      <td>0.611773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.582600</td>\n",
       "      <td>0.805128</td>\n",
       "      <td>0.672087</td>\n",
       "      <td>0.606198</td>\n",
       "      <td>0.612250</td>\n",
       "      <td>0.603020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2075' max='2075' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2075/2075 07:55, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.549952</td>\n",
       "      <td>0.765583</td>\n",
       "      <td>0.711007</td>\n",
       "      <td>0.709899</td>\n",
       "      <td>0.726720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.569500</td>\n",
       "      <td>0.527761</td>\n",
       "      <td>0.772358</td>\n",
       "      <td>0.724946</td>\n",
       "      <td>0.739545</td>\n",
       "      <td>0.714292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.455500</td>\n",
       "      <td>0.534189</td>\n",
       "      <td>0.790650</td>\n",
       "      <td>0.758230</td>\n",
       "      <td>0.765205</td>\n",
       "      <td>0.753987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.388700</td>\n",
       "      <td>0.548305</td>\n",
       "      <td>0.790650</td>\n",
       "      <td>0.760653</td>\n",
       "      <td>0.764960</td>\n",
       "      <td>0.757225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.366600</td>\n",
       "      <td>0.545580</td>\n",
       "      <td>0.789295</td>\n",
       "      <td>0.757801</td>\n",
       "      <td>0.763352</td>\n",
       "      <td>0.752834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2075' max='2075' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2075/2075 07:55, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.348728</td>\n",
       "      <td>0.871186</td>\n",
       "      <td>0.868748</td>\n",
       "      <td>0.878196</td>\n",
       "      <td>0.860574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.483700</td>\n",
       "      <td>0.358215</td>\n",
       "      <td>0.854915</td>\n",
       "      <td>0.849485</td>\n",
       "      <td>0.855168</td>\n",
       "      <td>0.847790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.390300</td>\n",
       "      <td>0.358081</td>\n",
       "      <td>0.869831</td>\n",
       "      <td>0.861023</td>\n",
       "      <td>0.862961</td>\n",
       "      <td>0.860438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.323500</td>\n",
       "      <td>0.354665</td>\n",
       "      <td>0.865085</td>\n",
       "      <td>0.857516</td>\n",
       "      <td>0.864430</td>\n",
       "      <td>0.851218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.258800</td>\n",
       "      <td>0.353827</td>\n",
       "      <td>0.875254</td>\n",
       "      <td>0.871269</td>\n",
       "      <td>0.873888</td>\n",
       "      <td>0.869313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2075' max='2075' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2075/2075 07:55, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.168454</td>\n",
       "      <td>0.943729</td>\n",
       "      <td>0.937055</td>\n",
       "      <td>0.928626</td>\n",
       "      <td>0.946808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.218700</td>\n",
       "      <td>0.139871</td>\n",
       "      <td>0.947119</td>\n",
       "      <td>0.941280</td>\n",
       "      <td>0.945818</td>\n",
       "      <td>0.937376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.176000</td>\n",
       "      <td>0.153678</td>\n",
       "      <td>0.952542</td>\n",
       "      <td>0.950456</td>\n",
       "      <td>0.954535</td>\n",
       "      <td>0.947482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.135700</td>\n",
       "      <td>0.121471</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.956687</td>\n",
       "      <td>0.959991</td>\n",
       "      <td>0.953786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.133000</td>\n",
       "      <td>0.121851</td>\n",
       "      <td>0.960678</td>\n",
       "      <td>0.957756</td>\n",
       "      <td>0.959463</td>\n",
       "      <td>0.956515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2075' max='2075' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2075/2075 07:57, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.104087</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.961966</td>\n",
       "      <td>0.967207</td>\n",
       "      <td>0.959019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.135700</td>\n",
       "      <td>0.051345</td>\n",
       "      <td>0.981017</td>\n",
       "      <td>0.977571</td>\n",
       "      <td>0.979747</td>\n",
       "      <td>0.975800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.106100</td>\n",
       "      <td>0.089372</td>\n",
       "      <td>0.970169</td>\n",
       "      <td>0.973098</td>\n",
       "      <td>0.975023</td>\n",
       "      <td>0.972505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.025264</td>\n",
       "      <td>0.991864</td>\n",
       "      <td>0.994034</td>\n",
       "      <td>0.995522</td>\n",
       "      <td>0.992586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.087600</td>\n",
       "      <td>0.018861</td>\n",
       "      <td>0.993220</td>\n",
       "      <td>0.994773</td>\n",
       "      <td>0.994630</td>\n",
       "      <td>0.994939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2075' max='2075' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2075/2075 07:55, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.094406</td>\n",
       "      <td>0.966102</td>\n",
       "      <td>0.967037</td>\n",
       "      <td>0.972988</td>\n",
       "      <td>0.961675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.118000</td>\n",
       "      <td>0.054872</td>\n",
       "      <td>0.985085</td>\n",
       "      <td>0.985141</td>\n",
       "      <td>0.987223</td>\n",
       "      <td>0.983130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.093300</td>\n",
       "      <td>0.059220</td>\n",
       "      <td>0.983051</td>\n",
       "      <td>0.980229</td>\n",
       "      <td>0.984212</td>\n",
       "      <td>0.976653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.053800</td>\n",
       "      <td>0.043497</td>\n",
       "      <td>0.990508</td>\n",
       "      <td>0.988435</td>\n",
       "      <td>0.987799</td>\n",
       "      <td>0.989184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.059200</td>\n",
       "      <td>0.027694</td>\n",
       "      <td>0.991864</td>\n",
       "      <td>0.991063</td>\n",
       "      <td>0.990718</td>\n",
       "      <td>0.991422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2075' max='2075' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2075/2075 07:55, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.040235</td>\n",
       "      <td>0.987119</td>\n",
       "      <td>0.986318</td>\n",
       "      <td>0.984143</td>\n",
       "      <td>0.988798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.100700</td>\n",
       "      <td>0.052885</td>\n",
       "      <td>0.984407</td>\n",
       "      <td>0.986790</td>\n",
       "      <td>0.983087</td>\n",
       "      <td>0.990841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.071000</td>\n",
       "      <td>0.041052</td>\n",
       "      <td>0.987119</td>\n",
       "      <td>0.985691</td>\n",
       "      <td>0.986089</td>\n",
       "      <td>0.985427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.045600</td>\n",
       "      <td>0.043328</td>\n",
       "      <td>0.988475</td>\n",
       "      <td>0.986680</td>\n",
       "      <td>0.983207</td>\n",
       "      <td>0.990304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.043900</td>\n",
       "      <td>0.017471</td>\n",
       "      <td>0.993898</td>\n",
       "      <td>0.992593</td>\n",
       "      <td>0.991459</td>\n",
       "      <td>0.993845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2075' max='2075' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2075/2075 07:55, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.045160</td>\n",
       "      <td>0.987119</td>\n",
       "      <td>0.983594</td>\n",
       "      <td>0.982828</td>\n",
       "      <td>0.984477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.115500</td>\n",
       "      <td>0.031962</td>\n",
       "      <td>0.988475</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.989094</td>\n",
       "      <td>0.991567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.053600</td>\n",
       "      <td>0.019188</td>\n",
       "      <td>0.993898</td>\n",
       "      <td>0.992187</td>\n",
       "      <td>0.993361</td>\n",
       "      <td>0.991165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.035300</td>\n",
       "      <td>0.011188</td>\n",
       "      <td>0.996610</td>\n",
       "      <td>0.994610</td>\n",
       "      <td>0.994610</td>\n",
       "      <td>0.994610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.035200</td>\n",
       "      <td>0.008845</td>\n",
       "      <td>0.997288</td>\n",
       "      <td>0.996257</td>\n",
       "      <td>0.996502</td>\n",
       "      <td>0.996029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2075' max='2075' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2075/2075 07:55, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.068416</td>\n",
       "      <td>0.981695</td>\n",
       "      <td>0.983625</td>\n",
       "      <td>0.985628</td>\n",
       "      <td>0.982069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.098300</td>\n",
       "      <td>0.032772</td>\n",
       "      <td>0.992542</td>\n",
       "      <td>0.992375</td>\n",
       "      <td>0.991132</td>\n",
       "      <td>0.993663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.048200</td>\n",
       "      <td>0.027192</td>\n",
       "      <td>0.993220</td>\n",
       "      <td>0.991858</td>\n",
       "      <td>0.991038</td>\n",
       "      <td>0.992739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.035100</td>\n",
       "      <td>0.023014</td>\n",
       "      <td>0.995932</td>\n",
       "      <td>0.995988</td>\n",
       "      <td>0.996020</td>\n",
       "      <td>0.995977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.026800</td>\n",
       "      <td>0.018810</td>\n",
       "      <td>0.996610</td>\n",
       "      <td>0.997623</td>\n",
       "      <td>0.997838</td>\n",
       "      <td>0.997416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2075' max='2075' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2075/2075 07:55, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.071473</td>\n",
       "      <td>0.980339</td>\n",
       "      <td>0.977182</td>\n",
       "      <td>0.976756</td>\n",
       "      <td>0.977951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>0.038516</td>\n",
       "      <td>0.986441</td>\n",
       "      <td>0.987414</td>\n",
       "      <td>0.990691</td>\n",
       "      <td>0.984470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.056200</td>\n",
       "      <td>0.017780</td>\n",
       "      <td>0.993898</td>\n",
       "      <td>0.995108</td>\n",
       "      <td>0.994280</td>\n",
       "      <td>0.995956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>0.008918</td>\n",
       "      <td>0.997288</td>\n",
       "      <td>0.997114</td>\n",
       "      <td>0.997067</td>\n",
       "      <td>0.997184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>0.006926</td>\n",
       "      <td>0.997966</td>\n",
       "      <td>0.996156</td>\n",
       "      <td>0.995585</td>\n",
       "      <td>0.996789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for train_index, val_index in kf.split(reviews):\n",
    "    train_reviews, val_reviews = reviews[train_index], reviews[val_index]\n",
    "    train_targets, val_targets = targets[train_index], targets[val_index]\n",
    "\n",
    "    train_dataset = ReviewDataset(train_reviews, train_targets, tokenizer, 128)\n",
    "    val_dataset = ReviewDataset(val_reviews, val_targets, tokenizer, 128)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 1/47 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = trainer.predict(val_dataset)\n",
    "predictions_argmax = torch.argmax(torch.tensor(predictions.predictions), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 1/52 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = trainer.predict(test_dataset)\n",
    "predictions_argmax = torch.argmax(torch.tensor(predictions.predictions), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfsAAAGwCAYAAACuFMx9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAABVtklEQVR4nO3deVhU9f4H8PcwwAwDzMgiIALuGymSaEqZWyap1zS9dSsyNLObobln3tzN8FqZmWtlopWpLVaaqWSJmrihmCu5oKBsKsuwM8v5/UFOd36iMg5wZua8X89znsfzPd9z5jOjzme+2zkyQRAEEBERkcNyEjsAIiIiqltM9kRERA6OyZ6IiMjBMdkTERE5OCZ7IiIiB8dkT0RE5OCY7ImIiBycs9gBWMNoNCIzMxOenp6QyWRih0NERBYSBAFFRUUIDAyEk1PdtT/Ly8tRWVlp9XVcXV2hVCprIaL6ZdfJPjMzE8HBwWKHQUREVsrIyEBQUFCdXLu8vBzNmnggO9dg9bUCAgKQlpZmdwnfrpO9p6cnAKBHm9fhLFeIHI1tk93IFzsEu2C4fkPsEOwDb7xJtUQPHfZju+n7vC5UVlYiO9eAK8lNofa8/94DbZERTSIuo7Kyksm+Pt3quneWK5js70Hm5Cp2CHZBJnMROwQ7wWRPteSvf0r1MRTr4SmDh+f9v44R9jtcbNfJnoiIqKYMghEGK36nGgRj7QVTz5jsiYhIEowQYLSiV8qac8XGpXdEREQOji17IiKSBCOMsKYj3rqzxcVkT0REkmAQBBisWElizbliYzc+ERGRg2PLnoiIJEHKE/SY7ImISBKMEGCQaLJnNz4REZGDY8ueiIgkgd34REREDo6z8YmIiMhhsWVPRESSYPxrs+Z8e8VkT0REkmCwcja+NeeKjcmeiIgkwSDAyqfe1V4s9Y1j9kRERA6OLXsiIpIEjtkTERE5OCNkMEBm1fn2it34REREDo4teyIikgSjULVZc769YrInIiJJMFjZjW/NuWJjNz4REZGDY8ueiIgkQcoteyZ7IiKSBKMgg1GwYja+FeeKjd34REREDo4teyIikgR24xMRETk4A5xgsKJD21CLsdQ3JnsiIpIEwcoxe4Fj9kRERGSr2LK/D/Hrt8I/oPS28q0/tsT6de0xfPgpdIrIQUO/UhQWKpB0oDHWx7dHaamrCNGKZ8DTGRj4z6vwDywDAFy55IGvPm6Oo7/7AgAWfnIUYZ3zzc7Z/k1jLFsQWu+x2rJnYnMw6j9Z2PKpL1bNDhI7HJszaMQN/HNMLrwb6nHpjBtWzGiM1BSV2GHZlPZdi/H0a9fRqkMpfAL0mPNSUyTt0IgdVr2T8pi9TbTsly9fjqZNm0KpVKJr1644fPiw2CHd1fhxj+P5fz1p2qZP6wkA2Lc3GD4+ZfD2Kcenn3TEmFeewOL3HkJE5yxMnHxE5Kjr340cJdZ+1BKvR3fF+OiuOHHYGzM/SEFI82JTnZ+/bYzovj1M25olrUWM2Pa07liKgS/cxKUzSrFDsUk9n8zHK7Mz8eXiAMRGtcalM0os2HAJGh+d2KHZFKXKiEunlVj2H2n/WDQITlZvlpgzZw5kMpnZ1rZtW9Px8vJyxMbGwsfHBx4eHhg2bBhycnLMrpGeno6BAwdCpVLBz88PU6dOhV6vt/i9i57sN23ahEmTJmH27Nk4duwYOnbsiKioKOTm5ood2h0VFiqRn+9m2rp2zUTmNQ+c/KMhrlxugAXzH8Ghg42RleWBEyn+WLc2DF27ZsLJyZ4fkGi5w3sb4uj+hshMd8e1dHesX94S5aVytA0rNNWpKJcj/6bCtJWVsLPpFqXKgGnLrmDJG8EoKpCLHY5NGvrKDezY4I1dm7yRfl6JpdOCUFEmQ9RzeWKHZlOO/qbGukWNcECCrXmxPfDAA8jKyjJt+/fvNx2bOHEitm7diq+//hqJiYnIzMzE0KFDTccNBgMGDhyIyspKHDhwAOvWrUN8fDxmzZplcRyiJ/vFixdj9OjRGDlyJEJDQ7Fq1SqoVCp89tlnYodWI87OBvR+7Ap27WwG3KGLx929EqWlLjAaRf+4RePkJKBHVDaUbgac/ePvL5zeA7Lw1a97sOLrAxgx7jwUSnue71q7xr5zFYd3q3F8n6fYodgkZxcjWoWV4tj/fD6CIMPxfZ4Ijbh9mI3ICBmMcLJis7wb39nZGQEBAabN17dqGLOwsBBr1qzB4sWL0adPH0RERGDt2rU4cOAADh48CADYtWsXzpw5gy+++ALh4eHo378/5s+fj+XLl6OystKyOCyOvBZVVlYiOTkZ06dPN5U5OTmhb9++SEpKuq1+RUUFKioqTPtarbZe4rybyIevwcNDh4Rdzao9rlZX4LnoM/h5e/N6jsw2NG1ZhPfXHYGrqxFlZXLMn9wRGZc8AAB7fg5AbpYSedcVaNqqGC+NP4/GTUqxYEpHkaMWX88n89GyfRnGDeSwxp2ovQ2QOwMF182/xvJvOCO4ZcUdziIpq60x+/+fexQKBRQKRbXnnD9/HoGBgVAqlYiMjERcXBxCQkKQnJwMnU6Hvn37muq2bdsWISEhSEpKQrdu3ZCUlIQOHTrA39/fVCcqKgpjxozB6dOn8eCDD9Y4dlGbmjdu3IDBYDB7IwDg7++P7Ozs2+rHxcVBo9GYtuDg4PoK9Y6inkjD0SONkJfndtsxlUqHuW/vRXq6Gl983l6E6MR39bI7xj7bDRNffAjbvw7C5HmnEfzXmP2O74JwLMkXly94Ys/PjfD+zPZ45LFcBARJu1XWMLASY+Zdw3/HNYGuQrq9QUS2Kjg42CwXxcXFVVuva9euiI+Px44dO7By5UqkpaXh0UcfRVFREbKzs+Hq6ooGDRqYnfO/+S87O7va/HjrmCXsaoB0+vTpmDRpkmlfq9WKmvD9/EoQ/mAO3p73yG3H3Nx0mL8gEWWlLpg/pzsMBml+aev1TsjKqJoZfeGsGq0e0GLwc+nVzrg/d7Kqez8wuBTZV6U7m7plh1J4NdRj+Y5UU5ncGejQrQRPjriBfzTrCKPRfmcF1xZtnhwGPdCgoflkJS9fPfKv29VXG9WT+5lkZ35+1QPtMzIyoFarTeV3atX379/f9OewsDB07doVTZo0webNm+HmdnsDsS6J+j/C19cXcrn8ttmHOTk5CAgIuK3+3bpKxPB4VBoKCxQ4fKiRWblKpcPb7yRCp3PC3NndodNxctUtTjIBLq7VT1Rs0aYIAJB3w3b+jsWQst8Tr/RpY1Y2eXE6Mi4qsXm5HxP9X/Q6J5z/Q4UHuxeZlpHJZALCuxfjx3gfkaMjW1Q1Zm/Fg3D+OletVpsl+5pq0KABWrdujQsXLuDxxx9HZWUlCgoKzFr3/5v/AgICbludditfVpcj70bU5qarqysiIiKwe/duU5nRaMTu3bsRGRkpYmT3JpMJeLxfGn5JaGo28U6l0mFB3B4olXosWfwQVCodvLzK4OVVJrnZ+CPGnUf7Tvnwa1SGpi2LMGLceXTonI892xshIKgUz42+hJbttPBrVIauPXMxef4pnExugMvnpT0hraxEjiupbmZbeakTivKryulv333si/7P56Hv03kIblmOcQuvQqkyYtdGb7FDsylKlQHNHyhD8weq7nkREFyJ5g+UoWFjyyZ5kXWKi4tx8eJFNGrUCBEREXBxcTHLf6mpqUhPTzflv8jISJw8edJsdVpCQgLUajVCQy27H4nofV2TJk1CTEwMOnfujIceeghLlixBSUkJRo4cKXZod/Vgpxz4+5di107ziXctWuajbbuqZT+frfvJ7FjM8H8gN8e93mIUm8a7EpPnn4K3bwVKip2Rdt4TM1/rhOOHfODrX47wrjcx+Pl0KN0MuJ6jwO+7/fDVp9KcyEj3J/FHL2h8DHhxaja8Gupx6bQb3opuhoIbLmKHZlNadyzDu99eNO2/OjcTALBrkxfenxgiVlj1zmjlvfGNECyqP2XKFAwaNAhNmjRBZmYmZs+eDblcjueeew4ajQajRo3CpEmT4O3tDbVajXHjxiEyMhLdunUDAPTr1w+hoaEYPnw4Fi1ahOzsbMyYMQOxsbEW93LLBEGwLPo6sGzZMrz77rvIzs5GeHg4li5diq5du97zPK1WC41Ggz6hU+Esl3bX773IrnPdcU0Ycq+LHYJ9EP9rgxyEXtBhD35AYWHhfXWN18StXLExJRQqz/sfVi0tMuDZ8DM1jvXZZ5/F3r17cfPmTTRs2BDdu3fHggUL0KJFCwBVN9WZPHkyvvrqK1RUVCAqKgorVqww66K/cuUKxowZgz179sDd3R0xMTFYuHAhnJ0ta6vbRLK/X0z2NcdkXzNM9jVkv18bZGPqM9lvSGlvdbJ/PvxUncZaV6Q5RZyIiEhCRB+zJyIiqg8GQQaDFY+pteZcsTHZExGRJBisnKBnsHCCni1hNz4REZGDY8ueiIgkwSg4wWjFHfSMdjwxlcmeiIgkgd34RERE5LDYsiciIkkwwroZ9fZ8w3MmeyIikgQjnGC06na59tsZbr+RExERUY2wZU9ERJJg/fPs7bd9zGRPRESSUFvPs7dHTPZERCQJUm7Z22/kREREVCNs2RMRkSRYf1Md+20fM9kTEZEkGAUZjNass7fjp97Z788UIiIiqhG27ImISBKMVnbj2/NNdZjsiYhIEqx/6p39Jnv7jZyIiIhqhC17IiKSBANkMFhxYxxrzhUbkz0REUkCu/GJiIjIYbFlT0REkmCAdV3xhtoLpd4x2RMRkSRIuRufyZ6IiCSBD8IhIiIih8WWPRERSYJg5fPsBS69IyIism3sxiciIiKH5Rgt+8sZgMxV7ChsmtA8ROwQ7ILcYM+La+qPsbBI7BDsgqCrFDsE+h9SfsStYyR7IiKiezBY+dQ7a84Vm/1GTkRERDXClj0REUkCu/GJiIgcnBFOMFrRoW3NuWKz38iJiIioRtiyJyIiSTAIMhis6Iq35lyxMdkTEZEkcMyeiIjIwQlWPvVO4B30iIiIyFaxZU9ERJJggAwGKx5mY825YmOyJyIiSTAK1o27G4VaDKaesRufiIjIwbFlT0REkmC0coKeNeeKjcmeiIgkwQgZjFaMu1tzrtjs92cKERER1Qhb9kREJAm8gx4REZGDk/KYvf1GTkRERDXClj0REUmCEVbeG9+OJ+gx2RMRkSQIVs7GF5jsiYiIbJuUn3rHMXsiIiIHx5Y9ERFJgpRn4zPZExGRJLAbn4iIiBwWkz0REUnCrXvjW7Pdr4ULF0Imk2HChAmmsvLycsTGxsLHxwceHh4YNmwYcnJyzM5LT0/HwIEDoVKp4Ofnh6lTp0Kv11v8+kz2REQkCbe68a3Z7seRI0ewevVqhIWFmZVPnDgRW7duxddff43ExERkZmZi6NChpuMGgwEDBw5EZWUlDhw4gHXr1iE+Ph6zZs2yOAYmeyIiIgtotVqzraKi4o51i4uLER0djU8++QReXl6m8sLCQqxZswaLFy9Gnz59EBERgbVr1+LAgQM4ePAgAGDXrl04c+YMvvjiC4SHh6N///6YP38+li9fjsrKSotiZrInIiJJqK2WfXBwMDQajWmLi4u742vGxsZi4MCB6Nu3r1l5cnIydDqdWXnbtm0REhKCpKQkAEBSUhI6dOgAf39/U52oqChotVqcPn3aovfO2fhERCQJtTUbPyMjA2q12lSuUCiqrb9x40YcO3YMR44cue1YdnY2XF1d0aBBA7Nyf39/ZGdnm+r8b6K/dfzWMUsw2RMREVlArVabJfvqZGRkYPz48UhISIBSqaynyO6Myf4+te+ixT9HZ6LlA8Xw8ddh3qttkPSLt1md4BaleOmNdHR4SAu5XED6BTe8HdsG17Oq/xXoaOLXb4V/QOlt5Vt/bIkVyyIwbvwRPPhgDrx9ylFe5owzZ3zw2ZqOuJpx9/9EjmbAM1cx8Jlr8A8sBwBcueiOr1Y3w9H9PgCAJ4ZdQ68BOWjZrggqDwOefuRRlBS5iBmyzXBzN+DFydfwcFQ+GvjqcPG0CqvmhODPPzzEDs3mDBpxA/8ckwvvhnpcOuOGFTMaIzVFJXZY9ao+19knJycjNzcXnTp1MpUZDAbs3bsXy5Ytw86dO1FZWYmCggKz1n1OTg4CAgIAAAEBATh8+LDZdW/N1r9Vp6ZEHbPfu3cvBg0ahMDAQMhkMnz//fdihmMRpZsBl86qsGJOs2qPNwopx3sbTyPjohumRT+A1/7RERuWB6GyQjrTJMaPexzP/+tJ0zZ9Wk8AwL69wQCAC+e9sfj9h/DKy/3x1n96QCYDFsQlwsnJKGbY9e5GjhJrl7TA6892wfjnuuDEYS/M/PAPhLQoBgAo3IxI/t0bmz5tInKktmfCf9PQ6dFCvDuxOV7t1x7H9moQ9+Wf8PG3bPKSo+v5ZD5emZ2JLxcHIDaqNS6dUWLBhkvQ+OjEDq1eCbBu+Z1gwWs99thjOHnyJFJSUkxb586dER0dbfqzi4sLdu/ebTonNTUV6enpiIyMBABERkbi5MmTyM3NNdVJSEiAWq1GaGioRe9d1JZ9SUkJOnbsiJdeeslsuYE9OLrXC0f3et3xeMykdBxJbIDPFv39BZ2VLn5XTn0qLDR/v8/86ywyr3ng5B8NAQA/b29hOpab44518R2wcvVO+PuXIitLOi2zw4m+ZvvrP2qBgc9cQ9swLdIveuCHL6p+HHXonC9GeDbLVWFE9/75mDu6FU4d9gQAfLGkMbr2LcA/hudi3XtBIkdoO4a+cgM7Nnhj16aq3sel04Lw0GNaRD2Xh83L/O9xtuOoz5a9p6cn2rdvb1bm7u4OHx8fU/moUaMwadIkeHt7Q61WY9y4cYiMjES3bt0AAP369UNoaCiGDx+ORYsWITs7GzNmzEBsbOwd5wnciajJvn///ujfv7+YIdQJmUxAl175+OaTxnh77Rm0CC1BdoYSm1c1vq2rXyqcnQ3o/dgVbPm2DVDNjSkUSj36RaUhK8sd16+71X+ANsLJSUD3frlQuhlw9oRG7HBsmtxZgNwZt/WWVZY74YHOxSJFZXucXYxoFVaKjcv8TGWCIMPxfZ4Ijbh9mI3qzwcffAAnJycMGzYMFRUViIqKwooVK0zH5XI5tm3bhjFjxiAyMhLu7u6IiYnBvHnzLH4tuxqzr6ioMFvPqNVqRYzmzhr46KDyMOKZf1/Dug+C8dmiJojoUYAZK1Lx5guhOHlYel/ikQ9fg4eHDgm7zIc9Bg46j1Ev/wE3Nz0yMjzx1pu9oNfLRYpSPE1bFeP9z5Ph6mpEWakc8yd0QMYld7HDsmllJXKcSXbH8+MykX5eiYIbLug1+CbadipG1mVp9aLdjdrbALkzUHDd/Os+/4YzglveeX24IxL73vh79uwx21cqlVi+fDmWL19+x3OaNGmC7du3W/W6gJ2ts4+LizNb2xgcHCx2SNWS/fWpJv3ihe/XBuLSWXd8vboxDv/mhQHP5dz9ZAcV9UQajh5phLw881b7b7ubYOyYfpg6uTeuXfXE9BkH4OJiEClK8VxNU2Hs010wMToC2zc3xuS3zyK4eYnYYdm8dyc0B2TAhiMnsPX8UQwekYvEH71htGRwlSRDrDvo2QK7SvbTp09HYWGhacvIyBA7pGpp852h18mQfsF8pmvGBTc0DJTexCE/vxKEP5iDHT83v+1YaakrMjM9ceqkHxbMfxjBwVo8/MhVEaIUl17vhKwMFS6cVSN+aQtc+tMDg6Nt89+3LclKV+KNf7XF4LadMDyyI8YPDoXcWUB2ujRWvNSENk8Ogx5o0ND8fupevnrkX7erzl2ygl0le4VCYVrfWJN1jmLR65zw50l3BDUvMytv3KwMuddcRYpKPI9HpaGwQIHDhxrdtZ7srx/NLi7Smo1fHScnAS6u/BxqqqJMjrxcV3io9YjooUXSrgZih2Qz9DonnP9DhQe7F5nKZDIB4d2LcSZZmkvvpNiy58+6+6RUGRDYpNy07x9cjubtSlBU4IzrWQp8+0kg3vzwPE4dUePEQTU69yhA1z75mBb9gIhR1z+ZTMDj/dLwS0JTGI1//7YMCChGj17pOJYcgMICBXwbluGZf51FZaUcR47c/UeBoxnx+kUc/d0buVlKqNwN6NU/Bx06F2Dmq+EAAC+fCnj5ViIwpOrHY9NWJSgrkSM3S4lirbTX20f0KARkwNVLSgQ2KcfL/8lAxkUldn3te++TJeS7j30xZUkG/jyhQupxFZ4afR1KlRG7NkprwrAgyCBYkbCtOVdsoib74uJiXLhwwbSflpaGlJQUeHt7IyQkRMTI7q1Vh2Is+vKMaf/fb10BACR82xCLp7XEgQQfLJtlwDOvXsOrM9Nw9ZIb3h7bBqeTbbM3oq482CkH/v6l2LXTvAu/slKO9u1vYMhTf8LDQ4eCAgVOnWyISRMeQ2GBtCZXabwrMfnts/BuWIGSYmek/emBma+G4/jBqi/iAc9cQ/SYy6b678YfAwAsntEOv/worR9G/5/K04CR067CN6ASxYXO2P+zF+LfbQyD3q46Letc4o9e0PgY8OLUbHg11OPSaTe8Fd0MBTek/WNRSmSCIIg2lWXPnj3o3bv3beUxMTGIj4+/5/larRYajQZ9VM/CWSa97nGLNLftH0+2QpZ9XewQ7IKxsOjelQiCTnpzdCylF3TYgx9QWFhYZ0Ozt3JF5A/j4Ox+//M59CUVSBr8UZ3GWldEbdn36tULIv7WICIiCRF76Z2Y2NdFRETk4DhBj4iIJIET9IiIiByclLvxmeyJiEgSpNyy55g9ERGRg2PLnoiIJEGwshvfnlv2TPZERCQJAgBrVnvb80JxduMTERE5OLbsiYhIEoyQQQYrZuNbca7YmOyJiEgSOBufiIiIHBZb9kREJAlGQQYZb6pDRETkuATBytn4djwdn934REREDo4teyIikgQpT9BjsiciIklgsiciInJwUp6gxzF7IiIiB8eWPRERSYKUZ+Mz2RMRkSRUJXtrxuxrMZh6xm58IiIiB8eWPRERSQJn4xMRETk4AdY9k96Oe/HZjU9EROTo2LInIiJJYDc+ERGRo5NwPz6TPRERSYOVLXvYccueY/ZEREQOji17IiKSBN5Bj4iIyMFxgp6dM5aVwygziB2GTZNnXxc7BLtgaB4odgh2QZ5XLHYIdsFwIU3sEIgAOEiyJyIiuidBZt0kO7bsiYiIbJuUx+w5G5+IiMjBsWVPRETSwJvqEBEROTbOxr+HH3/8scYXfPLJJ+87GCIiIqp9NUr2Q4YMqdHFZDIZDAYugSMiIhtlx13x1qhRsjcajXUdBxERUZ2Scje+VbPxy8vLaysOIiKiuiXUwmanLE72BoMB8+fPR+PGjeHh4YFLly4BAGbOnIk1a9bUeoBERERkHYuT/YIFCxAfH49FixbB1dXVVN6+fXt8+umntRocERFR7ZHVwmafLE7269evx8cff4zo6GjI5XJTeceOHXHu3LlaDY6IiKjWsBu/5q5du4aWLVveVm40GqHT6WolKCIiIqo9Fif70NBQ7Nu377byb775Bg8++GCtBEVERFTrJNyyt/gOerNmzUJMTAyuXbsGo9GI7777DqmpqVi/fj22bdtWFzESERFZT8JPvbO4ZT948GBs3boVv/zyC9zd3TFr1iycPXsWW7duxeOPP14XMRIREZEV7uve+I8++igSEhJqOxYiIqI6w0fc3oejR4/i888/x+eff47k5OTajImIiKj21fOY/cqVKxEWFga1Wg21Wo3IyEj8/PPPpuPl5eWIjY2Fj48PPDw8MGzYMOTk5JhdIz09HQMHDoRKpYKfnx+mTp0KvV5v8Vu3uGV/9epVPPfcc/j999/RoEEDAEBBQQEefvhhbNy4EUFBQRYHQURE5GiCgoKwcOFCtGrVCoIgYN26dRg8eDCOHz+OBx54ABMnTsRPP/2Er7/+GhqNBmPHjsXQoUPx+++/A6i6id3AgQMREBCAAwcOICsrCy+++CJcXFzwzjvvWBSLxS37l19+GTqdDmfPnkVeXh7y8vJw9uxZGI1GvPzyy5ZejoiIqH7cmqBnzWaBQYMGYcCAAWjVqhVat26NBQsWwMPDAwcPHkRhYSHWrFmDxYsXo0+fPoiIiMDatWtx4MABHDx4EACwa9cunDlzBl988QXCw8PRv39/zJ8/H8uXL0dlZaVFsVic7BMTE7Fy5Uq0adPGVNamTRt89NFH2Lt3r6WXIyIiqhcywfoNALRardlWUVFxz9c2GAzYuHEjSkpKEBkZieTkZOh0OvTt29dUp23btggJCUFSUhIAICkpCR06dIC/v7+pTlRUFLRaLU6fPm3Re7c42QcHB1d78xyDwYDAwEBLL0dERFQ/amnMPjg4GBqNxrTFxcXd8SVPnjwJDw8PKBQKvPrqq9iyZQtCQ0ORnZ0NV1dX03D4Lf7+/sjOzgYAZGdnmyX6W8dvHbOExWP27777LsaNG4fly5ejc+fOAKom640fPx7vvfeepZcjIiKyKxkZGVCr1aZ9hUJxx7pt2rRBSkoKCgsL8c033yAmJgaJiYn1EaaZGiV7Ly8vyGR/j1WUlJSga9eucHauOl2v18PZ2RkvvfQShgwZUieBEhERWaWWbqpza3Z9Tbi6uppuMR8REYEjR47gww8/xL/+9S9UVlaioKDArHWfk5ODgIAAAEBAQAAOHz5sdr1bs/Vv1ampGiX7JUuWWHRRIiIim2PtLW9rYZ290WhERUUFIiIi4OLigt27d2PYsGEAgNTUVKSnpyMyMhIAEBkZiQULFiA3Nxd+fn4AgISEBKjVaoSGhlr0ujVK9jExMRZdlIiISOqmT5+O/v37IyQkBEVFRdiwYQP27NmDnTt3QqPRYNSoUZg0aRK8vb2hVqsxbtw4REZGolu3bgCAfv36ITQ0FMOHD8eiRYuQnZ2NGTNmIDY29q5DB9W5rzvo3VJeXn7b9P+adm0QERHVq3pu2efm5uLFF19EVlYWNBoNwsLCsHPnTtOt5T/44AM4OTlh2LBhqKioQFRUFFasWGE6Xy6XY9u2bRgzZgwiIyPh7u6OmJgYzJs3z+LQLU72JSUlmDZtGjZv3oybN2/edtxgMFgcBBERUZ2r52S/Zs2aux5XKpVYvnw5li9ffsc6TZo0wfbt2y174WpYvPTujTfewK+//oqVK1dCoVDg008/xdy5cxEYGIj169dbHRARERHVLotb9lu3bsX69evRq1cvjBw5Eo8++ihatmyJJk2a4Msvv0R0dHRdxElERGQdPuK25vLy8tC8eXMAVePzeXl5AIDu3bvzDnpERGSzausOevbI4pZ98+bNkZaWhpCQELRt2xabN2/GQw89hK1bt952JyAp+ceLNzBw+A34B1dNWLzypxJffhCAo79Jd8LigGeuYuAz1+AfWA4AuHLRHV+tboaj+33godbhhdfS0OnhPDQMKEdhvguSfm2Iz5c3R2mxVfNG7ZKbUoeY6BN4uGsGGmjKcTHNCys/7Yw/L/gCAB7plo6BT5xHq+Y3oVZXYszEAbiU5i1y1PUreuRZRI9MNSvLuOKBfw+vut2ol3c5Ro05hfDO16FS6XE1wwObPm+N3xMbixGuzRk04gb+OSYX3g31uHTGDStmNEZqikrssKieWPytOnLkSJw4cQI9e/bEm2++iUGDBmHZsmXQ6XRYvHixRdeKi4vDd999h3PnzsHNzQ0PP/ww/vvf/5rdd99eXM9ywWdxgbiWpoBMJuDxp/Mx57M0xEa1xpU/3cQOTxQ3cpRYu6QFMtNVkMmAx57MwswP/8C4Z7pAJgN8/Crw6fstkX5RBf/AcoydkQofvwq8M7mD2KHXu4ljD6JpSAEWLXkYeXkq9Ol1CQvn7sbocYNwM08FpVKP02caYu/+EEwce0jscEVz+ZIn3pr0iGnfYPi7W3XyW8lw99Bh3n+6QVvgil6PX8Wbc45g/CvuuHS+gQjR2o6eT+bjldmZ+OjNIJw7psJTo69jwYZLGPVoGxTedBE7vPpjA+vsxWJxsp84caLpz3379sW5c+eQnJyMli1bIiwszKJrJSYmIjY2Fl26dIFer8d//vMf9OvXD2fOnIG7u7uloYnqUILGbD/+v43wj+E30LZTqWST/eFEX7P99R+1wMBnrqFtmBa7tgRiwaS/k3r2VRXWfdQCU+NOw0luhNFg8QiT3XJ11aN7ZDrmvNMTp85U3ff6i40d0a3LNfzjiT+xbkM4du+pGjrz9ysWM1TRGQwy5Ocpqz3W7oE8LF/cEX+e9QIAbFzfBkOevoBWrQskn+yHvnIDOzZ4Y9emqt6gpdOC8NBjWkQ9l4fNy/zvcTY5Aqv7S5s0aYImTZrc17k7duww24+Pj4efnx+Sk5PRo0cPa0MTjZOTgEf/UQCFyoizyfb1o6WuODkJ6N4vF0o3A86e0FRbx91Tj9JiZ0klegCQOwmQywVU6uRm5RUVcjwQmitSVLapcVAJPv9uByornXDutDfiV4fiem5VV/TZ097o0ecaDicFoKTYBY/2vgZXVyP+SPG9x1Udm7OLEa3CSrFxmZ+pTBBkOL7PE6ERpSJGVv9ksG7c3X6n59Uw2S9durTGF3z99dfvO5jCwkIAgLd39WORFRUVZo8S1Gq19/1adaFp2zIs+fE8XBVGlJU4Yd7LzZB+vvpWiFQ0bVWM9z9PhqurEWWlcsyf0AEZl27/AaRuUInnXknDz99K78mJZeUuOHPOF88/cxLpGRoUFCrR69HLaNfmBjKzPcQOz2aknvHG4rhOuJruAW+fcjw/MhXvLtuHMTF9UFbmgrjZXfDmnKPY/NN26PUyVJTLMX9GV2Rdk/ZnqPY2QO4MFFw3/7rPv+GM4Jb3fjQrOYYaJfsPPvigRheTyWT3neyNRiMmTJiARx55BO3bt6+2TlxcHObOnXtf168PVy8q8Fq/NlB5GvDowAJMWXIFU4e1knTCv5qmwtinu8DdQ4/uj1/H5LfP4o2XOpklfDd3PeYu/wPpl9zx5cpmIkYrnkVLHsGksUn4au13MBhkuHDRG3v2NUGrFnlih2Yzjh76u7v58iUNUs96IX7zLjza5xp2/dQUw0edhYeHDtMnPAJtoSsiH83C9DmH8ca4R3H5UvW9SSQxEl56V6Nkn5aWVtdxIDY2FqdOncL+/fvvWGf69OmYNGmSaV+r1SI4OLjOY6spvc4JmZer7ld84aQKbcJLMeTl61g6zXZirG96vROyMqq6WS+cVaNVey0GR2dg2fy2AAA3lR7zV6agtKSq1W/QS6sL/5asbE9MndEPCoUe7qpK5OWr8J8p+5CVI+1W6d2UFLviWoYHAhuXICCwBE8OS8OrL/ZB+uWqFTBpFzV4IOwm/vFUGpa9Hy5usCLS5slh0AMNGurNyr189ci/LrGVLxKeoGcT36xjx47Ftm3b8NtvvyEoKOiO9RQKhenRgpY8YlAsMifAxdUodhg2xclJMH0mbu56vL06BXqdE+a9HgZdpfweZzu+igpn5OWr4OFegYgHM5F0WLo/FO9F6aZHo8YlyLuphFJZlciE/9fyMhplkNnz4uhaoNc54fwfKjzYvchUJpMJCO9ejDPJXHonFaL+rBMEAePGjcOWLVuwZ88eNGtmv124I9/MxJHf1Lh+zQVuHkb0HpKPsMhivPV8C7FDE82I1y/i6O/eyM1SQuVuQK/+OejQuQAzXw2Hm7seC1anQKE04N3poVC566Fyr/rCLsx3hdFov91l9yMiPBMyGZBxTY3GjYrw8ohjyLiqwa7dVf9+PD0q0LBhCXy8ywAAwYFV81Xy892QXyCN1R6jXjuFQ78HIDfHDT6+5Xhh5DkYjTLs+SUIJcUuuHbVHeOmpODTFe3/6sbPxIOdczHnzW5ihy667z72xZQlGfjzhAqpx6uW3ilVRuzaKK17NUi5ZS9qso+NjcWGDRvwww8/wNPTE9nZ2QAAjUYDNzf7+gJr4KvH1A+vwNtPj9IiOdLOKvHW8y1wbJ+n2KGJRuNdiclvn4V3wwqUFDsj7U8PzHw1HMcPeqND53y0DatKWJ9tP2h23ognIpGbaV9//9Zyd9dh5PDj8PUpRVGRK35PCsHaL8Nh+GtlQreHrmLK60mm+v+ZWjXc9fnGDvhiY0dRYq5vvg3LMG32UajVlSgscMXpkz6Y+GpPaAurhs5mvxGJkf8+jdlxB+HmpkfmNXcsfqcTjh4MEDly8SX+6AWNjwEvTs2GV0M9Lp12w1vRzVBwQ0Jr7GH9XfDsuZNIJgiCaOHLZNW33tauXYsRI0bc83ytVguNRoNesiFwlknrH62l5D4S+wV/nwzNpbca4H7I86S93r+mDBfqfr6TvdMLOuzBDygsLKyzodlbuaLpggVwUt7/hGljeTkuv/VWncZaV0TvxiciIqoXEu7Gv68Jevv27cMLL7yAyMhIXLt2DQDw+eef33UmPRERkaiEWtjslMXJ/ttvv0VUVBTc3Nxw/Phx001uCgsL8c4779R6gERERGQdi5P922+/jVWrVuGTTz6Bi8vf4+SPPPIIjh07VqvBERER1RY+4tYCqamp1d63XqPRoKCgoDZiIiIiqn0SvoOexS37gIAAXLhw4bby/fv3o3nz5rUSFBERUa3jmH3NjR49GuPHj8ehQ4cgk8mQmZmJL7/8ElOmTMGYMWPqIkYiIiKygsXd+G+++SaMRiMee+wxlJaWokePHlAoFJgyZQrGjRtXFzESERFZTco31bE42ctkMrz11luYOnUqLly4gOLiYoSGhsLDgw/sICIiGybhdfb3fVMdV1dXhIaG1mYsREREVAcsTva9e/e+421uAeDXX3+1KiAiIqI6Ye3yOSm17MPDw832dTodUlJScOrUKcTExNRWXERERLWL3fg198EHH1RbPmfOHBQX8+EYREREtua+7o1fnRdeeAGfffZZbV2OiIiodkl4nX2tPfUuKSkJSiseHUhERFSXuPTOAkOHDjXbFwQBWVlZOHr0KGbOnFlrgREREVHtsDjZazQas30nJye0adMG8+bNQ79+/WotMCIiIqodFiV7g8GAkSNHokOHDvDy8qqrmIiIiGqfhGfjWzRBTy6Xo1+/fny6HRER2R0pP+LW4tn47du3x6VLl+oiFiIiIqoDFif7t99+G1OmTMG2bduQlZUFrVZrthEREdksCS67AywYs583bx4mT56MAQMGAACefPJJs9vmCoIAmUwGg8FQ+1ESERFZS8Jj9jVO9nPnzsWrr76K3377rS7jISIiolpW42QvCFU/aXr27FlnwRAREdUV3lSnhu72tDsiIiKbxm78mmnduvU9E35eXp5VAREREVHtsijZz50797Y76BEREdkDduPX0LPPPgs/P7+6ioWIiKjuSLgbv8br7DleT0REZJ8sno1PRERklyTcsq9xsjcajXUZBxERUZ3imL29ExzgXoZ1zFhYJHYIdsE5p0DsEOzC+VeDxA7BLvj84S92CDbPoCsHvv6hfl5Mwi17i++NT0RERPbFMVr2RERE9yLhlj2TPRERSYKUx+zZjU9EROTg2LInIiJpYDc+ERGRY2M3PhERETkstuyJiEga2I1PRETk4CSc7NmNT0RE5OCY7ImISBJktbBZIi4uDl26dIGnpyf8/PwwZMgQpKammtUpLy9HbGwsfHx84OHhgWHDhiEnJ8esTnp6OgYOHAiVSgU/Pz9MnToVer3eoliY7ImISBqEWtgskJiYiNjYWBw8eBAJCQnQ6XTo168fSkpKTHUmTpyIrVu34uuvv0ZiYiIyMzMxdOhQ03GDwYCBAweisrISBw4cwLp16xAfH49Zs2ZZFAvH7ImISBLqe+ndjh07zPbj4+Ph5+eH5ORk9OjRA4WFhVizZg02bNiAPn36AADWrl2Ldu3a4eDBg+jWrRt27dqFM2fO4JdffoG/vz/Cw8Mxf/58TJs2DXPmzIGrq2uNYmHLnoiIyAJardZsq6ioqNF5hYWFAABvb28AQHJyMnQ6Hfr27Wuq07ZtW4SEhCApKQkAkJSUhA4dOsDf/+8nKEZFRUGr1eL06dM1jpnJnoiIpKGWuvGDg4Oh0WhMW1xc3D1f2mg0YsKECXjkkUfQvn17AEB2djZcXV3RoEEDs7r+/v7Izs421fnfRH/r+K1jNcVufCIiko5aWD6XkZEBtVpt2lcoFPc8JzY2FqdOncL+/futD+A+sGVPRERkAbVabbbdK9mPHTsW27Ztw2+//YagoCBTeUBAACorK1FQUGBWPycnBwEBAaY6/392/q39W3VqgsmeiIgk4dYEPWs2SwiCgLFjx2LLli349ddf0axZM7PjERERcHFxwe7du01lqampSE9PR2RkJAAgMjISJ0+eRG5urqlOQkIC1Go1QkNDaxwLu/GJiEga6vkOerGxsdiwYQN++OEHeHp6msbYNRoN3NzcoNFoMGrUKEyaNAne3t5Qq9UYN24cIiMj0a1bNwBAv379EBoaiuHDh2PRokXIzs7GjBkzEBsbW6Phg1uY7ImIiOrAypUrAQC9evUyK1+7di1GjBgBAPjggw/g5OSEYcOGoaKiAlFRUVixYoWprlwux7Zt2zBmzBhERkbC3d0dMTExmDdvnkWxMNkTEZEk1Pc6e0G49wlKpRLLly/H8uXL71inSZMm2L59u2Uv/v8w2RMRkTTwQThERETkqNiyJyIiSajvbnxbwmRPRETSIOFufCZ7IiKSBgkne47ZExEROTi27ImISBI4Zk9EROTo2I1PREREjooteyIikgSZIEBWg7va3e18e8VkX0v+NTYHjwwoRHDLClSWO+HMURXWLGiEqxeVYocmqvYPFeGf/85Cqw6l8PHXYe7olkja5fU/NQQMn5SJ/s9dh7tajzNHPfHRW02QeVm6n9vTwy9gxGvn8P2mZvhkyQMAgIDGJRg17gweCMuHi6sRyQcbYtX77VGQX/MHYdibf7c/hn5N0tBMU4AKvRzHrwfg3eRuSNM2MNX5POoHdA3IMjvvq9RQzD7Yw7TfwScXUyIO4QGf6xAE4I8bfng3uRvO5fvW11upU+HNMxHd6wTaBN1AQ00ppq3th72n/n662oxnf8PALn+anXPwXBAmfjLQtB/sW4Cxgw4irFkOXOQGXMjywcc/d8axi43r7X3UC3bji2PlypUICwszPRM4MjISP//8s5gh3bewyBJsjffFhH+0wvRnm0PuLOCdry5B4WYQOzRRKVUGpJ1VYfnMJtUef/rVbAwekYOl/2mCCYNDUV7qhAWf/wkXhbGeI7UNrdoV4IkhV3DpvKepTKHU4+0lhwBBhunjumHKvx+Gs7MRs947DJk9zxi6hy4BWfji3AN4ZvtTGJnwDzg7GfHZ49vg5qwzq7fpz3Z4eNOLpm1RcjfTMZWzDp/2/QmZJR54+qeheG7HEJToXLHm8Z/gLHOM/5tKVz3OZ/rg/e+637FO0tlgDJwz3LTN+qKv2fH3Xt4BuZOAsSv/gREfDMOFTG+8N2oHvD1L6zp8qieiJvugoCAsXLgQycnJOHr0KPr06YPBgwfj9OnTYoZ1X96Kbo6Ezd648qcSl8644f0JIfAP0qFVWJnYoYnq6J4GWPdeEA7s9KrmqICnRuXgq2WNcDDBC2nnVHh3UjP4+FXi4X759R6r2JRuekydcxwfLQxDcZGLqTw0LB9+jUqxeH5HXLmoxpWLaiyeH45WbQvRsfMNESOuWy//MhBbLrbFhQJvnMv3xbT9vdHYoxgP+Fw3q1emd8aNcpVpK9G5mo411+TDS1mBD493QZq2AS4UeGPZiQg0dCtDoEdxfb+lOnHwXAg+3vEQEk81u2OdSoMceUUq01ZU9nePkMa9DCENC/H5r+G4mOWDqzc0WPFTV7gp9GgRkFcfb6He1Pfz7G2JqMl+0KBBGDBgAFq1aoXWrVtjwYIF8PDwwMGDB8UMq1a4q6taDUUFcpEjsV0BwRXw9tPh+H6Nqay0yBnnUjzQrpNjfBFbYsyUUzhywA8pRxqalbu4GgFBBp3u7/+ulZVOEIwyhIY51pfx3Xi6VgIACivMh3iebH4eh/4Vj21PbsLkToeglP/d8k8rbID8ciWebnUWLk4GKOR6/LPVOVwo8MK1Yk9IRacWmfhpzjpsnLYRU4ftg1pVbjpWWKLEldwG6N/5TyhddZA7GTEk8izyitxw7mrDu1zVDgm1sNkpmxmzNxgM+Prrr1FSUoLIyMhq61RUVKCiosK0r9Vq6ys8i8hkAl6dew2nDqtwJdVN7HBslpdf1ZdywQ3zf4YFN5zh1VBX3SkOq0ffa2jZphATXrq9K/bcqQYoL5djZOw5rF/ZFpAJGPnaOcidBXj7VlRzNccjg4C3uvyO5JwAnC/wNpVvu9QK10o8kVuqQhuvm5gacQjN1AUYuycKAFCid8ULO5/Eit478FrYMQDAlSINXkoYCIMgjcVIB88FY8/JZsi66YnGvlq82v8wPhi9HaOXDoFRcAIgw7hVA/HfkTuxe8FnMAoy5Be7YeInA8x6AMi+iZ7sT548icjISJSXl8PDwwNbtmxBaGhotXXj4uIwd+7ceo7QcmPfuYYmbcsxeUhLsUMhO+DrV4ZXJp7GjNe7QVd5e0+QtkCBuLciEDv1JJ58Og2CUYbEhEBcOKeB0SgTIeL6N7vbPrTyysNzPw8xK990/u/vij8LfHC9zB3ro7Yi2LMQGUUaKOR6vPPwHhzLDcCkvX3hJBMw6oET+Pix7Rj20zBUGET/Cqxzv6T8/T10MdsHFzJ98O1bX6FTy0wcPR8EQMCUofuRX+yGMcsHo1wnx5Ndz+Hdl3bgpSVP4WaRu3jB1zLeVEdEbdq0QUpKCgoLC/HNN98gJiYGiYmJ1Sb86dOnY9KkSaZ9rVaL4ODg+gz3nmIXXEXXx7WY/FQL3MhyvfcJEpafWzUu3cBXj7zcvz+rBr56XDojnR6Rlm0L4eVdiaXx+0xlcmcB7cPzMGjYZQzpOQDHDzfEy0/3gVpTCYNBhpJiF3yxLQHZmSoRI68fs7ruQ++gK4jeMRg5pR53rXvihh8AoImnFhlFGgxqdh6NPYrwzPanIKDqh9HkfY/hyLNr0Tf4Mn66LL0f5Jl5auQXKxHko8XR80DnVtfwSGg6+s0YgdKKqv+H733XEA+1vooBXf7E578+KHLEtUjCs/FFT/aurq5o2bLqP1xERASOHDmCDz/8EKtXr76trkKhgEJhq91KAmIXXMPDTxRi6j9bIifDVuO0HdkZCuTluiD8ES0unalKWioPA9qGF+OnLxxsrPAuThz1xWvRPczKJrx1AleveOCbL1qYtd61hVVfxmERN6DxqsChff71Gmv9EjCr6348HpKGF3Y8iavF6nue0c6rasLi9bKqf09uznoYBZnZd/StfUdeyXA3DTXF0KjKcaOo6jNSuugBAIJg3ktkFGRwcrDPiC17G2I0Gs3G5e3F2HeuofdT+ZgzshnKip1MY84lRXJUlktjbLA6SpUBgU3//vsMCK5A89BSFBXIcT1TgS1r/PHcuExkpimQnaHAi5Ov4WauKw7sqm72vmMqK3XGlUvmiay8XA6t1tVU3ndgBjIue6CwwBXt2ufjlYmn8f3G5riWfveWrj2b3XUfBjW/gDG/PoESnSt8lVXLwIp0rqgwOCPYsxCDml1A4tUQFFQo0MY7D//pcgCHsxshNd8HAPB7ZhDe6HwQs7vuwxfnOkAmE/Dv9sdhEJxwKDtQzLdXa9xcdQjyLTTtB3oXoVXgDWhLFdCWKjGq31H89kdz3CxSIci3ELEDD+HqTQ0OnavqFT15xR9FZQrMfO43fLYrAhU6OQZ3O4tA7yL8fqb6JbNkf0RN9tOnT0f//v0REhKCoqIibNiwAXv27MHOnTvFDOu+DBpxEwDw3ncXzcrfmxCMhM3e1Z0iCa3DSrBoU6pp/9+zMgAACV/74P0pzfH1qgAoVUa8HncZHmoDTh/1xIwXW0NXId0fSNUJCinGiDHn4KGuRG6WCpviW+H7jXdeauUIotueAQB8+cSPZuXT9vfClottoTPI8XCjq4hp9wdULnpklbhj55VmWPFHhKnuJa0X/r37CYzrmIxNA7bAKMhwNs8XoxIG4nqZY4xFtw2+jhWvbTXtjx+cBAD46UhrvPvNo2gRmIf+nf+Ep1slbmhVOJQahI93dIHOUDU/pLDEDRM/HoB/DziMZWO2wlluxKVsL7yxNgoXsnxEeU91RsLd+DJBEO/+f6NGjcLu3buRlZUFjUaDsLAwTJs2DY8//niNztdqtdBoNOiFwXCWudz7BAmTuXD+QE3IAx25W7z2nH81SOwQ7ILPH3acHeqJQVeO5K9noLCwEGr1vYdq7setXBHxzAI4u9z/3Tn1unIkb36rTmOtK6K27NesWSPmyxMREUmCzY3ZExER1QlBqNqsOd9OMdkTEZEkSHk2PmdBEREROTi27ImISBokPBufyZ6IiCRBZqzarDnfXrEbn4iIyMGxZU9ERNLAbnwiIiLHJuXZ+Ez2REQkDRJeZ88xeyIiIgfHlj0REUkCu/GJiIgcnYQn6LEbn4iIyMGxZU9ERJLAbnwiIiJHx9n4RERE5KjYsiciIklgNz4REZGj42x8IiIiclRs2RMRkSSwG5+IiMjRGYWqzZrz7RSTPRERSQPH7ImIiMhRsWVPRESSIIOVY/a1Fkn9Y7InIiJp4B30iIiIyFGxZU9ERJLApXdERESOjrPxiYiIyFGxZU9ERJIgEwTIrJhkZ825YmOylwhBVyl2CHZBfyVD7BDsgvpCkNgh2IWk91eJHYLN0xYZ4fV1Pb2Y8a/NmvPtFLvxiYiIHBxb9kREJAnsxiciInJ0nI1PRETk4G7dQc+azQJ79+7FoEGDEBgYCJlMhu+///7/hSNg1qxZaNSoEdzc3NC3b1+cP3/erE5eXh6io6OhVqvRoEEDjBo1CsXFxRa/dSZ7IiKiOlBSUoKOHTti+fLl1R5ftGgRli5dilWrVuHQoUNwd3dHVFQUysvLTXWio6Nx+vRpJCQkYNu2bdi7dy9eeeUVi2NhNz4REUlCbd1BT6vVmpUrFAooFIrb6vfv3x/9+/ev9lqCIGDJkiWYMWMGBg8eDABYv349/P398f333+PZZ5/F2bNnsWPHDhw5cgSdO3cGAHz00UcYMGAA3nvvPQQGBtY4drbsiYhIGmqpGz84OBgajca0xcXFWRxKWloasrOz0bdvX1OZRqNB165dkZSUBABISkpCgwYNTIkeAPr27QsnJyccOnTIotdjy56IiMgCGRkZUKvVpv3qWvX3kp2dDQDw9/c3K/f39zcdy87Ohp+fn9lxZ2dneHt7m+rUFJM9ERFJgsxYtVlzPgCo1WqzZG8P2I1PRETSUM+z8e8mICAAAJCTk2NWnpOTYzoWEBCA3Nxcs+N6vR55eXmmOjXFZE9ERFTPmjVrhoCAAOzevdtUptVqcejQIURGRgIAIiMjUVBQgOTkZFOdX3/9FUajEV27drXo9diNT0RE0lDPN9UpLi7GhQsXTPtpaWlISUmBt7c3QkJCMGHCBLz99tto1aoVmjVrhpkzZyIwMBBDhgwBALRr1w5PPPEERo8ejVWrVkGn02Hs2LF49tlnLZqJDzDZExGRRNT37XKPHj2K3r17m/YnTZoEAIiJiUF8fDzeeOMNlJSU4JVXXkFBQQG6d++OHTt2QKlUms758ssvMXbsWDz22GNwcnLCsGHDsHTpUotjZ7InIiKqA7169YJwlx8IMpkM8+bNw7x58+5Yx9vbGxs2bLA6FiZ7IiKSBmsn2fFBOERERDZOgHXPpLffXM9kT0RE0iDlR9xy6R0REZGDY8ueiIikQYCVY/a1Fkm9Y7InIiJpkPAEPXbjExEROTi27ImISBqMAGRWnm+nmOyJiEgSOBufiIiIHBZb9kREJA0SnqDHZE9ERNIg4WTPbnwiIiIHx5Y9ERFJg4Rb9kz2REQkDVx6R0RE5Ni49I6IiIgcFlv2tWzQiBv455hceDfU49IZN6yY0RipKSqxw7IZ/xqbg0cGFCK4ZQUqy51w5qgKaxY0wtWLSrFDsyn8nIAHm2RiePcTaBd4HQ3VpZi8IQqJZ5uZjh+dv6ra8z7c0Q2f/x4OAGjT6Dpe73cQoY2vwyDI8Ovp5vhgx8Moq3Spj7dQLz5/LwBfLA4wKwtqUY41+84BAKYOa4k/kjzMjg8YfgPj/3vVtB8VGH7bdaevuIxeQwpqPV5RccxefAsXLsT06dMxfvx4LFmyROxw7kvPJ/PxyuxMfPRmEM4dU+Gp0dexYMMljHq0DQpvOs6XizXCIkuwNd4Xf6aoIHcWMOLNLLzz1SWM7tkGFWVyscOzGfycADdXPc5n++DHY23x3vM7bzse9d8XzfYfbpWOmUP24NczzQEAvp4lWDFiGxJOtcCinx6Fu6ISk/v/jjlDf8O0jf3q5T3UlyZtyrBw00XTvlxunpT6R9/Ai1OzTfsKt9sHnyd/kI7OvbWmfQ+1oQ4iFZlRAGRWJGwjk71Vjhw5gtWrVyMsLEzsUKwy9JUb2LHBG7s2eQMAlk4LwkOPaRH1XB42L/MXOTrb8FZ0c7P99yeEYPOp02gVVoZThzzucJb08HMCDpwPwYHzIXc8frPYvMesZ7vLOJrWGNfy1QCAR9tcgd7ohP9uexSCUDUr652tPbBp7NcI8i7E1TxN3QVfz+RywNtPf8fjCjfhrseBquR+rzpkv0Qfsy8uLkZ0dDQ++eQTeHl5iR3OfXN2MaJVWCmO7fM0lQmCDMf3eSI0olTEyGyb+1+th6ICabRW7xc/p7vzdi9F99bp+OFYW1OZq9wAncHJlOgBoEJX1b4Jb5JV7zHWpWtprnjuwQcQ060dFsaGIPeqeU/ib9954ekH2uOV3m3w2TuNUF56+5T0ZW81xtMPtMe4Aa2w8ytve+6xvrNb3fjWbHZK9JZ9bGwsBg4ciL59++Ltt9++a92KigpUVFSY9rVa7V1q1y+1twFyZ6DguvlHmn/DGcEtK+5wlrTJZAJenXsNpw6rcCXVTexwbBY/p3v7x4OpKKlwwW9n/h7TP5LWGBP7J2H4Iyn46mAHuLnoMa7fIQCAr6fj/ABv26kEU5aUIahFBfJyXfDF+wGY/FQrrP7tHFQeRvR+Kh9+QZXw8dch7azbX3M/FJi15rLpGi9OzUL4I8VQuBmRnOiJj/4ThLISJwx5+YZ4b6xOWJuwmezvy8aNG3Hs2DEcOXKkRvXj4uIwd+7cOo6K6svYd66hSdtyTB7SUuxQbBo/p3t7slMqdvzRCpX6v7/SLuV6Y/Z3vTHxiQOIffwQjIIMGw92wI0iN7PWvr3r0qfI9OfmoeVo+2Aphj8Uir0/NsATz+dhwAs3TcebtSuHt58O055piczLrghsWgkAiJ6YY6rTskMZykud8PVKPwdM9tIlWrLPyMjA+PHjkZCQAKWyZjOMp0+fjkmTJpn2tVotgoOD6ypEi2jz5DDogQYNzce8vHz1yL8uegeKzYldcBVdH9di8lMtcCPLVexwbBY/p3sLb5KFpg0LMH1z39uO7fyjFXb+0Qre7qUo07lAEIDoh//A1Ty1CJHWDw+NAUHNK5B5WVHt8badqno1Mi8rTMm+ujoblgSgskIGV4X9tmZvI+HZ+KKN2ScnJyM3NxedOnWCs7MznJ2dkZiYiKVLl8LZ2RkGw+0zQRUKBdRqtdlmK/Q6J5z/Q4UHu//9K1smExDevRhnkrn07m8CYhdcxcNPFOKNp1sgJ6P6LyTi51RTgzudxZlrDXE+2/eOdfJKVCirdEG/DhdRqZfj0MWgeoywfpWVOCHziiu8/XTVHr94qmoo6E7HAeDiaTd4NNA7VqIHqmbTW7vZKdGanI899hhOnjxpVjZy5Ei0bdsW06ZNg1xufxORvvvYF1OWZODPEyqkHq9aeqdUGbFro7fYodmMse9cQ++n8jFnZDOUFTvBq2HVF05JkRyV5aLPF7UZ/JwAN1cdgr0LTfuNG2jROuAGCssUyCmsmgjrrqhE3/aXsGRHZLXXeKbrKZxI90dZpQu6triK8VEH8VFCVxSXO86Pp4/nBqJbv0L4BelwM9sZn7/XCHInoNdT+ci87Irftnjhoce08PQyIO2MEqvnNEaHbsVoHloOADi4S438685oF1EKF4URx/Z6YuNSP/zz1esivzOqTaIle09PT7Rv396szN3dHT4+PreV24vEH72g8THgxanZ8Gqox6XTbngruhkKbnCN/S2DRlSNH7733UWz8vcmBCNhM38U3cLPCQgNzMXqUVtN+5MGJAEAth5rjblb+gAA+nW4ABmAHX9UP5/hgaBcvNLnCFSuOly+4YV3fuyB7Sda13ns9elGlgviXmuKonw5ND56PNClBEu2/YkGPgZUljvh+D5PbPm0IcpLndAwUIfuAwrw3IS/x+jlLgK2xvti9RwFBAEIbFqJf8/JRP/om3d5VTslGKs2a863UzJBsJ1BiF69eiE8PLzGN9XRarXQaDTohcFwljGhEtWXm6Oqb0mTuaPzV4odgs3TFhnh1foSCgsL62xo9lau6Bs8Bs5O99+rozdW4JeMlXUaa12xqZlje/bsETsEIiJyVEYBVi2fs+Mxe2kM/hEREUmYTbXsiYiI6oyEl94x2RMRkTQIsDLZ11ok9Y7d+ERERA6OLXsiIpIGduMTERE5OKMRgBVr5Y32u86e3fhEREQOji17IiKSBnbjExEROTgJJ3t24xMRETk4tuyJiEgaJHy7XCZ7IiKSBEEwQrDiyXXWnCs2JnsiIpIGQbCudc4xeyIiIrJVbNkTEZE0CFaO2dtxy57JnoiIpMFoBGRWjLvb8Zg9u/GJiIgcHFv2REQkDezGJyIicmyC0QjBim58e156x258IiIiB8eWPRERSQO78YmIiBycUQBk0kz27MYnIiJycGzZExGRNAgCAGvW2dtvy57JnoiIJEEwChCs6MYXmOyJiIhsnGCEdS17Lr0jIiKiaixfvhxNmzaFUqlE165dcfjw4XqPgcmeiIgkQTAKVm+W2rRpEyZNmoTZs2fj2LFj6NixI6KiopCbm1sH7/DOmOyJiEgaBKP1m4UWL16M0aNHY+TIkQgNDcWqVaugUqnw2Wef1cEbvDO7HrO/NVlCD51V90kgIssYKsvFDsEuaIvsd4y3vmiLqz6j+pj8Zm2u0EMHANBqtWblCoUCCoXitvqVlZVITk7G9OnTTWVOTk7o27cvkpKS7j+Q+2DXyb6oqAgAsB/bRY6ESGLW/yB2BHbBa73YEdiPoqIiaDSaOrm2q6srAgICsD/b+lzh4eGB4OBgs7LZs2djzpw5t9W9ceMGDAYD/P39zcr9/f1x7tw5q2OxhF0n+8DAQGRkZMDT0xMymUzscABU/eILDg5GRkYG1Gq12OHYLH5ONcPPqWb4OdWMLX5OgiCgqKgIgYGBdfYaSqUSaWlpqKystPpagiDclm+qa9XbGrtO9k5OTggKChI7jGqp1Wqb+c9ky/g51Qw/p5rh51QztvY51VWL/n8plUoolco6f53/5evrC7lcjpycHLPynJwcBAQE1GssnKBHRERUB1xdXREREYHdu3ebyoxGI3bv3o3IyMh6jcWuW/ZERES2bNKkSYiJiUHnzp3x0EMPYcmSJSgpKcHIkSPrNQ4m+1qmUCgwe/ZsuxjDERM/p5rh51Qz/Jxqhp9T/fvXv/6F69evY9asWcjOzkZ4eDh27Nhx26S9uiYT7Plmv0RERHRPHLMnIiJycEz2REREDo7JnoiIyMEx2RMRETk4JvtaZguPMrRle/fuxaBBgxAYGAiZTIbvv/9e7JBsUlxcHLp06QJPT0/4+flhyJAhSE1NFTssm7Ny5UqEhYWZbhITGRmJn3/+WeywbNrChQshk8kwYcIEsUOhesRkX4ts5VGGtqykpAQdO3bE8uXLxQ7FpiUmJiI2NhYHDx5EQkICdDod+vXrh5KSErFDsylBQUFYuHAhkpOTcfToUfTp0weDBw/G6dOnxQ7NJh05cgSrV69GWFiY2KFQPePSu1rUtWtXdOnSBcuWLQNQdaek4OBgjBs3Dm+++abI0dkemUyGLVu2YMiQIWKHYvOuX78OPz8/JCYmokePHmKHY9O8vb3x7rvvYtSoUWKHYlOKi4vRqVMnrFixAm+//TbCw8OxZMkSscOiesKWfS259SjDvn37msrEepQhOZ7CwkIAVYmMqmcwGLBx40aUlJTU+61I7UFsbCwGDhxo9h1F0sE76NUSW3qUITkWo9GICRMm4JFHHkH79u3FDsfmnDx5EpGRkSgvL4eHhwe2bNmC0NBQscOyKRs3bsSxY8dw5MgRsUMhkTDZE9m42NhYnDp1Cvv37xc7FJvUpk0bpKSkoLCwEN988w1iYmKQmJjIhP+XjIwMjB8/HgkJCfX+1DeyHUz2tcSWHmVIjmPs2LHYtm0b9u7da7OPcxabq6srWrZsCQCIiIjAkSNH8OGHH2L16tUiR2YbkpOTkZubi06dOpnKDAYD9u7di2XLlqGiogJyuVzECKk+cMy+ltjSowzJ/gmCgLFjx2LLli349ddf0axZM7FDshtGoxEVFRVih2EzHnvsMZw8eRIpKSmmrXPnzoiOjkZKSgoTvUSwZV+LbOVRhrasuLgYFy5cMO2npaUhJSUF3t7eCAkJETEy2xIbG4sNGzbghx9+gKenJ7KzswEAGo0Gbm5uIkdnO6ZPn47+/fsjJCQERUVF2LBhA/bs2YOdO3eKHZrN8PT0vG2uh7u7O3x8fDgHREKY7GuRrTzK0JYdPXoUvXv3Nu1PmjQJABATE4P4+HiRorI9K1euBAD06tXLrHzt2rUYMWJE/Qdko3Jzc/Hiiy8iKysLGo0GYWFh2LlzJx5//HGxQyOyKVxnT0RE5OA4Zk9EROTgmOyJiIgcHJM9ERGRg2OyJyIicnBM9kRERA6OyZ6IiMjBMdkTERE5OCZ7IiIiB8dkT2SlESNGYMiQIab9Xr16YcKECfUex549eyCTyVBQUHDHOjKZDN9//32NrzlnzhyEh4dbFdfly5chk8mQkpJi1XWI6P4x2ZNDGjFiBGQyGWQymempaPPmzYNer6/z1/7uu+8wf/78GtWtSYImIrIW741PDuuJJ57A2rVrUVFRge3btyM2NhYuLi6YPn36bXUrKyvh6upaK6/r7e1dK9chIqotbNmTw1IoFAgICECTJk0wZswY9O3bFz/++COAv7veFyxYgMDAQLRp0wYAkJGRgWeeeQYNGjSAt7c3Bg8ejMuXL5uuaTAYMGnSJDRo0AA+Pj5444038P8fL/H/u/ErKiowbdo0BAcHQ6FQoGXLllizZg0uX75seiiQl5cXZDKZ6SE3RqMRcXFxaNasGdzc3NCxY0d88803Zq+zfft2tG7dGm5ubujdu7dZnDU1bdo0tG7dGiqVCs2bN8fMmTOh0+luq7d69WoEBwdDpVLhmWeeQWFhodnxTz/9FO3atYNSqUTbtm2xYsUKi2MhorrDZE+S4ebmhsrKStP+7t27kZqaioSEBGzbtg06nQ5RUVHw9PTEvn378Pvvv8PDwwNPPPGE6bz3338f8fHx+Oyzz7B//37k5eVhy5Ytd33dF198EV999RWWLl2Ks2fPYvXq1fDw8EBwcDC+/fZbAEBqaiqysrLw4YcfAgDi4uKwfv16rFq1CqdPn8bEiRPxwgsvIDExEUDVj5KhQ4di0KBBSElJwcsvv4w333zT4s/E09MT8fHxOHPmDD788EN88skn+OCDD8zqXLhwAZs3b8bWrVuxY8cOHD9+HK+99prp+JdffolZs2ZhwYIFOHv2LN555x3MnDkT69atszgeIqojApEDiomJEQYPHiwIgiAYjUYhISFBUCgUwpQpU0zH/f39hYqKCtM5n3/+udCmTRvBaDSayioqKgQ3Nzdh586dgiAIQqNGjYRFixaZjut0OiEoKMj0WoIgCD179hTGjx8vCIIgpKamCgCEhISEauP87bffBABCfn6+qay8vFxQqVTCgQMHzOqOGjVKeO655wRBEITp06cLoaGhZsenTZt227X+PwDCli1b7nj83XffFSIiIkz7s2fPFuRyuXD16lVT2c8//yw4OTkJWVlZgiAIQosWLYQNGzaYXWf+/PlCZGSkIAiCkJaWJgAQjh8/fsfXJaK6xTF7cljbtm2Dh4cHdDodjEYjnn/+ecyZM8d0vEOHDmbj9CdOnMCFCxfg6elpdp3y8nJcvHgRhYWFyMrKQteuXU3HnJ2d0blz59u68m9JSUmBXC5Hz549axz3hQsXUFpaetsz2SsrK/Hggw8CAM6ePWsWBwBERkbW+DVu2bRpE5YuXYqLFy+iuLgYer0earXarE5ISAgaN25s9jpGoxGpqanw9PTExYsXMWrUKIwePdpUR6/XQ6PRWBwPEdUNJntyWL1798bKlSvh6uqKwMBAODub/3N3d3c32y8uLkZERAS+/PLL267VsGHD+4rBzc3N4nOKi4sBAD/99JNZkgWq5iHUlqSkJERHR2Pu3LmIioqCRqPBxo0b8f7771sc6yeffHLbjw+5XF5rsRKRdZjsyWG5u7ujZcuWNa7fqVMnbNq0CX5+fre1bm9p1KgRDh06hB49egCoasEmJyejU6dO1dbv0KEDjEYjEhMT0bdv39uO3+pZMBgMprLQ0FAoFAqkp6ffsUegXbt2psmGtxw8ePDeb/J/HDhwAE2aNMFbb71lKrty5cpt9dLT05GZmYnAwEDT6zg5OaFNmzbw9/dHYGAgLl26hOjoaIten4jqDyfoEf0lOjoavr6+GDx4MPbt24e0tDTs2bMHr7/+Oq5evQoAGD9+PBYuXIjvv/8e586dw2uvvXbXNfJNmzZFTEwMXnrpJXz//fema27evBkA0KRJE8hkMmzbtg3Xr19HcXExPD09MWXKFEycOBHr1q3DxYsXcezYMXz00UemSW+vvvoqzp8/j6lTpyI1NRUbNmxAfHy8Re+3VatWSE9Px8aNG3Hx4kUsXbq02smGSqUSMTExOHHiBPbt24fXX38dzzzzDAICAgAAc+fORVxcHJYuXYo///wTJ0+exNq1a7F48WKL4iGiusNkT/QXlUqFvXv3IiQkBEOHDkW7du0watQolJeXm1r6kydPxvDhwxETE4PIyEh4enriqaeeuut1V65ciX/+85947bXX0LZtW4wePRolJSUAgMaNG2Pu3Ll488034e/vj7FjxwIA5s+fj5kzZyIuLg7t2rXDE088gZ9++gnNmjUDUDWO/u233+L7779Hx44dsWrVKrzzzjsWvd8nn3wSEydOxNixYxEeHo4DBw5g5syZt9Vr2bIlhg4digEDBqBfv34ICwszW1r38ssv49NPP8XatWvRoUMH9OzZE/Hx8aZYiUh8MuFOM4uIiIjIIbBlT0RE5OCY7ImIiBwckz0REZGDY7InIiJycEz2REREDo7JnoiIyMEx2RMRETk4JnsiIiIHx2RPRETk4JjsiYiIHByTPRERkYP7PxmbUvnIxllZAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_matrix_train = confusion_matrix(test_dataset.targets , predictions_argmax)\n",
    "ConfusionMatrixDisplay(confusion_matrix_train).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mca_eval = MulticlassAccuracy(num_classes=5, average=None)\n",
    "mca_average = MulticlassAccuracy(num_classes=5, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6429, 0.5659, 0.4946, 0.5409, 0.7520])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mca_eval(predictions_argmax, torch.tensor(test_dataset.targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6396)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mca_average(predictions_argmax, torch.tensor(test_dataset.targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Walidacja skroÅ›na pozwala na ograniczenie przetrenowania, ale w obecnej formie nie neguje problemÃ³w zwiÄ…zanych z nierÃ³wnÄ… dystrybucjÄ… danych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Walidacja skroÅ›na z wykorzystaniem podziaÅ‚u z rÃ³wnÄ… dystrybucjÄ… klas w poszczegÃ³lnych foldach i funkcji strat z wagami"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArtifficialNeuralNetworks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
