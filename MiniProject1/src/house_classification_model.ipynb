{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "ecbbcba522b3b875",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T22:11:38.840323Z",
     "start_time": "2024-03-24T22:11:36.431707Z"
    }
   },
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "ddc69bd5cd3a47af",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T22:11:38.860867Z",
     "start_time": "2024-03-24T22:11:38.846379Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import torch\n",
    "import abc\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from torchmetrics.classification import MulticlassAccuracy\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "import numpy as np\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f0091cd5a6f004",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Set up criteria for classifying the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "75a2ab3d11002674",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T22:11:38.863719Z",
     "start_time": "2024-03-24T22:11:38.861981Z"
    }
   },
   "outputs": [],
   "source": [
    "CRITERIUM_MAX_AVERAGE = 350000\n",
    "CRITERIUM_MAX_CHEAP = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "e9fd28a6c6909a0b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T22:11:38.866780Z",
     "start_time": "2024-03-24T22:11:38.864840Z"
    }
   },
   "outputs": [],
   "source": [
    "COLUMNS_TO_DUMMY = [\n",
    "    \"HeatingType\",\n",
    "    \"AptManageType\",\n",
    "    \"HallwayType\",\n",
    "    \"TimeToBusStop\",\n",
    "    \"TimeToSubway\",\n",
    "    \"SubwayStation\",\n",
    "]\n",
    "OUTPUT_COLUMN = \"SalePrice\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b896ae2e884ab2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Create a dataset class for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "4eeb0436a9898200",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T00:11:13.359621Z",
     "start_time": "2024-03-25T00:11:13.346001Z"
    }
   },
   "outputs": [],
   "source": [
    "class HouseDataset(data.Dataset):\n",
    "    def __init__(self, path_to_csv: str, scaler=None) -> None:\n",
    "        super().__init__()\n",
    "        self.data = pd.read_csv(path_to_csv)\n",
    "        self.scaler = scaler\n",
    "        self._prepare_data()\n",
    "        self.headers = list(self.data.columns)\n",
    "        self._to_tensor()\n",
    "        self.size = self.data.shape[0]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, idx) -> tuple[torch.tensor, torch.tensor]:\n",
    "        data_point = self.data[idx]\n",
    "        data_label = self.label[idx]\n",
    "        return data_point, data_label\n",
    "\n",
    "    def _to_dummy_columns(self, columns: List[str]) -> pd.DataFrame:\n",
    "        dummy_columns = pd.get_dummies(self.data, columns=columns).astype(float)\n",
    "        return dummy_columns\n",
    "\n",
    "    def prepare_for_training(self) -> None:\n",
    "        self.data = self.get_data_as_pandas()\n",
    "        self._multiply_data()\n",
    "        self.shuffle()\n",
    "        self._to_tensor()\n",
    "\n",
    "    def _scale_data(self) -> None:\n",
    "        for column in self.data:\n",
    "            if column not in COLUMNS_TO_DUMMY and column != OUTPUT_COLUMN:\n",
    "                self.data[column] = self.scaler.fit_transform(\n",
    "                    self.data[column].values.reshape(-1, 1)\n",
    "                )\n",
    "\n",
    "    def _prepare_data(self) -> None:\n",
    "        self.data = self._to_dummy_columns(columns=COLUMNS_TO_DUMMY)\n",
    "        if self.scaler:\n",
    "            self._scale_data()\n",
    "\n",
    "    def _to_tensor(self) -> None:\n",
    "        self.headers = list(self.data.columns)\n",
    "        if OUTPUT_COLUMN in self.headers:\n",
    "            self.label = torch.tensor(self.data.iloc[:,0].values, dtype=torch.float32)\n",
    "            self.data = torch.tensor(self.data.iloc[:, 1:].values, dtype=torch.float32)\n",
    "        else:\n",
    "            self.data = torch.tensor(self.data.values, dtype=torch.float32)\n",
    "            self.label = None\n",
    "        self.size = self.data.shape[0]\n",
    "\n",
    "    def get_data_as_pandas(self) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        data = pd.DataFrame(self.data.numpy())\n",
    "        labels = pd.DataFrame(self.label.numpy())\n",
    "        df = pd.concat([labels, data], axis=1)\n",
    "        df.columns = self.headers\n",
    "        return df\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def _multiply_data(self) -> None:\n",
    "        return\n",
    "\n",
    "\n",
    "    def shuffle(self):\n",
    "        self.data.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "id": "ce520d3db778c4d7",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T00:12:18.710018Z",
     "start_time": "2024-03-25T00:12:18.686819Z"
    }
   },
   "outputs": [],
   "source": [
    "class HouseDatasetClassification(HouseDataset):\n",
    "    def __init__(self, path_to_csv: str, scaler=None) -> None:\n",
    "        super().__init__(path_to_csv, scaler)\n",
    "        print(self.label)\n",
    "        if self.label is not None:\n",
    "            self._classify_data()\n",
    "\n",
    "    def _classify_data(self) -> None:\n",
    "        self.label = torch.where(\n",
    "            self.label > CRITERIUM_MAX_AVERAGE,\n",
    "            torch.tensor(2),\n",
    "            torch.where(\n",
    "                (self.label > CRITERIUM_MAX_CHEAP)\n",
    "                & (self.label <= CRITERIUM_MAX_AVERAGE),\n",
    "                torch.tensor(1),\n",
    "                torch.tensor(0),\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def _multiply_data(self) -> None:\n",
    "        ros = RandomOverSampler()\n",
    "        x, y = ros.fit_resample(self.data.iloc[:,1:], self.data[OUTPUT_COLUMN])\n",
    "        self.data = pd.concat([y, x], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "f8aee51640d8ca69",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T22:11:38.879738Z",
     "start_time": "2024-03-24T22:11:38.877783Z"
    }
   },
   "outputs": [],
   "source": [
    "train_path = \"../data/split_train_data/train_data.csv\"\n",
    "val_path = \"../data/split_train_data/val_data.csv\"\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "20699de6d6f88cd0",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T22:11:38.921327Z",
     "start_time": "2024-03-24T22:11:38.880194Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset_classify = HouseDatasetClassification(train_path, scaler)\n",
    "train_dataset_classify.prepare_for_training()\n",
    "train_dataset_classify_df = train_dataset_classify.get_data_as_pandas()\n",
    "\n",
    "val_dataset_classify = HouseDatasetClassification(val_path, scaler)\n",
    "# train_dataset_classify_df = train_dataset_classify.get_data_as_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "8acb2d4740a9dc5b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T22:11:38.924591Z",
     "start_time": "2024-03-24T22:11:38.922425Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "48326919b8e303f2",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T22:11:38.937259Z",
     "start_time": "2024-03-24T22:11:38.927825Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      SalePrice  YearBuilt  Size(sqf)     Floor  N_Parkinglot(Ground)  \\\n0           0.0   0.202324  -1.019485  0.641248             -0.571717   \n1           1.0   0.432564  -0.245248 -0.400815             -0.886559   \n2           2.0   1.353523  -0.124927 -0.661331             -0.064211   \n3           0.0  -1.294234  -1.009022  0.120216              0.053267   \n4           1.0  -1.179114   1.279685  1.683310              1.571086   \n...         ...        ...        ...       ...                   ...   \n6010        2.0   1.238403   0.340661 -0.400815             -0.463637   \n6011        2.0   0.432564   1.781893  0.641248             -0.886559   \n6012        2.0   1.238403   0.759168  0.250474              1.307935   \n6013        2.0   0.432564   1.781893 -1.312620             -0.886559   \n6014        2.0   0.432564   1.904829  0.120216             -0.853665   \n\n      N_Parkinglot(Basement)  N_manager  N_elevators  N_FacilitiesInApt  \\\n0                   0.535631  -0.096317    -1.424494           0.480494   \n1                   1.687585   2.379252     0.650023           1.751334   \n2                   1.812055   0.522575     1.687281           1.751334   \n3                  -1.411954  -0.405763    -0.127921          -1.213960   \n4                  -0.103802   0.522575     1.168652          -0.790347   \n...                      ...        ...          ...                ...   \n6010                1.453289   0.213129     1.168652           1.327721   \n6011                1.687585   2.379252     0.650023           1.751334   \n6012               -0.916516  -0.405763     0.131394           1.751334   \n6013                1.687585   2.379252     0.650023           1.751334   \n6014                0.064598  -0.405763    -0.776208          -0.366733   \n\n      N_FacilitiesNearBy(Total)  ...  TimeToSubway_5min~10min  \\\n0                      0.928305  ...                 2.021979   \n1                     -0.232155  ...                -0.494565   \n2                     -1.102500  ...                 2.021979   \n3                      1.798650  ...                -0.494565   \n4                      1.218420  ...                -0.494565   \n...                         ...  ...                      ...   \n6010                   1.218420  ...                -0.494565   \n6011                  -0.232155  ...                -0.494565   \n6012                  -2.843189  ...                -0.494565   \n6013                  -0.232155  ...                -0.494565   \n6014                  -0.232155  ...                -0.494565   \n\n      TimeToSubway_no_bus_stop_nearby  SubwayStation_Bangoge  \\\n0                           -0.199736               2.634323   \n1                           -0.199736              -0.379604   \n2                           -0.199736              -0.379604   \n3                           -0.199736              -0.379604   \n4                           -0.199736              -0.379604   \n...                               ...                    ...   \n6010                        -0.199736              -0.379604   \n6011                        -0.199736              -0.379604   \n6012                        -0.199736              -0.379604   \n6013                        -0.199736              -0.379604   \n6014                        -0.199736              -0.379604   \n\n      SubwayStation_Banwoldang  SubwayStation_Chil-sung-market  \\\n0                    -0.378980                       -0.153989   \n1                    -0.378980                       -0.153989   \n2                    -0.378980                       -0.153989   \n3                    -0.378980                       -0.153989   \n4                    -0.378980                       -0.153989   \n...                        ...                             ...   \n6010                 -0.378980                       -0.153989   \n6011                 -0.378980                       -0.153989   \n6012                  2.638662                       -0.153989   \n6013                 -0.378980                       -0.153989   \n6014                  2.638662                       -0.153989   \n\n      SubwayStation_Daegu  SubwayStation_Kyungbuk_uni_hospital  \\\n0               -0.130117                            -0.617098   \n1               -0.130117                             1.620489   \n2               -0.130117                            -0.617098   \n3               -0.130117                            -0.617098   \n4               -0.130117                            -0.617098   \n...                   ...                                  ...   \n6010            -0.130117                            -0.617098   \n6011            -0.130117                             1.620489   \n6012            -0.130117                            -0.617098   \n6013            -0.130117                             1.620489   \n6014            -0.130117                            -0.617098   \n\n      SubwayStation_Myung-duk  SubwayStation_Sin-nam  \\\n0                   -0.580833              -0.351607   \n1                   -0.580833              -0.351607   \n2                   -0.580833              -0.351607   \n3                    1.721666              -0.351607   \n4                    1.721666              -0.351607   \n...                       ...                    ...   \n6010                 1.721666              -0.351607   \n6011                -0.580833              -0.351607   \n6012                -0.580833              -0.351607   \n6013                -0.580833              -0.351607   \n6014                -0.580833              -0.351607   \n\n      SubwayStation_no_subway_nearby  \n0                          -0.275562  \n1                          -0.275562  \n2                           3.628943  \n3                          -0.275562  \n4                          -0.275562  \n...                              ...  \n6010                       -0.275562  \n6011                       -0.275562  \n6012                       -0.275562  \n6013                       -0.275562  \n6014                       -0.275562  \n\n[6015 rows x 34 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SalePrice</th>\n      <th>YearBuilt</th>\n      <th>Size(sqf)</th>\n      <th>Floor</th>\n      <th>N_Parkinglot(Ground)</th>\n      <th>N_Parkinglot(Basement)</th>\n      <th>N_manager</th>\n      <th>N_elevators</th>\n      <th>N_FacilitiesInApt</th>\n      <th>N_FacilitiesNearBy(Total)</th>\n      <th>...</th>\n      <th>TimeToSubway_5min~10min</th>\n      <th>TimeToSubway_no_bus_stop_nearby</th>\n      <th>SubwayStation_Bangoge</th>\n      <th>SubwayStation_Banwoldang</th>\n      <th>SubwayStation_Chil-sung-market</th>\n      <th>SubwayStation_Daegu</th>\n      <th>SubwayStation_Kyungbuk_uni_hospital</th>\n      <th>SubwayStation_Myung-duk</th>\n      <th>SubwayStation_Sin-nam</th>\n      <th>SubwayStation_no_subway_nearby</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.202324</td>\n      <td>-1.019485</td>\n      <td>0.641248</td>\n      <td>-0.571717</td>\n      <td>0.535631</td>\n      <td>-0.096317</td>\n      <td>-1.424494</td>\n      <td>0.480494</td>\n      <td>0.928305</td>\n      <td>...</td>\n      <td>2.021979</td>\n      <td>-0.199736</td>\n      <td>2.634323</td>\n      <td>-0.378980</td>\n      <td>-0.153989</td>\n      <td>-0.130117</td>\n      <td>-0.617098</td>\n      <td>-0.580833</td>\n      <td>-0.351607</td>\n      <td>-0.275562</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>0.432564</td>\n      <td>-0.245248</td>\n      <td>-0.400815</td>\n      <td>-0.886559</td>\n      <td>1.687585</td>\n      <td>2.379252</td>\n      <td>0.650023</td>\n      <td>1.751334</td>\n      <td>-0.232155</td>\n      <td>...</td>\n      <td>-0.494565</td>\n      <td>-0.199736</td>\n      <td>-0.379604</td>\n      <td>-0.378980</td>\n      <td>-0.153989</td>\n      <td>-0.130117</td>\n      <td>1.620489</td>\n      <td>-0.580833</td>\n      <td>-0.351607</td>\n      <td>-0.275562</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.0</td>\n      <td>1.353523</td>\n      <td>-0.124927</td>\n      <td>-0.661331</td>\n      <td>-0.064211</td>\n      <td>1.812055</td>\n      <td>0.522575</td>\n      <td>1.687281</td>\n      <td>1.751334</td>\n      <td>-1.102500</td>\n      <td>...</td>\n      <td>2.021979</td>\n      <td>-0.199736</td>\n      <td>-0.379604</td>\n      <td>-0.378980</td>\n      <td>-0.153989</td>\n      <td>-0.130117</td>\n      <td>-0.617098</td>\n      <td>-0.580833</td>\n      <td>-0.351607</td>\n      <td>3.628943</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>-1.294234</td>\n      <td>-1.009022</td>\n      <td>0.120216</td>\n      <td>0.053267</td>\n      <td>-1.411954</td>\n      <td>-0.405763</td>\n      <td>-0.127921</td>\n      <td>-1.213960</td>\n      <td>1.798650</td>\n      <td>...</td>\n      <td>-0.494565</td>\n      <td>-0.199736</td>\n      <td>-0.379604</td>\n      <td>-0.378980</td>\n      <td>-0.153989</td>\n      <td>-0.130117</td>\n      <td>-0.617098</td>\n      <td>1.721666</td>\n      <td>-0.351607</td>\n      <td>-0.275562</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>-1.179114</td>\n      <td>1.279685</td>\n      <td>1.683310</td>\n      <td>1.571086</td>\n      <td>-0.103802</td>\n      <td>0.522575</td>\n      <td>1.168652</td>\n      <td>-0.790347</td>\n      <td>1.218420</td>\n      <td>...</td>\n      <td>-0.494565</td>\n      <td>-0.199736</td>\n      <td>-0.379604</td>\n      <td>-0.378980</td>\n      <td>-0.153989</td>\n      <td>-0.130117</td>\n      <td>-0.617098</td>\n      <td>1.721666</td>\n      <td>-0.351607</td>\n      <td>-0.275562</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6010</th>\n      <td>2.0</td>\n      <td>1.238403</td>\n      <td>0.340661</td>\n      <td>-0.400815</td>\n      <td>-0.463637</td>\n      <td>1.453289</td>\n      <td>0.213129</td>\n      <td>1.168652</td>\n      <td>1.327721</td>\n      <td>1.218420</td>\n      <td>...</td>\n      <td>-0.494565</td>\n      <td>-0.199736</td>\n      <td>-0.379604</td>\n      <td>-0.378980</td>\n      <td>-0.153989</td>\n      <td>-0.130117</td>\n      <td>-0.617098</td>\n      <td>1.721666</td>\n      <td>-0.351607</td>\n      <td>-0.275562</td>\n    </tr>\n    <tr>\n      <th>6011</th>\n      <td>2.0</td>\n      <td>0.432564</td>\n      <td>1.781893</td>\n      <td>0.641248</td>\n      <td>-0.886559</td>\n      <td>1.687585</td>\n      <td>2.379252</td>\n      <td>0.650023</td>\n      <td>1.751334</td>\n      <td>-0.232155</td>\n      <td>...</td>\n      <td>-0.494565</td>\n      <td>-0.199736</td>\n      <td>-0.379604</td>\n      <td>-0.378980</td>\n      <td>-0.153989</td>\n      <td>-0.130117</td>\n      <td>1.620489</td>\n      <td>-0.580833</td>\n      <td>-0.351607</td>\n      <td>-0.275562</td>\n    </tr>\n    <tr>\n      <th>6012</th>\n      <td>2.0</td>\n      <td>1.238403</td>\n      <td>0.759168</td>\n      <td>0.250474</td>\n      <td>1.307935</td>\n      <td>-0.916516</td>\n      <td>-0.405763</td>\n      <td>0.131394</td>\n      <td>1.751334</td>\n      <td>-2.843189</td>\n      <td>...</td>\n      <td>-0.494565</td>\n      <td>-0.199736</td>\n      <td>-0.379604</td>\n      <td>2.638662</td>\n      <td>-0.153989</td>\n      <td>-0.130117</td>\n      <td>-0.617098</td>\n      <td>-0.580833</td>\n      <td>-0.351607</td>\n      <td>-0.275562</td>\n    </tr>\n    <tr>\n      <th>6013</th>\n      <td>2.0</td>\n      <td>0.432564</td>\n      <td>1.781893</td>\n      <td>-1.312620</td>\n      <td>-0.886559</td>\n      <td>1.687585</td>\n      <td>2.379252</td>\n      <td>0.650023</td>\n      <td>1.751334</td>\n      <td>-0.232155</td>\n      <td>...</td>\n      <td>-0.494565</td>\n      <td>-0.199736</td>\n      <td>-0.379604</td>\n      <td>-0.378980</td>\n      <td>-0.153989</td>\n      <td>-0.130117</td>\n      <td>1.620489</td>\n      <td>-0.580833</td>\n      <td>-0.351607</td>\n      <td>-0.275562</td>\n    </tr>\n    <tr>\n      <th>6014</th>\n      <td>2.0</td>\n      <td>0.432564</td>\n      <td>1.904829</td>\n      <td>0.120216</td>\n      <td>-0.853665</td>\n      <td>0.064598</td>\n      <td>-0.405763</td>\n      <td>-0.776208</td>\n      <td>-0.366733</td>\n      <td>-0.232155</td>\n      <td>...</td>\n      <td>-0.494565</td>\n      <td>-0.199736</td>\n      <td>-0.379604</td>\n      <td>2.638662</td>\n      <td>-0.153989</td>\n      <td>-0.130117</td>\n      <td>-0.617098</td>\n      <td>-0.580833</td>\n      <td>-0.351607</td>\n      <td>-0.275562</td>\n    </tr>\n  </tbody>\n</table>\n<p>6015 rows × 34 columns</p>\n</div>"
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_classify_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "6a39122fcd9b551a",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T22:11:38.941502Z",
     "start_time": "2024-03-24T22:11:38.937970Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "SalePrice\n0.0    2005\n1.0    2005\n2.0    2005\nName: count, dtype: int64"
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_classify_df.iloc[:, 0].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59399c3c77e0dd2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "4c06a57a2790ba07",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T22:11:38.945315Z",
     "start_time": "2024-03-24T22:11:38.942427Z"
    }
   },
   "outputs": [],
   "source": [
    "class HousingClassificationModel(nn.Module):\n",
    "    def __init__(self, input_size: int, class_num: int) -> None:\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 36)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.gelu = nn.LeakyReLU()\n",
    "        self.fc2 = nn.Linear(36, 24)\n",
    "        self.bn2 = nn.BatchNorm1d(32)\n",
    "        self.fc3 = nn.Linear(24,  class_num)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x: torch.tensor) -> torch.tensor:\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.dropout(x)\n",
    "        # x = self.bn2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e97ae93face9a6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "####  Prepare loaders and set batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "ea89e4426bdf2b31",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T22:11:38.948230Z",
     "start_time": "2024-03-24T22:11:38.946106Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_loader_classify = data.DataLoader(train_dataset_classify, batch_size=batch_size, shuffle=True)\n",
    "validation_loader_classify = data.DataLoader(val_dataset_classify, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "d0dd85e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T22:11:38.952327Z",
     "start_time": "2024-03-24T22:11:38.949Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0., 1., 2.,  ..., 2., 2., 2.])"
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_classify.label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d05f35242e7f1b9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Set up the model, optimizer and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "c54d4b07b52dca9d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T22:11:38.956181Z",
     "start_time": "2024-03-24T22:11:38.953010Z"
    }
   },
   "outputs": [],
   "source": [
    "model_classify = HousingClassificationModel(input_size=train_dataset_classify.data.shape[1], class_num=3)\n",
    "optimizer = torch.optim.Adam(model_classify.parameters(), lr=0.0001)\n",
    "loss_fn_classify = nn.CrossEntropyLoss(torch.tensor([0.7,2.4, 1.12]))\n",
    "mca = MulticlassAccuracy(num_classes=3, average=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36824f8da5825829",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "c81432a52316cf45",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T22:11:40.114445Z",
     "start_time": "2024-03-24T22:11:38.957244Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/420 [00:01<07:04,  1.01s/it, Epoch=1, Los in train={1.0588156238515327}, Loss in eval={1.020615551360818}, f1 in train={0.5430089653397392}, f1 in eval={0.5681002051983585}]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[545], line 21\u001B[0m\n\u001B[1;32m     19\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m     20\u001B[0m     train_batch_accuracy_sum \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m mca(torch\u001B[38;5;241m.\u001B[39margmax(model_output, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m), label)\n\u001B[0;32m---> 21\u001B[0m     train_batch_f1_score_sum \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43mf1_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margmax\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_output\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maverage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmicro\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     23\u001B[0m train_batch_loss_avg \u001B[38;5;241m=\u001B[39m train_batch_loss_sum \u001B[38;5;241m/\u001B[39m t_batch_num\n\u001B[1;32m     24\u001B[0m train_batch_accuracy_avg \u001B[38;5;241m=\u001B[39m train_batch_accuracy_sum \u001B[38;5;241m/\u001B[39m t_batch_num\n",
      "File \u001B[0;32m~/SSNEProjects/SNNE/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:213\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    207\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    208\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m    209\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m    210\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m    211\u001B[0m         )\n\u001B[1;32m    212\u001B[0m     ):\n\u001B[0;32m--> 213\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    214\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    215\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[1;32m    217\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[1;32m    219\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[1;32m    220\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    221\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    222\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[1;32m    223\u001B[0m     )\n",
      "File \u001B[0;32m~/SSNEProjects/SNNE/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1271\u001B[0m, in \u001B[0;36mf1_score\u001B[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001B[0m\n\u001B[1;32m   1091\u001B[0m \u001B[38;5;129m@validate_params\u001B[39m(\n\u001B[1;32m   1092\u001B[0m     {\n\u001B[1;32m   1093\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_true\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marray-like\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msparse matrix\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1118\u001B[0m     zero_division\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwarn\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1119\u001B[0m ):\n\u001B[1;32m   1120\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Compute the F1 score, also known as balanced F-score or F-measure.\u001B[39;00m\n\u001B[1;32m   1121\u001B[0m \n\u001B[1;32m   1122\u001B[0m \u001B[38;5;124;03m    The F1 score can be interpreted as a harmonic mean of the precision and\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1269\u001B[0m \u001B[38;5;124;03m    array([0.66666667, 1.        , 0.66666667])\u001B[39;00m\n\u001B[1;32m   1270\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1271\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfbeta_score\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1272\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1273\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1274\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeta\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1275\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1276\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpos_label\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpos_label\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1277\u001B[0m \u001B[43m        \u001B[49m\u001B[43maverage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maverage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1278\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1279\u001B[0m \u001B[43m        \u001B[49m\u001B[43mzero_division\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mzero_division\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1280\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/SSNEProjects/SNNE/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:186\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    184\u001B[0m global_skip_validation \u001B[38;5;241m=\u001B[39m get_config()[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mskip_parameter_validation\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    185\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m global_skip_validation:\n\u001B[0;32m--> 186\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    188\u001B[0m func_sig \u001B[38;5;241m=\u001B[39m signature(func)\n\u001B[1;32m    190\u001B[0m \u001B[38;5;66;03m# Map *args/**kwargs to the function signature\u001B[39;00m\n",
      "File \u001B[0;32m~/SSNEProjects/SNNE/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1463\u001B[0m, in \u001B[0;36mfbeta_score\u001B[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001B[0m\n\u001B[1;32m   1283\u001B[0m \u001B[38;5;129m@validate_params\u001B[39m(\n\u001B[1;32m   1284\u001B[0m     {\n\u001B[1;32m   1285\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_true\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marray-like\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msparse matrix\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1312\u001B[0m     zero_division\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwarn\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1313\u001B[0m ):\n\u001B[1;32m   1314\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Compute the F-beta score.\u001B[39;00m\n\u001B[1;32m   1315\u001B[0m \n\u001B[1;32m   1316\u001B[0m \u001B[38;5;124;03m    The F-beta score is the weighted harmonic mean of precision and recall,\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1460\u001B[0m \u001B[38;5;124;03m    0.12...\u001B[39;00m\n\u001B[1;32m   1461\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1463\u001B[0m     _, _, f, _ \u001B[38;5;241m=\u001B[39m \u001B[43mprecision_recall_fscore_support\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1464\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1465\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1466\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeta\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1467\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1468\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpos_label\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpos_label\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1469\u001B[0m \u001B[43m        \u001B[49m\u001B[43maverage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maverage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1470\u001B[0m \u001B[43m        \u001B[49m\u001B[43mwarn_for\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mf-score\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1471\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1472\u001B[0m \u001B[43m        \u001B[49m\u001B[43mzero_division\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mzero_division\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1473\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1474\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m f\n",
      "File \u001B[0;32m~/SSNEProjects/SNNE/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:186\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    184\u001B[0m global_skip_validation \u001B[38;5;241m=\u001B[39m get_config()[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mskip_parameter_validation\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    185\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m global_skip_validation:\n\u001B[0;32m--> 186\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    188\u001B[0m func_sig \u001B[38;5;241m=\u001B[39m signature(func)\n\u001B[1;32m    190\u001B[0m \u001B[38;5;66;03m# Map *args/**kwargs to the function signature\u001B[39;00m\n",
      "File \u001B[0;32m~/SSNEProjects/SNNE/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1767\u001B[0m, in \u001B[0;36mprecision_recall_fscore_support\u001B[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001B[0m\n\u001B[1;32m   1604\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Compute precision, recall, F-measure and support for each class.\u001B[39;00m\n\u001B[1;32m   1605\u001B[0m \n\u001B[1;32m   1606\u001B[0m \u001B[38;5;124;03mThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1764\u001B[0m \u001B[38;5;124;03m array([2, 2, 2]))\u001B[39;00m\n\u001B[1;32m   1765\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1766\u001B[0m _check_zero_division(zero_division)\n\u001B[0;32m-> 1767\u001B[0m labels \u001B[38;5;241m=\u001B[39m \u001B[43m_check_set_wise_labels\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maverage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpos_label\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1769\u001B[0m \u001B[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001B[39;00m\n\u001B[1;32m   1770\u001B[0m samplewise \u001B[38;5;241m=\u001B[39m average \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msamples\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[0;32m~/SSNEProjects/SNNE/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1539\u001B[0m, in \u001B[0;36m_check_set_wise_labels\u001B[0;34m(y_true, y_pred, average, labels, pos_label)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m average \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m average_options \u001B[38;5;129;01mand\u001B[39;00m average \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m   1537\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maverage has to be one of \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(average_options))\n\u001B[0;32m-> 1539\u001B[0m y_type, y_true, y_pred \u001B[38;5;241m=\u001B[39m \u001B[43m_check_targets\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1540\u001B[0m \u001B[38;5;66;03m# Convert to Python primitive type to avoid NumPy type / Python str\u001B[39;00m\n\u001B[1;32m   1541\u001B[0m \u001B[38;5;66;03m# comparison. See https://github.com/numpy/numpy/issues/6784\u001B[39;00m\n\u001B[1;32m   1542\u001B[0m present_labels \u001B[38;5;241m=\u001B[39m unique_labels(y_true, y_pred)\u001B[38;5;241m.\u001B[39mtolist()\n",
      "File \u001B[0;32m~/SSNEProjects/SNNE/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:87\u001B[0m, in \u001B[0;36m_check_targets\u001B[0;34m(y_true, y_pred)\u001B[0m\n\u001B[1;32m     85\u001B[0m check_consistent_length(y_true, y_pred)\n\u001B[1;32m     86\u001B[0m type_true \u001B[38;5;241m=\u001B[39m type_of_target(y_true, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_true\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 87\u001B[0m type_pred \u001B[38;5;241m=\u001B[39m \u001B[43mtype_of_target\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43my_pred\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     89\u001B[0m y_type \u001B[38;5;241m=\u001B[39m {type_true, type_pred}\n\u001B[1;32m     90\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y_type \u001B[38;5;241m==\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmulticlass\u001B[39m\u001B[38;5;124m\"\u001B[39m}:\n",
      "File \u001B[0;32m~/SSNEProjects/SNNE/venv/lib/python3.11/site-packages/sklearn/utils/multiclass.py:385\u001B[0m, in \u001B[0;36mtype_of_target\u001B[0;34m(y, input_name)\u001B[0m\n\u001B[1;32m    382\u001B[0m     suffix \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m  \u001B[38;5;66;03m# [1, 2, 3] or [[1], [2], [3]]\u001B[39;00m\n\u001B[1;32m    384\u001B[0m \u001B[38;5;66;03m# Check float and contains non-integer float values\u001B[39;00m\n\u001B[0;32m--> 385\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mxp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43misdtype\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mreal floating\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m:\n\u001B[1;32m    386\u001B[0m     \u001B[38;5;66;03m# [.1, .2, 3] or [[.1, .2, 3]] or [[1., .2]] and not [1., 2., 3.]\u001B[39;00m\n\u001B[1;32m    387\u001B[0m     data \u001B[38;5;241m=\u001B[39m y\u001B[38;5;241m.\u001B[39mdata \u001B[38;5;28;01mif\u001B[39;00m issparse(y) \u001B[38;5;28;01melse\u001B[39;00m y\n\u001B[1;32m    388\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m xp\u001B[38;5;241m.\u001B[39many(data \u001B[38;5;241m!=\u001B[39m xp\u001B[38;5;241m.\u001B[39mastype(data, \u001B[38;5;28mint\u001B[39m)):\n",
      "File \u001B[0;32m~/SSNEProjects/SNNE/venv/lib/python3.11/site-packages/sklearn/utils/_array_api.py:327\u001B[0m, in \u001B[0;36m_NumPyAPIWrapper.isdtype\u001B[0;34m(self, dtype, kind)\u001B[0m\n\u001B[1;32m    324\u001B[0m         x \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[1;32m    325\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m numpy\u001B[38;5;241m.\u001B[39mreshape(x, shape)\n\u001B[0;32m--> 327\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21misdtype\u001B[39m(\u001B[38;5;28mself\u001B[39m, dtype, kind):\n\u001B[1;32m    328\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m isdtype(dtype, kind, xp\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS_NUMBER = 420\n",
    "train_losses, train_accuracies, val_losses, val_accuracies, train_f1_scores, val_f1_scores = [], [], [], [], [], []\n",
    "tqdm_progress = tqdm(range(EPOCHS_NUMBER))\n",
    "\n",
    "t_batch_num, v_batch_num = len(train_loader_classify), len(validation_loader_classify)\n",
    "\n",
    "for epoch in tqdm_progress:\n",
    "    train_batch_loss_sum, val_batch_loss_sum = 0, 0\n",
    "    train_batch_accuracy_sum, val_batch_accuracy_sum = 0, 0\n",
    "    train_batch_f1_score_sum, val_batch_f1_score_sum = 0, 0\n",
    "\n",
    "    model_classify.train()\n",
    "    for data_patch, label in train_loader_classify:\n",
    "        model_output = model_classify(data_patch).squeeze()\n",
    "        loss = loss_fn_classify(model_output, label.type(torch.LongTensor))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_batch_loss_sum += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        train_batch_accuracy_sum += mca(torch.argmax(model_output, dim=1), label)\n",
    "        train_batch_f1_score_sum += f1_score(torch.argmax(model_output, dim=1), label, average=\"micro\")\n",
    "\n",
    "    train_batch_loss_avg = train_batch_loss_sum / t_batch_num\n",
    "    train_batch_accuracy_avg = train_batch_accuracy_sum / t_batch_num\n",
    "    train_batch_f1_score_avg = train_batch_f1_score_sum / t_batch_num\n",
    "\n",
    "    train_losses.append(train_batch_loss_avg)\n",
    "    train_accuracies.append(train_batch_accuracy_avg)\n",
    "    train_f1_scores.append(train_batch_f1_score_avg)\n",
    "    \n",
    "    model_classify.eval()\n",
    "    for val_inputs, val_labels in validation_loader_classify:\n",
    "        val_predicts = model_classify(val_inputs).squeeze(dim=1)\n",
    "        val_loss = loss_fn_classify(val_predicts, val_labels.type(torch.LongTensor))\n",
    "        val_batch_loss_sum += val_loss.item()\n",
    "        val_batch_accuracy_sum += mca(torch.argmax(val_predicts, dim=1), val_labels)\n",
    "        val_batch_f1_score_sum += f1_score(\n",
    "            torch.argmax(val_predicts, dim=1), val_labels, average=\"micro\"\n",
    "        )\n",
    "    val_batch_loss_avg = val_batch_loss_sum / v_batch_num\n",
    "    val_batch_accuracy_avg = val_batch_accuracy_sum / v_batch_num\n",
    "    val_batch_f1_score_avg = val_batch_f1_score_sum / v_batch_num\n",
    "    \n",
    "    val_accuracies.append(val_batch_accuracy_avg)\n",
    "    val_losses.append(val_batch_loss_avg)\n",
    "    val_f1_scores.append(val_batch_f1_score_avg)\n",
    "    \n",
    "    tqdm_progress.set_postfix(\n",
    "        {\n",
    "            \"Epoch\": epoch + 1,\n",
    "            \"Los in train\": {train_batch_loss_avg},\n",
    "            \"Loss in eval\": {val_batch_loss_avg},\n",
    "            \"f1 in train\": {train_batch_f1_score_avg},\n",
    "            \"f1 in eval\": {val_batch_f1_score_avg},\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8599f87fc5af03c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    predicts_train = model_classify(train_dataset_classify.data.clone().detach())\n",
    "    predicts_val = model_classify(val_dataset_classify.data.clone().detach())\n",
    "    predicted_argmax_train = torch.argmax(predicts_train, dim=1)\n",
    "    predicted_argmax_val = torch.argmax(predicts_val, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "val_accuracies"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c785dc2c57333e4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe524b179b0f4f8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(train_accuracies, label=\"Train\")\n",
    "plt.plot(val_accuracies, label=\"Validation\")\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985842ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_f1_scores, label=\"Train\")\n",
    "plt.plot(val_f1_scores, label=\"Validation\")\n",
    "plt.legend()\n",
    "plt.title(\"F1 score\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"F1 score\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "val_accuracies"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed18c3b931d4b3bb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385eb2c9f8c8b80",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_accuracies_mean = [tensor.mean().item() for tensor in train_accuracies]\n",
    "val_accuracies_mean = [tensor.mean().item() for tensor in val_accuracies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7441384eced5bc",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(train_accuracies_mean, label=\"Train\")\n",
    "plt.plot(val_accuracies_mean, label=\"Validation\")\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy mean for all classes\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb0251d86dc3076",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conf_matrix_val = confusion_matrix(val_dataset_classify.label, predicted_argmax_val)\n",
    "ConfusionMatrixDisplay(conf_matrix_val).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61734f42ad80fda",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f1_score(val_dataset_classify.label, predicted_argmax_val, average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f38cd2d5e81d477",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mca(predicted_argmax_val, val_dataset_classify.label)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "torch.save(model_classify.state_dict(), \"../final_models/classification_model_without_cv.pth\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f61338a4911f105",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "mca(predicted_argmax_train, train_dataset_classify.label)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac03fe64db64588c",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train on whole dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a7e617162bf45741"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "whole_dataset_classify = HouseDatasetClassification(\"../data/train_data.csv\", scaler)\n",
    "whole_dataset_classify.prepare_for_training()\n",
    "whole_loader_classify = data.DataLoader(whole_dataset_classify, batch_size=batch_size, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T23:00:37.064002Z",
     "start_time": "2024-03-24T23:00:36.955847Z"
    }
   },
   "id": "563f255c6876ae03",
   "execution_count": 589
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = HousingClassificationModel(input_size=whole_dataset_classify.data.shape[1], class_num=3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T23:00:37.405474Z",
     "start_time": "2024-03-24T23:00:37.393695Z"
    }
   },
   "id": "e167bfba5573bd56",
   "execution_count": 590
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "loss_fn_classify = nn.CrossEntropyLoss(torch.tensor([0.7,2.4, 1.12]))\n",
    "mca = MulticlassAccuracy(num_classes=3, average=None)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T23:27:57.222811Z",
     "start_time": "2024-03-24T23:27:57.205784Z"
    }
   },
   "id": "11506e90ac8094cb",
   "execution_count": 603
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 57/420 [00:19<02:06,  2.87it/s, Epoch=57, Los in train={0.28480964647175155}, f1 in train={0.8724421708185054}]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[604], line 17\u001B[0m\n\u001B[1;32m     15\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_fn_classify(model_output, label\u001B[38;5;241m.\u001B[39mtype(torch\u001B[38;5;241m.\u001B[39mLongTensor))\n\u001B[1;32m     16\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m---> 17\u001B[0m \u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     18\u001B[0m train_batch_loss_sum \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n\u001B[1;32m     19\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n",
      "File \u001B[0;32m~/SSNEProjects/SNNE/venv/lib/python3.11/site-packages/torch/optim/optimizer.py:385\u001B[0m, in \u001B[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    380\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    381\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    382\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    383\u001B[0m             )\n\u001B[0;32m--> 385\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    386\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_optimizer_step_code()\n\u001B[1;32m    388\u001B[0m \u001B[38;5;66;03m# call optimizer step post hooks\u001B[39;00m\n",
      "File \u001B[0;32m~/SSNEProjects/SNNE/venv/lib/python3.11/site-packages/torch/optim/optimizer.py:76\u001B[0m, in \u001B[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     74\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefaults[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m     75\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n\u001B[0;32m---> 76\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     78\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n",
      "File \u001B[0;32m~/SSNEProjects/SNNE/venv/lib/python3.11/site-packages/torch/optim/adam.py:166\u001B[0m, in \u001B[0;36mAdam.step\u001B[0;34m(self, closure)\u001B[0m\n\u001B[1;32m    155\u001B[0m     beta1, beta2 \u001B[38;5;241m=\u001B[39m group[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbetas\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m    157\u001B[0m     has_complex \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_group(\n\u001B[1;32m    158\u001B[0m         group,\n\u001B[1;32m    159\u001B[0m         params_with_grad,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    163\u001B[0m         max_exp_avg_sqs,\n\u001B[1;32m    164\u001B[0m         state_steps)\n\u001B[0;32m--> 166\u001B[0m     \u001B[43madam\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    167\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams_with_grad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    168\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    169\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    170\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    171\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    172\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    173\u001B[0m \u001B[43m        \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mamsgrad\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    174\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhas_complex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhas_complex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    175\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    176\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    177\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    178\u001B[0m \u001B[43m        \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mweight_decay\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    179\u001B[0m \u001B[43m        \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43meps\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    180\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmaximize\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    181\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforeach\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mforeach\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    182\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcapturable\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    183\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdifferentiable\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    184\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfused\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mfused\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    185\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgrad_scale\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    186\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfound_inf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    187\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    189\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "File \u001B[0;32m~/SSNEProjects/SNNE/venv/lib/python3.11/site-packages/torch/optim/adam.py:316\u001B[0m, in \u001B[0;36madam\u001B[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001B[0m\n\u001B[1;32m    313\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    314\u001B[0m     func \u001B[38;5;241m=\u001B[39m _single_tensor_adam\n\u001B[0;32m--> 316\u001B[0m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    317\u001B[0m \u001B[43m     \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    318\u001B[0m \u001B[43m     \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    319\u001B[0m \u001B[43m     \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    320\u001B[0m \u001B[43m     \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    321\u001B[0m \u001B[43m     \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    322\u001B[0m \u001B[43m     \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mamsgrad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    323\u001B[0m \u001B[43m     \u001B[49m\u001B[43mhas_complex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhas_complex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    324\u001B[0m \u001B[43m     \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    325\u001B[0m \u001B[43m     \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    326\u001B[0m \u001B[43m     \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    327\u001B[0m \u001B[43m     \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweight_decay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    328\u001B[0m \u001B[43m     \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    329\u001B[0m \u001B[43m     \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaximize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    330\u001B[0m \u001B[43m     \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcapturable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    331\u001B[0m \u001B[43m     \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdifferentiable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    332\u001B[0m \u001B[43m     \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgrad_scale\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    333\u001B[0m \u001B[43m     \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfound_inf\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/SSNEProjects/SNNE/venv/lib/python3.11/site-packages/torch/optim/adam.py:441\u001B[0m, in \u001B[0;36m_single_tensor_adam\u001B[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001B[0m\n\u001B[1;32m    438\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    439\u001B[0m         denom \u001B[38;5;241m=\u001B[39m (exp_avg_sq\u001B[38;5;241m.\u001B[39msqrt() \u001B[38;5;241m/\u001B[39m bias_correction2_sqrt)\u001B[38;5;241m.\u001B[39madd_(eps)\n\u001B[0;32m--> 441\u001B[0m     \u001B[43mparam\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maddcdiv_\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexp_avg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdenom\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43mstep_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    443\u001B[0m \u001B[38;5;66;03m# Lastly, switch back to complex view\u001B[39;00m\n\u001B[1;32m    444\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m amsgrad \u001B[38;5;129;01mand\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mis_complex(params[i]):\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS_NUMBER = 420\n",
    "train_losses, train_accuracies, train_f1_scores =  [], [], []\n",
    "tqdm_progress = tqdm(range(EPOCHS_NUMBER))\n",
    "\n",
    "t_batch_num= len(whole_loader_classify)\n",
    "\n",
    "for epoch in tqdm_progress:\n",
    "    train_batch_loss_sum = 0\n",
    "    train_batch_accuracy_sum = 0\n",
    "    train_batch_f1_score_sum= 0\n",
    "\n",
    "    model.train()\n",
    "    for data_patch, label in whole_loader_classify:\n",
    "        model_output = model(data_patch).squeeze()\n",
    "        loss = loss_fn_classify(model_output, label.type(torch.LongTensor))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_batch_loss_sum += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        train_batch_accuracy_sum += mca(torch.argmax(model_output, dim=1), label)\n",
    "        train_batch_f1_score_sum += f1_score(torch.argmax(model_output, dim=1), label, average=\"micro\")\n",
    "\n",
    "    train_batch_loss_avg = train_batch_loss_sum / t_batch_num\n",
    "    train_batch_accuracy_avg = train_batch_accuracy_sum / t_batch_num\n",
    "    train_batch_f1_score_avg = train_batch_f1_score_sum / t_batch_num\n",
    "\n",
    "    train_losses.append(train_batch_loss_avg)\n",
    "    train_accuracies.append(train_batch_accuracy_avg)\n",
    "    train_f1_scores.append(train_batch_f1_score_avg)\n",
    "    tqdm_progress.set_postfix(\n",
    "        {\n",
    "            \"Epoch\": epoch + 1,\n",
    "            \"Los in train\": {train_batch_loss_avg},\n",
    "            \"f1 in train\": {train_batch_f1_score_avg},\n",
    "        }\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T23:28:17.558186Z",
     "start_time": "2024-03-24T23:27:57.570127Z"
    }
   },
   "id": "975dc3b2e8793cdd",
   "execution_count": 604
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    predicts_whole = model_classify(whole_dataset_classify.data.clone().detach())\n",
    "    predicted_argmax_whole = torch.argmax(predicts_whole, dim=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T23:28:17.559465Z",
     "start_time": "2024-03-24T23:28:17.559314Z"
    }
   },
   "id": "58134649a4b7506d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "conf_matrix_whole= confusion_matrix(whole_dataset_classify.label, predicted_argmax_whole)\n",
    "ConfusionMatrixDisplay(conf_matrix_whole).plot()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92c79e96719b65bf",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "0.6026069518716578"
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(whole_dataset_classify.label, predicted_argmax_whole, average=\"micro\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T23:04:49.056869Z",
     "start_time": "2024-03-24T23:04:49.039001Z"
    }
   },
   "id": "7d1cebc4abe5ac0d",
   "execution_count": 595
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7e91f4b109206a6f"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.2276, 0.7781, 0.8021])"
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mca(predicted_argmax_whole, whole_dataset_classify.label)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T23:04:49.064625Z",
     "start_time": "2024-03-24T23:04:49.059193Z"
    }
   },
   "id": "36b8755b9f9f4261",
   "execution_count": 596
  },
  {
   "cell_type": "markdown",
   "source": [
    " # Load the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ee02058049a2266"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_classify = HousingClassificationModel(input_size=whole_dataset_classify.data.shape[1], class_num=3)\n",
    "model_classify.load_state_dict(torch.load(\"../final_models/classification_model_without_cv.pth\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T23:09:36.427882Z",
     "start_time": "2024-03-24T23:09:36.410232Z"
    }
   },
   "id": "d0bc8cec88f7eef",
   "execution_count": 598
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    predicts_whole = model_classify(whole_dataset_classify.data.clone().detach())\n",
    "    predicted_argmax_whole = torch.argmax(predicts_whole, dim=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T23:09:42.579090Z",
     "start_time": "2024-03-24T23:09:42.554280Z"
    }
   },
   "id": "2ffe10162f3bb8cc",
   "execution_count": 599
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_matrix_whole= confusion_matrix(whole_dataset_classify.label, predicted_argmax_whole)\n",
    "ConfusionMatrixDisplay(conf_matrix_whole).plot()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T23:09:48.469218Z",
     "start_time": "2024-03-24T23:09:47.495508Z"
    }
   },
   "id": "7eab0a980fb2c121",
   "execution_count": 600
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "0.8672014260249554"
     },
     "execution_count": 601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(whole_dataset_classify.label, predicted_argmax_whole, average=\"micro\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T23:09:52.806003Z",
     "start_time": "2024-03-24T23:09:52.794608Z"
    }
   },
   "id": "7cc14dcc22a07992",
   "execution_count": 601
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.9098, 0.8222, 0.8697])"
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mca(predicted_argmax_whole, whole_dataset_classify.label)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T23:09:54.954009Z",
     "start_time": "2024-03-24T23:09:54.937834Z"
    }
   },
   "id": "589b9297462f83a5",
   "execution_count": 602
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Whole dataset predictions - save to csv"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "724cbb1f588447bc"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "test_dataset = HouseDatasetClassification(\"../data/test_data.csv\", scaler)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T00:12:21.964208Z",
     "start_time": "2024-03-25T00:12:21.934760Z"
    }
   },
   "id": "d689edbba670ec96",
   "execution_count": 625
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 626,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_classify_whole = HousingClassificationModel(input_size=whole_dataset_classify.data.shape[1], class_num=3)\n",
    "model_classify_whole.load_state_dict(torch.load(\"../final_models/classification_model_without_cv.pth\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T00:12:22.102011Z",
     "start_time": "2024-03-25T00:12:22.096264Z"
    }
   },
   "id": "7e8d49ed755af804",
   "execution_count": 626
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    predicts_test_whole = model_classify(test_dataset.data.clone().detach())\n",
    "    predicted_argmax_test_whole = torch.argmax(predicts_test_whole, dim=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T00:12:22.435537Z",
     "start_time": "2024-03-25T00:12:22.425783Z"
    }
   },
   "id": "67c3bf25474d88c7",
   "execution_count": 627
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "numpy_data_whole = predicted_argmax_test_whole.numpy()\n",
    "np.savetxt(\"../final_predictions/classification_data_without_cv.csv\", numpy_data_whole, delimiter=\",\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T00:12:22.849Z",
     "start_time": "2024-03-25T00:12:22.841153Z"
    }
   },
   "id": "f1efdc2f4be94d34",
   "execution_count": 628
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d194f10bb6d05003"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
