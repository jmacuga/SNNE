{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:40:46.843225Z",
     "start_time": "2024-03-27T22:40:45.633939Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensory w PyTorchu to specjalne struktury danych które przypominają tablice/macierze. Używamy ich do przechowywania wejśc/wyjść z sieci jak również wag modelu.\n",
    "Tensory przypominają swoją budową tablice numpy https://numpy.org/, z zasadniczą różnicą ktorą jest łatwa możliwość przechowywania i operowania na tensorach na kartach graficznych "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensory mogą być tworzone w różny sposób:\n",
    "1. Ze standardowych tablic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:40:49.346645Z",
     "start_time": "2024-03-27T22:40:49.340110Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1, 2],\n        [3, 4]])"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [[1, 2],[3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "x_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T07:40:32.096100Z",
     "start_time": "2021-10-02T07:40:32.090797Z"
    }
   },
   "source": [
    "2. Na poodstawie tablic numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:40:50.614201Z",
     "start_time": "2024-03-27T22:40:50.610123Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1, 2],\n        [3, 4]])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "x_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Na podstawie innych tensorów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-03-27T22:40:51.606749Z",
     "start_time": "2024-03-27T22:40:51.596395Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.1425, 0.2549],\n",
      "        [0.9787, 0.1370]]) \n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Z losowymi lub stałymi wartościami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:40:52.393259Z",
     "start_time": "2024-03-27T22:40:52.388499Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.8653, 0.7777, 0.1006],\n",
      "        [0.7657, 0.3043, 0.3326]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]]) \n"
     ]
    }
   ],
   "source": [
    "shape = (2,3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "ones_tensor = torch.ones(shape)\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atrybuty tensorów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:40:52.755888Z",
     "start_time": "2024-03-27T22:40:52.752613Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,4)\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operacje na tensorach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nie ma co się bać dokumentacji! (Jest bardzo przyjemnie napisana) Wszystkie operacje na tensorach są opisane tutaj: https://pytorch.org/docs/stable/torch.html\n",
    "Standardowo operacje są uruchamiane na CPU, ale można przenosić tensory, całe modele i **wszystkie operacje** na GPU (co zazwyczaj jest szybsze) za pomocą prostej komendy. Przetestujemy to w kolejnych częściach laboratorium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardowe indeksowanie i slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:40:55.349272Z",
     "start_time": "2024-03-27T22:40:55.343974Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row:  tensor([1., 1., 1., 1.])\n",
      "First column:  tensor([1., 1., 1., 1.])\n",
      "Last column: tensor([1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4, 4)\n",
    "print('First row: ', tensor[0])\n",
    "print('First column: ', tensor[:, 0])\n",
    "print('Last column:', tensor[:, -1])\n",
    "tensor[:,1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transponowanie tensorów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:40:57.939506Z",
     "start_time": "2024-03-27T22:40:57.934857Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 2.],\n",
      "        [1., 0., 2.],\n",
      "        [1., 0., 2.],\n",
      "        [1., 0., 2.]])\n",
      "Tensor shape:torch.Size([4, 3])\n",
      "\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [2., 2., 2., 2.]])\n",
      "Transposed tensor shape:torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4, 3)\n",
    "tensor[:,1] = 0\n",
    "tensor[:,2] = 2\n",
    "print(tensor)\n",
    "print(f\"Tensor shape:{tensor.shape}\\n\")\n",
    "tensor2 = tensor.T\n",
    "print(tensor2)\n",
    "print(f\"Transposed tensor shape:{tensor2.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zmiana wymiarów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:40:59.069378Z",
     "start_time": "2024-03-27T22:40:59.063372Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "Tensor1 shape:torch.Size([10])\n",
      "\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "Tensor2 shape:torch.Size([1, 10])\n",
      "\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]])\n",
      "Tensor3 shape:torch.Size([10, 1])\n",
      "\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n",
      "Tensor4 shape:torch.Size([5, 2])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones([10])\n",
    "print(tensor)\n",
    "print(f\"Tensor1 shape:{tensor.shape}\\n\")\n",
    "\n",
    "tensor2 = tensor.unsqueeze(dim=0)\n",
    "print(tensor2)\n",
    "print(f\"Tensor2 shape:{tensor2.shape}\\n\")\n",
    "\n",
    "tensor3 = tensor.unsqueeze(dim=1)\n",
    "print(tensor3)\n",
    "print(f\"Tensor3 shape:{tensor3.shape}\\n\")\n",
    "\n",
    "tensor4 = tensor.view(5,2)\n",
    "print(tensor4)\n",
    "print(f\"Tensor4 shape:{tensor4.shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Łączenie tensorów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:40:59.611044Z",
     "start_time": "2024-03-27T22:40:59.606697Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4, 4)\n",
    "tensor[:,1] = 0\n",
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:00.072718Z",
     "start_time": "2024-03-27T22:41:00.068708Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.cat([tensor, tensor, tensor], dim=0)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:00.444439Z",
     "start_time": "2024-03-27T22:41:00.440490Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.]],\n",
      "\n",
      "        [[1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.]],\n",
      "\n",
      "        [[1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.stack([tensor, tensor, tensor])\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:00.826592Z",
     "start_time": "2024-03-27T22:41:00.820114Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 4])\n",
      "tensor([[[1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.]],\n",
      "\n",
      "        [[1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.]],\n",
      "\n",
      "        [[1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.]]])\n",
      "torch.Size([4, 3, 4])\n",
      "tensor([[[1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.]],\n",
      "\n",
      "        [[1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.]],\n",
      "\n",
      "        [[1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.]],\n",
      "\n",
      "        [[1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.]]])\n",
      "torch.Size([4, 4, 3])\n",
      "tensor([[[1., 1., 1.],\n",
      "         [0., 0., 0.],\n",
      "         [1., 1., 1.],\n",
      "         [1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.],\n",
      "         [0., 0., 0.],\n",
      "         [1., 1., 1.],\n",
      "         [1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.],\n",
      "         [0., 0., 0.],\n",
      "         [1., 1., 1.],\n",
      "         [1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.],\n",
      "         [0., 0., 0.],\n",
      "         [1., 1., 1.],\n",
      "         [1., 1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.stack([tensor, tensor, tensor],dim=0)\n",
    "print(t1.shape)\n",
    "print(t1)\n",
    "t1 = torch.stack([tensor, tensor, tensor],dim=1)\n",
    "print(t1.shape)\n",
    "print(t1)\n",
    "t1 = torch.stack([tensor, tensor, tensor],dim=2)\n",
    "print(t1.shape)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:01.272974Z",
     "start_time": "2024-03-27T22:41:01.220124Z"
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-3, 2], but got 3)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m t1 \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstack\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtensor\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43mdim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(t1\u001B[38;5;241m.\u001B[39mshape)\n",
      "\u001B[0;31mIndexError\u001B[0m: Dimension out of range (expected to be in range of [-3, 2], but got 3)"
     ]
    }
   ],
   "source": [
    "t1 = torch.stack([tensor, tensor, tensor],dim=3)\n",
    "print(t1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operacje arytmetyczne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:03.531453Z",
     "start_time": "2024-03-27T22:41:03.526933Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "tensor([[3., 2., 3., 3.],\n",
      "        [3., 2., 3., 3.],\n",
      "        [3., 2., 3., 3.],\n",
      "        [3., 2., 3., 3.]])\n",
      "tensor([[5., 0., 5., 5.],\n",
      "        [5., 0., 5., 5.],\n",
      "        [5., 0., 5., 5.],\n",
      "        [5., 0., 5., 5.]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor)\n",
    "print(tensor+2)\n",
    "print(tensor*5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operacje na elementach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:03.850104Z",
     "start_time": "2024-03-27T22:41:03.845987Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 0., 1., 1.],\n        [1., 0., 1., 1.],\n        [1., 0., 1., 1.],\n        [1., 0., 1., 1.]])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor * tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:04.094197Z",
     "start_time": "2024-03-27T22:41:04.090235Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[2., 0., 2., 2.],\n        [2., 0., 2., 2.],\n        [2., 0., 2., 2.],\n        [2., 0., 2., 2.]])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor + tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:04.343583Z",
     "start_time": "2024-03-27T22:41:04.339295Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.8972, 0.1996, 0.9082, 2.0041],\n",
      "        [1.7059, 9.4723, 2.3926, 7.0346],\n",
      "        [3.0231, 1.6426, 7.2113, 8.5514],\n",
      "        [8.0510, 0.3670, 3.9399, 5.1638]])\n",
      "tensor([[2.8972,    inf, 0.9082, 2.0041],\n",
      "        [1.7059,    inf, 2.3926, 7.0346],\n",
      "        [3.0231,    inf, 7.2113, 8.5514],\n",
      "        [8.0510,    inf, 3.9399, 5.1638]])\n"
     ]
    }
   ],
   "source": [
    "rand_tensor = torch.rand(4,4)*10\n",
    "print(rand_tensor)\n",
    "print(rand_tensor / tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:04.582102Z",
     "start_time": "2024-03-27T22:41:04.577276Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., inf, 3., 8.],\n",
      "        [2., inf, 4., 2.],\n",
      "        [1., inf, 0., 2.],\n",
      "        [2., inf, 3., 7.]])\n",
      "torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "rand_tensor = torch.rand(4,4)*10\n",
    "print(rand_tensor // tensor)\n",
    "print((tensor / tensor).type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini zadanie na plusa, mozna wysłać po zajęciach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stwórz macierz dwuwymiarową której wartości będą kolejnymi numerami od 1 do zadanej liczby x. Nie uzywaj pętli."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: https://pytorch.org/docs/stable/torch.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operacje macierzowe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:07.558687Z",
     "start_time": "2024-03-27T22:41:07.554240Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [0., 0., 0.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4, 3)\n",
    "tensor[1,:] = 0\n",
    "print(tensor)\n",
    "print(tensor.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:14.188007Z",
     "start_time": "2024-03-27T22:41:14.180073Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 0., 3., 3.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [3., 0., 3., 3.],\n",
      "        [3., 0., 3., 3.]]) \n",
      "\n",
      "tensor([[3., 0., 3., 3.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [3., 0., 3., 3.],\n",
      "        [3., 0., 3., 3.]])\n"
     ]
    }
   ],
   "source": [
    "y1 = tensor.matmul(tensor.T)\n",
    "print(y1,\"\\n\")\n",
    "y2 = tensor @ tensor.T\n",
    "print(y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zaawansowany przykład - regresja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dla wszystkich którzy potrzebują powtórki z matmy: https://mml-book.github.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:16.181853Z",
     "start_time": "2024-03-27T22:41:16.178876Z"
    }
   },
   "outputs": [],
   "source": [
    "apples_kg_ordered = [2,4,7,3,13]\n",
    "plums_kg_ordered = [3,8,9,1,1]\n",
    "prices = [11.97 , 28.05, 38.98, 10.96, 41.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:16.416910Z",
     "start_time": "2024-03-27T22:41:16.412637Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2,  4,  7,  3, 13],\n",
      "        [ 3,  8,  9,  1,  1]])\n",
      "tensor([11.9700, 28.0500, 38.9800, 10.9600, 41.1000])\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor([apples_kg_ordered,plums_kg_ordered])\n",
    "Y = torch.tensor(prices)\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:16.835565Z",
     "start_time": "2024-03-27T22:41:16.830467Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_227/4260911095.py:2: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3637.)\n",
      "  Y = Y.T\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[ 2.,  3.],\n        [ 4.,  8.],\n        [ 7.,  9.],\n        [ 3.,  1.],\n        [13.,  1.]])"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.T.float()\n",
    "Y = Y.T\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:17.125055Z",
     "start_time": "2024-03-27T22:41:17.092930Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([3.0065, 1.9963])"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = torch.inverse((X.T@X))@X.T@Y\n",
    "theta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:17.456551Z",
     "start_time": "2024-03-27T22:41:17.452308Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([12.0020, 27.9967, 39.0126, 11.0159, 41.0810])"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X @ theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatyczne obliczanie gradientu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do automatycznego obliczania gradientu służy wbudowany pakiet torch.autograd, który umożliwia automatyczne obliczanie gradientu dla dowolnego grafu (ciągu obliczeń)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:24.790211Z",
     "start_time": "2024-03-27T22:41:24.786452Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(5, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:25.000655Z",
     "start_time": "2024-03-27T22:41:24.996302Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([3., 3., 3., 3., 3.], grad_fn=<AddBackward0>)"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x + 2\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:25.220753Z",
     "start_time": "2024-03-27T22:41:25.216612Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([2., 2., 2., 2., 2.], grad_fn=<MulBackward0>)"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x * 2\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:25.698147Z",
     "start_time": "2024-03-27T22:41:25.693969Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(5., grad_fn=<DotBackward0>)"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x @ x.T\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:25.770179Z",
     "start_time": "2024-03-27T22:41:25.765965Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([-1., -1., -1., -1., -1.], grad_fn=<SubBackward0>)"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x - 2\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:25.818373Z",
     "start_time": "2024-03-27T22:41:25.814439Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<AccumulateGrad at 0x76252b93e1a0>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.grad_fn.next_functions[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:25.955279Z",
     "start_time": "2024-03-27T22:41:25.950905Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1., 1., 1., 1., 1.], requires_grad=True)"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.grad_fn.next_functions[0][0].variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:26.103836Z",
     "start_time": "2024-03-27T22:41:26.101199Z"
    }
   },
   "outputs": [],
   "source": [
    "z = y * y * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:26.253975Z",
     "start_time": "2024-03-27T22:41:26.250072Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3., 3.], grad_fn=<MulBackward0>)\n",
      "tensor(3., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "a = z.mean()\n",
    "print(z)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:26.568676Z",
     "start_time": "2024-03-27T22:41:26.566226Z"
    }
   },
   "outputs": [],
   "source": [
    "# from torchviz import make_dot - skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:27.079230Z",
     "start_time": "2024-03-27T22:41:27.076667Z"
    }
   },
   "outputs": [],
   "source": [
    "# make_dot(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradienty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:27.858545Z",
     "start_time": "2024-03-27T22:41:27.849389Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([125.], grad_fn=<PowBackward0>)"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(1, requires_grad=True)\n",
    "print(x)\n",
    "y = (x+4)**3\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:28.083276Z",
     "start_time": "2024-03-27T22:41:28.080734Z"
    }
   },
   "outputs": [],
   "source": [
    "#make_dot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:28.389966Z",
     "start_time": "2024-03-27T22:41:28.364297Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([75.])"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obliczenia z pominięciem gradientów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:29.235957Z",
     "start_time": "2024-03-27T22:41:29.231209Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1022, 0.6124, 1.9093],\n",
      "        [1.0432, 0.6620, 1.1442],\n",
      "        [1.1583, 1.2465, 1.7148]])\n",
      "tensor([[1.1022, 0.6124, 1.9093],\n",
      "        [1.0432, 0.6620, 1.1442],\n",
      "        [1.1583, 1.2465, 1.7148]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.rand(3,4, requires_grad=True)\n",
    "t2 = torch.rand(4,3, requires_grad=True)\n",
    "with torch.no_grad():\n",
    "    y = t1@t2\n",
    "print(y)\n",
    "print(t1@t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funkcja backward pozwala nam policzyć pochodną cząstkową w punkcie dla wszystkich źródeł (liści w grafie obliczeń)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:30.751541Z",
     "start_time": "2024-03-27T22:41:30.748594Z"
    }
   },
   "outputs": [],
   "source": [
    "x = torch.ones(5)  # input tensor\n",
    "y = torch.zeros(3)  # expected output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:31.134168Z",
     "start_time": "2024-03-27T22:41:31.131160Z"
    }
   },
   "outputs": [],
   "source": [
    "w = torch.randn(5, 3, requires_grad=True) #weights\n",
    "b = torch.randn(3, requires_grad=True) #bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:31.564349Z",
     "start_time": "2024-03-27T22:41:31.558135Z"
    }
   },
   "outputs": [],
   "source": [
    "z = torch.matmul(x, w)+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:31.995791Z",
     "start_time": "2024-03-27T22:41:31.991631Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(2.2770, grad_fn=<MeanBackward0>)"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = torch.abs((z-y)).mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:32.127263Z",
     "start_time": "2024-03-27T22:41:32.123206Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3333, -0.3333, -0.3333],\n",
      "        [-0.3333, -0.3333, -0.3333],\n",
      "        [-0.3333, -0.3333, -0.3333],\n",
      "        [-0.3333, -0.3333, -0.3333],\n",
      "        [-0.3333, -0.3333, -0.3333]])\n",
      "tensor([-0.3333, -0.3333, -0.3333])\n"
     ]
    }
   ],
   "source": [
    "loss.backward()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresja raz jeszcze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:32.801947Z",
     "start_time": "2024-03-27T22:41:32.799057Z"
    }
   },
   "outputs": [],
   "source": [
    "apples_kg_ordered = [2,4,7,3,13]\n",
    "plums_kg_ordered = [3,8,9,1,1]\n",
    "prices = [11.97 , 28.05, 38.98, 10.96, 41.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:32.920079Z",
     "start_time": "2024-03-27T22:41:32.915522Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.,  3.],\n",
      "        [ 4.,  8.],\n",
      "        [ 7.,  9.],\n",
      "        [ 3.,  1.],\n",
      "        [13.,  1.]])\n",
      "tensor([11.9700, 28.0500, 38.9800, 10.9600, 41.1000])\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor([apples_kg_ordered,plums_kg_ordered])\n",
    "y = torch.tensor(prices)\n",
    "X = X.T.float()\n",
    "Y = Y.T\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:33.134297Z",
     "start_time": "2024-03-27T22:41:33.131653Z"
    }
   },
   "outputs": [],
   "source": [
    "params = torch.rand(2,requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:33.251296Z",
     "start_time": "2024-03-27T22:41:33.247284Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([2.7666, 7.1848, 8.4443, 1.2595, 2.7051], grad_fn=<MvBackward0>)"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = X@params\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:33.362576Z",
     "start_time": "2024-03-27T22:41:33.358252Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(604.1505, grad_fn=<MeanBackward0>)"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = (torch.square(Y-y_pred)).mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:33.568982Z",
     "start_time": "2024-03-27T22:41:33.566064Z"
    }
   },
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:34.408978Z",
     "start_time": "2024-03-27T22:41:34.404679Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([-337.5409, -206.9793])"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:34.615992Z",
     "start_time": "2024-03-27T22:41:34.613360Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:34.792550Z",
     "start_time": "2024-03-27T22:41:34.787481Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1446, 0.8258], requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([0.4821, 1.0328], grad_fn=<SubBackward0>)"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(params)\n",
    "params - lr *params.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:35.143837Z",
     "start_time": "2024-03-27T22:41:35.140961Z"
    }
   },
   "outputs": [],
   "source": [
    "params = torch.rand(2,requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:35.866377Z",
     "start_time": "2024-03-27T22:41:35.832519Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5071, 0.3705], requires_grad=True)\n",
      "tensor([-371.5037, -251.5051])\n",
      "tensor([0.8302, 0.5889], requires_grad=True)\n",
      "tensor([-323.0286, -218.4248])\n",
      "tensor([1.1111, 0.7786], requires_grad=True)\n",
      "tensor([-280.8911, -189.6774])\n",
      "tensor([1.3553, 0.9433], requires_grad=True)\n",
      "tensor([-244.2622, -164.6958])\n",
      "tensor([1.5677, 1.0862], requires_grad=True)\n",
      "tensor([-212.4213, -142.9873])\n",
      "tensor([1.7525, 1.2104], requires_grad=True)\n",
      "tensor([-184.7423, -124.1236])\n",
      "tensor([1.9132, 1.3181], requires_grad=True)\n",
      "tensor([-160.6807, -107.7323])\n",
      "tensor([2.0529, 1.4116], requires_grad=True)\n",
      "tensor([-139.7636,  -93.4900])\n",
      "tensor([2.1745, 1.4927], requires_grad=True)\n",
      "tensor([-121.5796,  -81.1152])\n",
      "tensor([2.2803, 1.5631], requires_grad=True)\n",
      "tensor([-105.7714,  -70.3637])\n",
      "tensor([2.3723, 1.6241], requires_grad=True)\n",
      "tensor([-92.0282, -61.0229])\n",
      "tensor([2.4524, 1.6770], requires_grad=True)\n",
      "tensor([-80.0799, -52.9082])\n",
      "tensor([2.5221, 1.7229], requires_grad=True)\n",
      "tensor([-69.6919, -45.8590])\n",
      "tensor([2.5827, 1.7626], requires_grad=True)\n",
      "tensor([-60.6601, -39.7358])\n",
      "tensor([2.6356, 1.7970], requires_grad=True)\n",
      "tensor([-52.8073, -34.4174])\n",
      "tensor([2.6815, 1.8268], requires_grad=True)\n",
      "tensor([-45.9792, -29.7984])\n",
      "tensor([2.7216, 1.8526], requires_grad=True)\n",
      "tensor([-40.0419, -25.7871])\n",
      "tensor([2.7565, 1.8749], requires_grad=True)\n",
      "tensor([-34.8789, -22.3040])\n",
      "tensor([2.7868, 1.8942], requires_grad=True)\n",
      "tensor([-30.3890, -19.2799])\n",
      "tensor([2.8133, 1.9108], requires_grad=True)\n",
      "tensor([-26.4843, -16.6547])\n",
      "tensor([2.8364, 1.9252], requires_grad=True)\n",
      "tensor([-23.0882, -14.3759])\n",
      "tensor([2.8565, 1.9376], requires_grad=True)\n",
      "tensor([-20.1343, -12.3984])\n",
      "tensor([2.8741, 1.9483], requires_grad=True)\n",
      "tensor([-17.5648, -10.6824])\n",
      "tensor([2.8894, 1.9575], requires_grad=True)\n",
      "tensor([-15.3294,  -9.1938])\n",
      "tensor([2.9028, 1.9654], requires_grad=True)\n",
      "tensor([-13.3846,  -7.9027])\n",
      "tensor([2.9145, 1.9722], requires_grad=True)\n",
      "tensor([-11.6924,  -6.7832])\n",
      "tensor([2.9247, 1.9780], requires_grad=True)\n",
      "tensor([-10.2198,  -5.8127])\n",
      "tensor([2.9337, 1.9830], requires_grad=True)\n",
      "tensor([-8.9380, -4.9717])\n",
      "tensor([2.9415, 1.9872], requires_grad=True)\n",
      "tensor([-7.8222, -4.2432])\n",
      "tensor([2.9483, 1.9908], requires_grad=True)\n",
      "tensor([-6.8508, -3.6123])\n",
      "tensor([2.9544, 1.9939], requires_grad=True)\n",
      "tensor([-6.0049, -3.0663])\n",
      "tensor([2.9596, 1.9965], requires_grad=True)\n",
      "tensor([-5.2681, -2.5939])\n",
      "tensor([2.9642, 1.9987], requires_grad=True)\n",
      "tensor([-4.6262, -2.1855])\n",
      "tensor([2.9683, 2.0005], requires_grad=True)\n",
      "tensor([-4.0669, -1.8326])\n",
      "tensor([2.9719, 2.0020], requires_grad=True)\n",
      "tensor([-3.5793, -1.5279])\n",
      "tensor([2.9750, 2.0033], requires_grad=True)\n",
      "tensor([-3.1542, -1.2651])\n",
      "tensor([2.9778, 2.0043], requires_grad=True)\n",
      "tensor([-2.7833, -1.0385])\n",
      "tensor([2.9803, 2.0052], requires_grad=True)\n",
      "tensor([-2.4597, -0.8435])\n",
      "tensor([2.9825, 2.0058], requires_grad=True)\n",
      "tensor([-2.1772, -0.6757])\n",
      "tensor([2.9844, 2.0064], requires_grad=True)\n",
      "tensor([-1.9305, -0.5316])\n",
      "tensor([2.9861, 2.0068], requires_grad=True)\n",
      "tensor([-1.7149, -0.4081])\n",
      "tensor([2.9876, 2.0071], requires_grad=True)\n",
      "tensor([-1.5263, -0.3024])\n",
      "tensor([2.9890, 2.0073], requires_grad=True)\n",
      "tensor([-1.3614, -0.2121])\n",
      "tensor([2.9902, 2.0074], requires_grad=True)\n",
      "tensor([-1.2169, -0.1351])\n",
      "tensor([2.9913, 2.0075], requires_grad=True)\n",
      "tensor([-1.0904, -0.0698])\n",
      "tensor([2.9923, 2.0075], requires_grad=True)\n",
      "tensor([-0.9794, -0.0144])\n",
      "tensor([2.9932, 2.0075], requires_grad=True)\n",
      "tensor([-0.8820,  0.0324])\n",
      "tensor([2.9940, 2.0074], requires_grad=True)\n",
      "tensor([-0.7963,  0.0716])\n",
      "tensor([2.9947, 2.0073], requires_grad=True)\n",
      "tensor([-0.7210,  0.1044])\n",
      "tensor([2.9953, 2.0072], requires_grad=True)\n",
      "tensor([-0.6547,  0.1316])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "    y_pred = X@params\n",
    "    loss = (torch.square(Y-y_pred)).mean()\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        params.copy_(params - lr *params.grad)\n",
    "    print(params)\n",
    "    print(params.grad)\n",
    "    params.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini zadanie na plusa, mozna wyslać po zajęciach.\n",
    "Tym razem na innym targu do ceny owoców doliczany jest stały koszt reklamówki. Napisz model regresji liniowej który oszacuje cenę kg ziemniaków, pomidorów i reklamówki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:36.526449Z",
     "start_time": "2024-03-27T22:41:36.523059Z"
    }
   },
   "outputs": [],
   "source": [
    "potatoes_kg_ordered = [1,3,7,3,10,6,8,4,3,1,2,0]\n",
    "tomatoes_kg_ordered = [5,2,3,1,2,3,6,7,3,2,3,1]\n",
    "prices = [22.37 , 14.45, 26.6, 10.44, 28.49, 24.52, 40.38, 36.51, 18.50, 10.46, 16.51, 4.58]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:38.381036Z",
     "start_time": "2024-03-27T22:41:38.376564Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([22.5, 14.5, 26.5, 10.5, 28.5, 24.5, 40.5, 36.5, 18.5, 10.5, 16.5,\n        4.5])"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(potatoes_kg_ordered)*2 + np.array(tomatoes_kg_ordered)*4 + 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:38.461909Z",
     "start_time": "2024-03-27T22:41:38.456998Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  5.],\n",
      "        [ 3.,  2.],\n",
      "        [ 7.,  3.],\n",
      "        [ 3.,  1.],\n",
      "        [10.,  2.],\n",
      "        [ 6.,  3.],\n",
      "        [ 8.,  6.],\n",
      "        [ 4.,  7.],\n",
      "        [ 3.,  3.],\n",
      "        [ 1.,  2.],\n",
      "        [ 2.,  3.],\n",
      "        [ 0.,  1.]])\n",
      "tensor([22.3700, 14.4500, 26.6000, 10.4400, 28.4900, 24.5200, 40.3800, 36.5100,\n",
      "        18.5000, 10.4600, 16.5100,  4.5800])\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor([potatoes_kg_ordered,tomatoes_kg_ordered])\n",
    "Y = torch.tensor(prices)\n",
    "X = X.T.float()\n",
    "Y = Y.T\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:38.900034Z",
     "start_time": "2024-03-27T22:41:38.896981Z"
    }
   },
   "outputs": [],
   "source": [
    "params = torch.rand(2,requires_grad=True)\n",
    "bias = torch.rand(1,requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:38.919379Z",
     "start_time": "2024-03-27T22:41:38.900996Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:39.172468Z",
     "start_time": "2024-03-27T22:41:39.073758Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.9833, 2.0901], requires_grad=True)\n",
      "tensor([0.8491], requires_grad=True)\n",
      "tensor([2.4910, 2.5801], requires_grad=True)\n",
      "tensor([0.9641], requires_grad=True)\n",
      "tensor([2.6017, 2.7917], requires_grad=True)\n",
      "tensor([1.0051], requires_grad=True)\n",
      "tensor([2.5956, 2.9136], requires_grad=True)\n",
      "tensor([1.0231], requires_grad=True)\n",
      "tensor([2.5574, 3.0036], requires_grad=True)\n",
      "tensor([1.0335], requires_grad=True)\n",
      "tensor([2.5124, 3.0795], requires_grad=True)\n",
      "tensor([1.0410], requires_grad=True)\n",
      "tensor([2.4682, 3.1471], requires_grad=True)\n",
      "tensor([1.0472], requires_grad=True)\n",
      "tensor([2.4267, 3.2086], requires_grad=True)\n",
      "tensor([1.0525], requires_grad=True)\n",
      "tensor([2.3884, 3.2648], requires_grad=True)\n",
      "tensor([1.0571], requires_grad=True)\n",
      "tensor([2.3532, 3.3163], requires_grad=True)\n",
      "tensor([1.0611], requires_grad=True)\n",
      "tensor([2.3209, 3.3635], requires_grad=True)\n",
      "tensor([1.0646], requires_grad=True)\n",
      "tensor([2.2913, 3.4069], requires_grad=True)\n",
      "tensor([1.0677], requires_grad=True)\n",
      "tensor([2.2642, 3.4467], requires_grad=True)\n",
      "tensor([1.0702], requires_grad=True)\n",
      "tensor([2.2393, 3.4832], requires_grad=True)\n",
      "tensor([1.0724], requires_grad=True)\n",
      "tensor([2.2165, 3.5167], requires_grad=True)\n",
      "tensor([1.0743], requires_grad=True)\n",
      "tensor([2.1956, 3.5475], requires_grad=True)\n",
      "tensor([1.0757], requires_grad=True)\n",
      "tensor([2.1764, 3.5758], requires_grad=True)\n",
      "tensor([1.0769], requires_grad=True)\n",
      "tensor([2.1589, 3.6017], requires_grad=True)\n",
      "tensor([1.0778], requires_grad=True)\n",
      "tensor([2.1428, 3.6256], requires_grad=True)\n",
      "tensor([1.0784], requires_grad=True)\n",
      "tensor([2.1281, 3.6475], requires_grad=True)\n",
      "tensor([1.0789], requires_grad=True)\n",
      "tensor([2.1146, 3.6676], requires_grad=True)\n",
      "tensor([1.0790], requires_grad=True)\n",
      "tensor([2.1022, 3.6860], requires_grad=True)\n",
      "tensor([1.0790], requires_grad=True)\n",
      "tensor([2.0908, 3.7030], requires_grad=True)\n",
      "tensor([1.0788], requires_grad=True)\n",
      "tensor([2.0805, 3.7186], requires_grad=True)\n",
      "tensor([1.0785], requires_grad=True)\n",
      "tensor([2.0709, 3.7329], requires_grad=True)\n",
      "tensor([1.0780], requires_grad=True)\n",
      "tensor([2.0622, 3.7461], requires_grad=True)\n",
      "tensor([1.0774], requires_grad=True)\n",
      "tensor([2.0542, 3.7582], requires_grad=True)\n",
      "tensor([1.0766], requires_grad=True)\n",
      "tensor([2.0469, 3.7693], requires_grad=True)\n",
      "tensor([1.0757], requires_grad=True)\n",
      "tensor([2.0403, 3.7796], requires_grad=True)\n",
      "tensor([1.0747], requires_grad=True)\n",
      "tensor([2.0341, 3.7890], requires_grad=True)\n",
      "tensor([1.0737], requires_grad=True)\n",
      "tensor([2.0285, 3.7977], requires_grad=True)\n",
      "tensor([1.0725], requires_grad=True)\n",
      "tensor([2.0234, 3.8057], requires_grad=True)\n",
      "tensor([1.0713], requires_grad=True)\n",
      "tensor([2.0187, 3.8130], requires_grad=True)\n",
      "tensor([1.0700], requires_grad=True)\n",
      "tensor([2.0144, 3.8198], requires_grad=True)\n",
      "tensor([1.0686], requires_grad=True)\n",
      "tensor([2.0105, 3.8260], requires_grad=True)\n",
      "tensor([1.0672], requires_grad=True)\n",
      "tensor([2.0069, 3.8318], requires_grad=True)\n",
      "tensor([1.0657], requires_grad=True)\n",
      "tensor([2.0036, 3.8371], requires_grad=True)\n",
      "tensor([1.0642], requires_grad=True)\n",
      "tensor([2.0006, 3.8420], requires_grad=True)\n",
      "tensor([1.0626], requires_grad=True)\n",
      "tensor([1.9979, 3.8465], requires_grad=True)\n",
      "tensor([1.0610], requires_grad=True)\n",
      "tensor([1.9954, 3.8507], requires_grad=True)\n",
      "tensor([1.0593], requires_grad=True)\n",
      "tensor([1.9931, 3.8545], requires_grad=True)\n",
      "tensor([1.0577], requires_grad=True)\n",
      "tensor([1.9910, 3.8581], requires_grad=True)\n",
      "tensor([1.0560], requires_grad=True)\n",
      "tensor([1.9891, 3.8614], requires_grad=True)\n",
      "tensor([1.0542], requires_grad=True)\n",
      "tensor([1.9874, 3.8644], requires_grad=True)\n",
      "tensor([1.0525], requires_grad=True)\n",
      "tensor([1.9858, 3.8673], requires_grad=True)\n",
      "tensor([1.0507], requires_grad=True)\n",
      "tensor([1.9844, 3.8699], requires_grad=True)\n",
      "tensor([1.0489], requires_grad=True)\n",
      "tensor([1.9831, 3.8723], requires_grad=True)\n",
      "tensor([1.0471], requires_grad=True)\n",
      "tensor([1.9819, 3.8746], requires_grad=True)\n",
      "tensor([1.0453], requires_grad=True)\n",
      "tensor([1.9808, 3.8767], requires_grad=True)\n",
      "tensor([1.0434], requires_grad=True)\n",
      "tensor([1.9799, 3.8786], requires_grad=True)\n",
      "tensor([1.0416], requires_grad=True)\n",
      "tensor([1.9790, 3.8804], requires_grad=True)\n",
      "tensor([1.0398], requires_grad=True)\n",
      "tensor([1.9782, 3.8821], requires_grad=True)\n",
      "tensor([1.0379], requires_grad=True)\n",
      "tensor([1.9775, 3.8837], requires_grad=True)\n",
      "tensor([1.0360], requires_grad=True)\n",
      "tensor([1.9768, 3.8852], requires_grad=True)\n",
      "tensor([1.0342], requires_grad=True)\n",
      "tensor([1.9762, 3.8866], requires_grad=True)\n",
      "tensor([1.0323], requires_grad=True)\n",
      "tensor([1.9757, 3.8879], requires_grad=True)\n",
      "tensor([1.0304], requires_grad=True)\n",
      "tensor([1.9752, 3.8891], requires_grad=True)\n",
      "tensor([1.0285], requires_grad=True)\n",
      "tensor([1.9748, 3.8902], requires_grad=True)\n",
      "tensor([1.0266], requires_grad=True)\n",
      "tensor([1.9744, 3.8913], requires_grad=True)\n",
      "tensor([1.0248], requires_grad=True)\n",
      "tensor([1.9741, 3.8923], requires_grad=True)\n",
      "tensor([1.0229], requires_grad=True)\n",
      "tensor([1.9738, 3.8933], requires_grad=True)\n",
      "tensor([1.0210], requires_grad=True)\n",
      "tensor([1.9735, 3.8942], requires_grad=True)\n",
      "tensor([1.0191], requires_grad=True)\n",
      "tensor([1.9733, 3.8950], requires_grad=True)\n",
      "tensor([1.0172], requires_grad=True)\n",
      "tensor([1.9731, 3.8958], requires_grad=True)\n",
      "tensor([1.0154], requires_grad=True)\n",
      "tensor([1.9729, 3.8966], requires_grad=True)\n",
      "tensor([1.0135], requires_grad=True)\n",
      "tensor([1.9728, 3.8973], requires_grad=True)\n",
      "tensor([1.0116], requires_grad=True)\n",
      "tensor([1.9726, 3.8980], requires_grad=True)\n",
      "tensor([1.0098], requires_grad=True)\n",
      "tensor([1.9725, 3.8987], requires_grad=True)\n",
      "tensor([1.0079], requires_grad=True)\n",
      "tensor([1.9724, 3.8993], requires_grad=True)\n",
      "tensor([1.0060], requires_grad=True)\n",
      "tensor([1.9724, 3.8999], requires_grad=True)\n",
      "tensor([1.0042], requires_grad=True)\n",
      "tensor([1.9723, 3.9005], requires_grad=True)\n",
      "tensor([1.0023], requires_grad=True)\n",
      "tensor([1.9723, 3.9011], requires_grad=True)\n",
      "tensor([1.0005], requires_grad=True)\n",
      "tensor([1.9722, 3.9016], requires_grad=True)\n",
      "tensor([0.9986], requires_grad=True)\n",
      "tensor([1.9722, 3.9021], requires_grad=True)\n",
      "tensor([0.9968], requires_grad=True)\n",
      "tensor([1.9722, 3.9026], requires_grad=True)\n",
      "tensor([0.9950], requires_grad=True)\n",
      "tensor([1.9722, 3.9031], requires_grad=True)\n",
      "tensor([0.9931], requires_grad=True)\n",
      "tensor([1.9722, 3.9036], requires_grad=True)\n",
      "tensor([0.9913], requires_grad=True)\n",
      "tensor([1.9723, 3.9040], requires_grad=True)\n",
      "tensor([0.9895], requires_grad=True)\n",
      "tensor([1.9723, 3.9045], requires_grad=True)\n",
      "tensor([0.9877], requires_grad=True)\n",
      "tensor([1.9723, 3.9049], requires_grad=True)\n",
      "tensor([0.9859], requires_grad=True)\n",
      "tensor([1.9724, 3.9053], requires_grad=True)\n",
      "tensor([0.9841], requires_grad=True)\n",
      "tensor([1.9724, 3.9058], requires_grad=True)\n",
      "tensor([0.9823], requires_grad=True)\n",
      "tensor([1.9725, 3.9062], requires_grad=True)\n",
      "tensor([0.9805], requires_grad=True)\n",
      "tensor([1.9725, 3.9065], requires_grad=True)\n",
      "tensor([0.9787], requires_grad=True)\n",
      "tensor([1.9726, 3.9069], requires_grad=True)\n",
      "tensor([0.9770], requires_grad=True)\n",
      "tensor([1.9727, 3.9073], requires_grad=True)\n",
      "tensor([0.9752], requires_grad=True)\n",
      "tensor([1.9727, 3.9077], requires_grad=True)\n",
      "tensor([0.9734], requires_grad=True)\n",
      "tensor([1.9728, 3.9080], requires_grad=True)\n",
      "tensor([0.9717], requires_grad=True)\n",
      "tensor([1.9729, 3.9084], requires_grad=True)\n",
      "tensor([0.9699], requires_grad=True)\n",
      "tensor([1.9730, 3.9087], requires_grad=True)\n",
      "tensor([0.9682], requires_grad=True)\n",
      "tensor([1.9731, 3.9091], requires_grad=True)\n",
      "tensor([0.9664], requires_grad=True)\n",
      "tensor([1.9731, 3.9094], requires_grad=True)\n",
      "tensor([0.9647], requires_grad=True)\n",
      "tensor([1.9732, 3.9098], requires_grad=True)\n",
      "tensor([0.9630], requires_grad=True)\n",
      "tensor([1.9733, 3.9101], requires_grad=True)\n",
      "tensor([0.9613], requires_grad=True)\n",
      "tensor([1.9734, 3.9104], requires_grad=True)\n",
      "tensor([0.9595], requires_grad=True)\n",
      "tensor([1.9735, 3.9107], requires_grad=True)\n",
      "tensor([0.9578], requires_grad=True)\n",
      "tensor([1.9736, 3.9111], requires_grad=True)\n",
      "tensor([0.9561], requires_grad=True)\n",
      "tensor([1.9737, 3.9114], requires_grad=True)\n",
      "tensor([0.9544], requires_grad=True)\n",
      "tensor([1.9738, 3.9117], requires_grad=True)\n",
      "tensor([0.9527], requires_grad=True)\n",
      "tensor([1.9739, 3.9120], requires_grad=True)\n",
      "tensor([0.9511], requires_grad=True)\n",
      "tensor([1.9740, 3.9123], requires_grad=True)\n",
      "tensor([0.9494], requires_grad=True)\n",
      "tensor([1.9741, 3.9126], requires_grad=True)\n",
      "tensor([0.9477], requires_grad=True)\n",
      "tensor([1.9742, 3.9129], requires_grad=True)\n",
      "tensor([0.9461], requires_grad=True)\n",
      "tensor([1.9743, 3.9132], requires_grad=True)\n",
      "tensor([0.9444], requires_grad=True)\n",
      "tensor([1.9744, 3.9135], requires_grad=True)\n",
      "tensor([0.9427], requires_grad=True)\n",
      "tensor([1.9745, 3.9138], requires_grad=True)\n",
      "tensor([0.9411], requires_grad=True)\n",
      "tensor([1.9746, 3.9141], requires_grad=True)\n",
      "tensor([0.9395], requires_grad=True)\n",
      "tensor([1.9747, 3.9144], requires_grad=True)\n",
      "tensor([0.9378], requires_grad=True)\n",
      "tensor([1.9748, 3.9147], requires_grad=True)\n",
      "tensor([0.9362], requires_grad=True)\n",
      "tensor([1.9749, 3.9150], requires_grad=True)\n",
      "tensor([0.9346], requires_grad=True)\n",
      "tensor([1.9750, 3.9152], requires_grad=True)\n",
      "tensor([0.9330], requires_grad=True)\n",
      "tensor([1.9751, 3.9155], requires_grad=True)\n",
      "tensor([0.9314], requires_grad=True)\n",
      "tensor([1.9752, 3.9158], requires_grad=True)\n",
      "tensor([0.9298], requires_grad=True)\n",
      "tensor([1.9753, 3.9161], requires_grad=True)\n",
      "tensor([0.9282], requires_grad=True)\n",
      "tensor([1.9754, 3.9164], requires_grad=True)\n",
      "tensor([0.9266], requires_grad=True)\n",
      "tensor([1.9755, 3.9166], requires_grad=True)\n",
      "tensor([0.9250], requires_grad=True)\n",
      "tensor([1.9756, 3.9169], requires_grad=True)\n",
      "tensor([0.9234], requires_grad=True)\n",
      "tensor([1.9757, 3.9172], requires_grad=True)\n",
      "tensor([0.9219], requires_grad=True)\n",
      "tensor([1.9758, 3.9175], requires_grad=True)\n",
      "tensor([0.9203], requires_grad=True)\n",
      "tensor([1.9759, 3.9177], requires_grad=True)\n",
      "tensor([0.9187], requires_grad=True)\n",
      "tensor([1.9760, 3.9180], requires_grad=True)\n",
      "tensor([0.9172], requires_grad=True)\n",
      "tensor([1.9761, 3.9183], requires_grad=True)\n",
      "tensor([0.9156], requires_grad=True)\n",
      "tensor([1.9762, 3.9185], requires_grad=True)\n",
      "tensor([0.9141], requires_grad=True)\n",
      "tensor([1.9763, 3.9188], requires_grad=True)\n",
      "tensor([0.9126], requires_grad=True)\n",
      "tensor([1.9764, 3.9191], requires_grad=True)\n",
      "tensor([0.9110], requires_grad=True)\n",
      "tensor([1.9765, 3.9193], requires_grad=True)\n",
      "tensor([0.9095], requires_grad=True)\n",
      "tensor([1.9766, 3.9196], requires_grad=True)\n",
      "tensor([0.9080], requires_grad=True)\n",
      "tensor([1.9767, 3.9199], requires_grad=True)\n",
      "tensor([0.9065], requires_grad=True)\n",
      "tensor([1.9768, 3.9201], requires_grad=True)\n",
      "tensor([0.9050], requires_grad=True)\n",
      "tensor([1.9769, 3.9204], requires_grad=True)\n",
      "tensor([0.9035], requires_grad=True)\n",
      "tensor([1.9770, 3.9206], requires_grad=True)\n",
      "tensor([0.9020], requires_grad=True)\n",
      "tensor([1.9771, 3.9209], requires_grad=True)\n",
      "tensor([0.9005], requires_grad=True)\n",
      "tensor([1.9772, 3.9211], requires_grad=True)\n",
      "tensor([0.8990], requires_grad=True)\n",
      "tensor([1.9773, 3.9214], requires_grad=True)\n",
      "tensor([0.8975], requires_grad=True)\n",
      "tensor([1.9774, 3.9217], requires_grad=True)\n",
      "tensor([0.8961], requires_grad=True)\n",
      "tensor([1.9775, 3.9219], requires_grad=True)\n",
      "tensor([0.8946], requires_grad=True)\n",
      "tensor([1.9776, 3.9222], requires_grad=True)\n",
      "tensor([0.8931], requires_grad=True)\n",
      "tensor([1.9777, 3.9224], requires_grad=True)\n",
      "tensor([0.8917], requires_grad=True)\n",
      "tensor([1.9778, 3.9227], requires_grad=True)\n",
      "tensor([0.8902], requires_grad=True)\n",
      "tensor([1.9778, 3.9229], requires_grad=True)\n",
      "tensor([0.8888], requires_grad=True)\n",
      "tensor([1.9779, 3.9232], requires_grad=True)\n",
      "tensor([0.8873], requires_grad=True)\n",
      "tensor([1.9780, 3.9234], requires_grad=True)\n",
      "tensor([0.8859], requires_grad=True)\n",
      "tensor([1.9781, 3.9236], requires_grad=True)\n",
      "tensor([0.8845], requires_grad=True)\n",
      "tensor([1.9782, 3.9239], requires_grad=True)\n",
      "tensor([0.8831], requires_grad=True)\n",
      "tensor([1.9783, 3.9241], requires_grad=True)\n",
      "tensor([0.8816], requires_grad=True)\n",
      "tensor([1.9784, 3.9244], requires_grad=True)\n",
      "tensor([0.8802], requires_grad=True)\n",
      "tensor([1.9785, 3.9246], requires_grad=True)\n",
      "tensor([0.8788], requires_grad=True)\n",
      "tensor([1.9786, 3.9249], requires_grad=True)\n",
      "tensor([0.8774], requires_grad=True)\n",
      "tensor([1.9787, 3.9251], requires_grad=True)\n",
      "tensor([0.8760], requires_grad=True)\n",
      "tensor([1.9788, 3.9253], requires_grad=True)\n",
      "tensor([0.8747], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(150):\n",
    "    y_pred = X@params + bias\n",
    "    loss = (torch.square(Y-y_pred)).mean()\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        params.copy_(params - lr *params.grad)\n",
    "        bias.copy_(bias - lr *bias.grad)\n",
    "    print(params)\n",
    "    print(bias)\n",
    "    params.grad.zero_()\n",
    "    bias.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB 2 - Tworzenie architektury i przygotowanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:39.640357Z",
     "start_time": "2024-03-27T22:41:39.296501Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jednym z kluczowych udogodnień pytorcha jest możliwość szybkiego i prostego przenoszenia obliczeń między CPU a GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:39.710143Z",
     "start_time": "2024-03-27T22:41:39.706260Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:41.356437Z",
     "start_time": "2024-03-27T22:41:41.352740Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda')"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") \n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:42.163343Z",
     "start_time": "2024-03-27T22:41:41.941435Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "X tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(2, 3)\n",
    "print(\"X\", x)\n",
    "x = x.to(device)\n",
    "print(\"X\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Co nam to daje?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-03-27T22:41:47.644359Z",
     "start_time": "2024-03-27T22:41:46.544915Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU time: 0.83908s\n",
      "GPU time: 0.00013s\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(5000, 5000)\n",
    "\n",
    "## CPU version\n",
    "start_time = time.time()\n",
    "_ = torch.matmul(x, x)\n",
    "end_time = time.time()\n",
    "print(f\"CPU time: {(end_time - start_time):6.5f}s\")\n",
    "\n",
    "## GPU version\n",
    "x = x.to(device)\n",
    "# The first operation on a CUDA device can be slow as it has to establish a CPU-GPU communication first. \n",
    "# Hence, we run an arbitrary command first without timing it for a fair comparison.\n",
    "_ = torch.matmul(x*0.0, x)\n",
    "start_time = time.time()\n",
    "_ = torch.matmul(x, x)\n",
    "end_time = time.time()\n",
    "print(f\"GPU time: {(end_time - start_time):6.5f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ciąg komend do zapisania\n",
    "Losowość jest bardzo ważnym elementem trenowania sieci neuronowych (o czym się wkrótce przekonamy). Eksperymentując, chcielibyśmy jednak żeby przy każdym uruchomieniu programu, wynik był taki sam. Tylko w takim przypadku jesteśmy w stanie coś wnioskować. Do zapewnienia możliwości reprodukcji wyników na GPU za pomocą pytorcha służa poniższe komendy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:54.834922Z",
     "start_time": "2024-03-03T23:28:54.834854Z"
    }
   },
   "outputs": [],
   "source": [
    "# GPU operations have a separate seed we also want to set\n",
    "if torch.cuda.is_available(): \n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    \n",
    "# Additionally, some operations on a GPU are implemented stochastic for efficiency\n",
    "# We want to ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.determinstic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tworzenie modeli\n",
    "Tworzymy tensory z parametrami, wagi i biasy, obliczamy gradienty, aktualizujemy parametry itd.\n",
    "lub\n",
    "wykorzystujemy torch.nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W torch.nn możemy znaleźć wiele przydatnych predefiniowanych klas jak wagi sieci, funkcje aktywacji, funkcje straty, optymalizacja itp. Jeszcze raz, dokumentacja jest fajna: https://pytorch.org/docs/stable/nn.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dodatkowo, funkcje wykorzystywane w budowaniu sieci znajdują się w module torch.nn.functionl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Module\n",
    "W PyTorchu, sieci neuronowe są zbudowane z modułów - obiektów klas dziedziczących po klasie nn.Module. Moduły mogą składać się z innych modułów, a sieć neuronowa w całości też zazwyczaj jest modułem.\n",
    "\n",
    "Podstawowy template dla modułu wygląda następująco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Some init for my module\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Function for performing the calculation of the module.\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W konstruktorze modułu zazwyczaj inicjowane są wszystkie parametry, lub wewnętrzne moduły (np. warstwy sieci)\n",
    "\n",
    "W funkcji forward zapisane są wszystkie obliczenia które są wykonywane kiedy wywołujemy dany moduł. Przykładowo: (nn = MyModule(); nn(x)). \n",
    "\n",
    "Kalkulacja wstecz (backwards) jest tworzona automatycznie, ale w razie potrzeby można ją też nadpisywać "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stwórzmy pierwsza sieć neuronową "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, num_inputs, num_hidden, num_outputs):\n",
    "        super().__init__()\n",
    "        # Initialize the modules we need to build the network\n",
    "        self.linear1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.act_fn = nn.Tanh()\n",
    "        self.linear2 = nn.Linear(num_hidden, num_outputs)\n",
    "#         self.linear3 = nn.Linear(num_hidden, num_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Perform the calculation of the model to determine the prediction\n",
    "        x = self.linear1(x)\n",
    "        x = self.act_fn(x)\n",
    "        x = self.linear2(x)\n",
    "#         x = self.act_fn(x)\n",
    "#         x = self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wypisywanie zawartości modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleClassifier(num_inputs=2, num_hidden=4, num_outputs=1)\n",
    "model.cuda()\n",
    "# Printing a module shows all its submodules\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:54.890232Z",
     "start_time": "2024-03-03T23:28:54.872012Z"
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[161], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTensor\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/ArtifficialNeuralNetworks/Introduction_lab_1_2/venv/lib/python3.11/site-packages/torch/cuda/__init__.py:293\u001B[0m, in \u001B[0;36m_lazy_init\u001B[0;34m()\u001B[0m\n\u001B[1;32m    288\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    289\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    290\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultiprocessing, you must use the \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mspawn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m start method\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    291\u001B[0m     )\n\u001B[1;32m    292\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(torch\u001B[38;5;241m.\u001B[39m_C, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_cuda_getDeviceCount\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 293\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTorch not compiled with CUDA enabled\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    294\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _cudart \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    295\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\n\u001B[1;32m    296\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    297\u001B[0m     )\n",
      "\u001B[0;31mAssertionError\u001B[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor(2).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:55.002082Z",
     "start_time": "2024-03-03T23:28:54.994645Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[162], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241m.\u001B[39mforward(x)\n\u001B[1;32m      2\u001B[0m model(x)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.forward(x)\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Co tak właściwie mamy w środku?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:55.078100Z",
     "start_time": "2024-03-03T23:28:55.067620Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[163], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m name, param \u001B[38;5;129;01min\u001B[39;00m \u001B[43mmodel\u001B[49m\u001B[38;5;241m.\u001B[39mnamed_parameters():\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mParameter \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, shape \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mparam\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"Parameter {name}, shape {param.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:55.143072Z",
     "start_time": "2024-03-03T23:28:55.135078Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'F' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[164], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m act_fn_by_name \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msigmoid\u001B[39m\u001B[38;5;124m\"\u001B[39m: torch\u001B[38;5;241m.\u001B[39msigmoid,\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtanh\u001B[39m\u001B[38;5;124m\"\u001B[39m: torch\u001B[38;5;241m.\u001B[39mtanh,\n\u001B[0;32m----> 4\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrelu\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[43mF\u001B[49m\u001B[38;5;241m.\u001B[39mrelu,\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mleakyrelu\u001B[39m\u001B[38;5;124m\"\u001B[39m: F\u001B[38;5;241m.\u001B[39mleaky_relu\n\u001B[1;32m      6\u001B[0m }\n",
      "\u001B[0;31mNameError\u001B[0m: name 'F' is not defined"
     ]
    }
   ],
   "source": [
    "act_fn_by_name = {\n",
    "    \"sigmoid\": torch.sigmoid,\n",
    "    \"tanh\": torch.tanh,\n",
    "    \"relu\": F.relu,\n",
    "    \"leakyrelu\": F.leaky_relu\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:55.188583Z",
     "start_time": "2024-03-03T23:28:55.186570Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_grads(act_fn, x):\n",
    "    x = x.clone().requires_grad_() # Mark the input as tensor for which we want to store gradients\n",
    "    out = act_fn(x)\n",
    "    out.sum().backward() # Summing results in an equal gradient flow to each element in x\n",
    "    return x.grad # Accessing the gradients of x by \"x.grad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:55.314292Z",
     "start_time": "2024-03-03T23:28:55.283885Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'act_fn_by_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[166], line 17\u001B[0m\n\u001B[1;32m     15\u001B[0m x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mlinspace(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m5\u001B[39m, \u001B[38;5;241m5\u001B[39m, \u001B[38;5;241m1000\u001B[39m) \u001B[38;5;66;03m# Range on which we want to visualize the activation functions\u001B[39;00m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;66;03m## Plotting\u001B[39;00m\n\u001B[0;32m---> 17\u001B[0m rows \u001B[38;5;241m=\u001B[39m math\u001B[38;5;241m.\u001B[39mceil(\u001B[38;5;28mlen\u001B[39m(\u001B[43mact_fn_by_name\u001B[49m)\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m2.0\u001B[39m)\n\u001B[1;32m     18\u001B[0m fig, ax \u001B[38;5;241m=\u001B[39m plt\u001B[38;5;241m.\u001B[39msubplots(rows, \u001B[38;5;241m2\u001B[39m, figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m8\u001B[39m, rows\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m4\u001B[39m))\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(act_fn_by_name\u001B[38;5;241m.\u001B[39mkeys()):\n",
      "\u001B[0;31mNameError\u001B[0m: name 'act_fn_by_name' is not defined"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "def vis_act_fn(act_fn, name, ax, x):\n",
    "    # Run activation function\n",
    "    y = act_fn(x)\n",
    "    y_grads = get_grads(act_fn, x)\n",
    "    # Push x, y and gradients back to cpu for plotting\n",
    "    x, y, y_grads = x.cpu().numpy(), y.cpu().numpy(), y_grads.cpu().numpy()\n",
    "    ## Plotting\n",
    "    ax.plot(x, y, linewidth=2, label=\"ActFn\")\n",
    "    ax.plot(x, y_grads, linewidth=2, label=\"Gradient\")\n",
    "    ax.set_title(name)\n",
    "    ax.legend()\n",
    "    ax.set_ylim(-1.5, x.max())\n",
    "\n",
    "x = torch.linspace(-5, 5, 1000) # Range on which we want to visualize the activation functions\n",
    "## Plotting\n",
    "rows = math.ceil(len(act_fn_by_name)/2.0)\n",
    "fig, ax = plt.subplots(rows, 2, figsize=(8, rows*4))\n",
    "for i, name in enumerate(act_fn_by_name.keys()):\n",
    "    vis_act_fn(act_fn_by_name[name], name, ax[divmod(i,2)], x)\n",
    "fig.subplots_adjust(hspace=0.3)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dane\n",
    "PyTorch posiada zaimplementowanych kilka funkcjonalności które pozwalają wczytywać i manipulować danymi. Znajdują się one w pakiecie torch.utils.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:55.315184Z",
     "start_time": "2024-03-03T23:28:55.315133Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Główną strukturą w ramach której przechowywane (lub niekoniecznie) są dane jest klasa Dataset. Stwórzmy sobie przykładowy zbiór danych - tzw. ciągły XOR. Przykład zaczerpnięty z https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial2/Introduction_to_PyTorch.html#Learning-by-example:-Continuous-XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:55.382872Z",
     "start_time": "2024-03-03T23:28:55.369012Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'Dataset'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[167], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mXORDataset\u001B[39;00m(\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDataset\u001B[49m):\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, size, std\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.1\u001B[39m):\n\u001B[1;32m      4\u001B[0m \u001B[38;5;250m        \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;124;03m        Inputs:\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;124;03m            size - Number of data points we want to generate\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;124;03m            std - Standard deviation of the noise (see generate_continuous_xor function)\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;124;03m        \"\"\"\u001B[39;00m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'list' object has no attribute 'Dataset'"
     ]
    }
   ],
   "source": [
    "class XORDataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, size, std=0.1):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            size - Number of data points we want to generate\n",
    "            std - Standard deviation of the noise (see generate_continuous_xor function)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.size = size\n",
    "        self.std = std\n",
    "        self.generate_continuous_xor()\n",
    "\n",
    "    def generate_continuous_xor(self):\n",
    "        # Each data point in the XOR dataset has two variables, x and y, that can be either 0 or 1\n",
    "        # The label is their XOR combination, i.e. 1 if only x or only y is 1 while the other is 0.\n",
    "        # If x=y, the label is 0.\n",
    "        data = torch.randint(low=0, high=2, size=(self.size, 2), dtype=torch.float32)\n",
    "        label = (data.sum(dim=1) == 1).to(torch.long)\n",
    "        # To make it slightly more challenging, we add a bit of gaussian noise to the data points.\n",
    "        data += self.std * torch.randn(data.shape)\n",
    "\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        # Number of data point we have. Alternatively self.data.shape[0], or self.label.shape[0]\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return the idx-th data point of the dataset\n",
    "        # If we have multiple things to return (data point and label), we can return them as tuple\n",
    "        data_point = self.data[idx]\n",
    "        data_label = self.label[idx]\n",
    "        return data_point, data_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:55.408592Z",
     "start_time": "2024-03-03T23:28:55.399598Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'XORDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[168], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m dataset \u001B[38;5;241m=\u001B[39m \u001B[43mXORDataset\u001B[49m(size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m200\u001B[39m)\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSize of dataset:\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mlen\u001B[39m(dataset))\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mData point 0:\u001B[39m\u001B[38;5;124m\"\u001B[39m, dataset[\u001B[38;5;241m0\u001B[39m])\n",
      "\u001B[0;31mNameError\u001B[0m: name 'XORDataset' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = XORDataset(size=200)\n",
    "print(\"Size of dataset:\", len(dataset))\n",
    "print(\"Data point 0:\", dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:55.489835Z",
     "start_time": "2024-03-03T23:28:55.481202Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[169], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m examples \u001B[38;5;241m=\u001B[39m \u001B[43mdataset\u001B[49m\u001B[38;5;241m.\u001B[39mdata\n\u001B[1;32m      2\u001B[0m labels \u001B[38;5;241m=\u001B[39m dataset\u001B[38;5;241m.\u001B[39mlabel\n\u001B[1;32m      3\u001B[0m data_0 \u001B[38;5;241m=\u001B[39m examples[labels \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m]\n",
      "\u001B[0;31mNameError\u001B[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "examples = dataset.data\n",
    "labels = dataset.label\n",
    "data_0 = examples[labels == 0]\n",
    "data_1 = examples[labels == 1]\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.scatter(data_0[:,0], data_0[:,1], edgecolor=\"#333\", label=\"Class 0\")\n",
    "plt.scatter(data_1[:,0], data_1[:,1], edgecolor=\"#333\", label=\"Class 1\")\n",
    "plt.title(\"Dataset samples\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loaders (Ładowacze danych?!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:55.535869Z",
     "start_time": "2024-03-03T23:28:55.528170Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'DataLoader'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[170], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m data_loader \u001B[38;5;241m=\u001B[39m \u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDataLoader\u001B[49m(dataset, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m8\u001B[39m, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'list' object has no attribute 'DataLoader'"
     ]
    }
   ],
   "source": [
    "data_loader = data.DataLoader(dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:55.591049Z",
     "start_time": "2024-03-03T23:28:55.582475Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[171], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28miter\u001B[39m(\u001B[43mdata_loader\u001B[49m))\n",
      "\u001B[0;31mNameError\u001B[0m: name 'data_loader' is not defined"
     ]
    }
   ],
   "source": [
    "next(iter(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:55.635876Z",
     "start_time": "2024-03-03T23:28:55.627673Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[172], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28mlen\u001B[39m(\u001B[43mdata_loader\u001B[49m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'data_loader' is not defined"
     ]
    }
   ],
   "source": [
    "len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:55.713143Z",
     "start_time": "2024-03-03T23:28:55.704319Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[173], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28miter\u001B[39m(\u001B[43mdata_loader\u001B[49m))[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mlen\u001B[39m(data_loader)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'data_loader' is not defined"
     ]
    }
   ],
   "source": [
    "next(iter(data_loader))[0].shape[0]*len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:55.730419Z",
     "start_time": "2024-03-03T23:28:55.722363Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'DataLoader'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[174], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m data_loader_2 \u001B[38;5;241m=\u001B[39m \u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDataLoader\u001B[49m(dataset, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m7\u001B[39m, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28miter\u001B[39m(data_loader_2))[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mlen\u001B[39m(data_loader_2)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'list' object has no attribute 'DataLoader'"
     ]
    }
   ],
   "source": [
    "data_loader_2 = data.DataLoader(dataset, batch_size=7, shuffle=True)\n",
    "next(iter(data_loader_2))[0].shape[0]*len(data_loader_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:55.762570Z",
     "start_time": "2024-03-03T23:28:55.755047Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_loader_2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[175], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28miter\u001B[39m(\u001B[43mdata_loader_2\u001B[49m))[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n",
      "\u001B[0;31mNameError\u001B[0m: name 'data_loader_2' is not defined"
     ]
    }
   ],
   "source": [
    "list(iter(data_loader_2))[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop last\n",
    "Parametr powodujący pominięcie ostatniego wsadu (batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:55.829938Z",
     "start_time": "2024-03-03T23:28:55.820347Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'DataLoader'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[176], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m data_loader_2 \u001B[38;5;241m=\u001B[39m \u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDataLoader\u001B[49m(dataset,batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m7\u001B[39m, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, drop_last\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28miter\u001B[39m(data_loader_2))[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mlen\u001B[39m(data_loader_2)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'list' object has no attribute 'DataLoader'"
     ]
    }
   ],
   "source": [
    "data_loader_2 = data.DataLoader(dataset,batch_size=7, shuffle=True, drop_last=True)\n",
    "next(iter(data_loader_2))[0].shape[0]*len(data_loader_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funkcje straty\n",
    "Na poprzednich zajęciach obliczaliśmy funkcję straty ręcznie wykonując operacje na tensorach. Jest to w pełni poprawne rozwiązanie, ale możemy też nie wymyślać koła na nowo, ale wykorzystać wbudowane moduły. Pełna lista dostępna tutaj: https://pytorch.org/docs/stable/nn.html#loss-functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:55.908364Z",
     "start_time": "2024-03-03T23:28:55.906345Z"
    }
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:55.942755Z",
     "start_time": "2024-03-03T23:28:55.939416Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4]) tensor([1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "tensor_1 = torch.arange(5)\n",
    "tensor_2 = torch.ones(5)\n",
    "print(tensor_1, tensor_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Błąd średniokwadratowy (Mean Squared Error) lub L2Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:56.024612Z",
     "start_time": "2024-03-03T23:28:56.016553Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[179], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[43mnn\u001B[49m\u001B[38;5;241m.\u001B[39mMSELoss()\n\u001B[1;32m      2\u001B[0m loss(tensor_1,tensor_2)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "loss = nn.MSELoss()\n",
    "loss(tensor_1,tensor_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\quad l_{n}=\\left(x_{n}-y_{n}\\right)^{2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:56.055076Z",
     "start_time": "2024-03-03T23:28:56.046704Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[180], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[43mnn\u001B[49m\u001B[38;5;241m.\u001B[39mMSELoss(reduction\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnone\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo reduction: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mloss(tensor_1,tensor_2)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      3\u001B[0m loss \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mMSELoss(reduction\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmean\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "loss = nn.MSELoss(reduction=\"none\")\n",
    "print(f\"No reduction: {loss(tensor_1,tensor_2)}\")\n",
    "loss = nn.MSELoss(reduction=\"mean\")\n",
    "print(f\"Mean: {loss(tensor_1,tensor_2)}\")\n",
    "loss = nn.MSELoss(reduction=\"sum\")\n",
    "print(f\"Sum: {loss(tensor_1,tensor_2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:56.123232Z",
     "start_time": "2024-03-03T23:28:56.115968Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'F' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[181], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mF\u001B[49m\u001B[38;5;241m.\u001B[39mmse_loss(tensor_1, tensor_2)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'F' is not defined"
     ]
    }
   ],
   "source": [
    "F.mse_loss(tensor_1, tensor_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:56.158812Z",
     "start_time": "2024-03-03T23:28:56.148930Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[182], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[43mnn\u001B[49m\u001B[38;5;241m.\u001B[39mMSELoss(reduction\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnone\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      2\u001B[0m x, y \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmeshgrid(torch\u001B[38;5;241m.\u001B[39mlinspace(\u001B[38;5;241m0\u001B[39m,\u001B[38;5;241m10\u001B[39m,\u001B[38;5;241m100\u001B[39m),torch\u001B[38;5;241m.\u001B[39mlinspace(\u001B[38;5;241m0\u001B[39m,\u001B[38;5;241m10\u001B[39m,\u001B[38;5;241m100\u001B[39m))\n\u001B[1;32m      3\u001B[0m z \u001B[38;5;241m=\u001B[39m loss(x,y)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "loss = nn.MSELoss(reduction=\"none\")\n",
    "x, y = torch.meshgrid(torch.linspace(0,10,100),torch.linspace(0,10,100))\n",
    "z = loss(x,y)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection = '3d')\n",
    "#ax = fig.gca(projection='3d') - for older matplotlib\n",
    "\n",
    "ax.plot_trisurf(x.numpy().flatten(), y.numpy().flatten(), z.numpy().flatten(), linewidth=0.2, antialiased=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Błąd bezwzględny (Mean absolute Error) lub L1Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T20:04:21.482653Z",
     "start_time": "2021-10-08T20:04:21.475776Z"
    }
   },
   "source": [
    "$ \\quad l_{n}=\\left|x_{n}-y_{n}\\right|$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:56.223979Z",
     "start_time": "2024-03-03T23:28:56.215868Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4]) tensor([1., 1., 1., 1., 1.])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[183], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28mprint\u001B[39m(tensor_1, tensor_2)\n\u001B[0;32m----> 2\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[43mnn\u001B[49m\u001B[38;5;241m.\u001B[39mL1Loss()\n\u001B[1;32m      3\u001B[0m loss(tensor_1,tensor_2)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "print(tensor_1, tensor_2)\n",
    "loss = nn.L1Loss()\n",
    "loss(tensor_1,tensor_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:56.247395Z",
     "start_time": "2024-03-03T23:28:56.239148Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[184], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[43mnn\u001B[49m\u001B[38;5;241m.\u001B[39mL1Loss(reduction\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnone\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo reduction: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mloss(tensor_1,tensor_2)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      3\u001B[0m loss \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mL1Loss(reduction\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmean\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "loss = nn.L1Loss(reduction=\"none\")\n",
    "print(f\"No reduction: {loss(tensor_1,tensor_2)}\")\n",
    "loss = nn.L1Loss(reduction=\"mean\")\n",
    "print(f\"Mean: {loss(tensor_1,tensor_2)}\")\n",
    "loss = nn.L1Loss(reduction=\"sum\")\n",
    "print(f\"Sum: {loss(tensor_1,tensor_2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:56.343206Z",
     "start_time": "2024-03-03T23:28:56.334355Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[185], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[43mnn\u001B[49m\u001B[38;5;241m.\u001B[39mL1Loss(reduction\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnone\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      2\u001B[0m x, y \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmeshgrid(torch\u001B[38;5;241m.\u001B[39mlinspace(\u001B[38;5;241m0\u001B[39m,\u001B[38;5;241m10\u001B[39m,\u001B[38;5;241m100\u001B[39m),torch\u001B[38;5;241m.\u001B[39mlinspace(\u001B[38;5;241m0\u001B[39m,\u001B[38;5;241m10\u001B[39m,\u001B[38;5;241m100\u001B[39m))\n\u001B[1;32m      3\u001B[0m z \u001B[38;5;241m=\u001B[39m loss(x,y)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "loss = nn.L1Loss(reduction=\"none\")\n",
    "x, y = torch.meshgrid(torch.linspace(0,10,100),torch.linspace(0,10,100))\n",
    "z = loss(x,y)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection = '3d')\n",
    "#ax = fig.gca(projection='3d') - for older matplotlib\n",
    "\n",
    "ax.plot_trisurf(x.numpy().flatten(), y.numpy().flatten(), z.numpy().flatten(), linewidth=0.2, antialiased=True)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropia krzyżowa:\n",
    "$l_{n}=\\left[y_{n} \\cdot \\log x_{n}+\\left(1-y_{n}\\right) \\cdot \\log \\left(1-x_{n}\\right)\\right]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:56.374992Z",
     "start_time": "2024-03-03T23:28:56.366287Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7855, 0.2664, 0.3826, 0.3065, 0.5009]) tensor([1., 1., 1., 1., 1.])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[186], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m tensor_2 \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mones(\u001B[38;5;241m5\u001B[39m)\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(tensor_1, tensor_2)\n\u001B[0;32m----> 4\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[43mnn\u001B[49m\u001B[38;5;241m.\u001B[39mBCELoss(reduction\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnone\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      5\u001B[0m loss(tensor_1,tensor_2)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "tensor_1 = torch.rand(5)\n",
    "tensor_2 = torch.ones(5)\n",
    "print(tensor_1, tensor_2)\n",
    "loss = nn.BCELoss(reduction=\"none\")\n",
    "loss(tensor_1,tensor_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:56.458423Z",
     "start_time": "2024-03-03T23:28:56.450917Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Tensor' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[187], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mloss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtensor_1\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mtensor_2\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mTypeError\u001B[0m: 'Tensor' object is not callable"
     ]
    }
   ],
   "source": [
    "loss(tensor_1*10,tensor_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:56.477973Z",
     "start_time": "2024-03-03T23:28:56.469491Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[188], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[43mnn\u001B[49m\u001B[38;5;241m.\u001B[39mBCEWithLogitsLoss(reduction\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnone\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      2\u001B[0m loss(tensor_1\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m100\u001B[39m,tensor_2)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "loss = nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "loss(tensor_1*100,tensor_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:56.517147Z",
     "start_time": "2024-03-03T23:28:56.506317Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[189], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[43mnn\u001B[49m\u001B[38;5;241m.\u001B[39mBCEWithLogitsLoss(reduction\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnone\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      2\u001B[0m x, y \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmeshgrid(torch\u001B[38;5;241m.\u001B[39mlinspace(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m10\u001B[39m,\u001B[38;5;241m10\u001B[39m,\u001B[38;5;241m100\u001B[39m),torch\u001B[38;5;241m.\u001B[39mlinspace(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m10\u001B[39m,\u001B[38;5;241m10\u001B[39m,\u001B[38;5;241m100\u001B[39m))\n\u001B[1;32m      3\u001B[0m z \u001B[38;5;241m=\u001B[39m loss(x,y)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "loss = nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "x, y = torch.meshgrid(torch.linspace(-10,10,100),torch.linspace(-10,10,100))\n",
    "z = loss(x,y)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection = '3d')\n",
    "#ax = fig.gca(projection='3d') - for older matplotlib\n",
    "\n",
    "ax.plot_trisurf(x.numpy().flatten(), y.numpy().flatten(), z.numpy().flatten(), linewidth=0.2, antialiased=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optymalizacja parametrów\n",
    "W przykładowym problemie optymalizacji parametrów regresji, ręcznie aktualizowaliśmy gradienty. W torch są do tego narzędzia zwane optymalizatorami, znajdują się one w pakiecie torch.optim\n",
    "\n",
    "Najprostszym optymalizaotrem jest algorytm stochastycznego spadku gradientu (Stochastic Gradient Descent) - SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:56.588074Z",
     "start_time": "2024-03-03T23:28:56.580556Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SimpleClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[190], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mSimpleClassifier\u001B[49m(num_inputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m, num_hidden\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m, num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(model)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'SimpleClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "model = SimpleClassifier(num_inputs=2, num_hidden=4, num_outputs=1)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:56.659730Z",
     "start_time": "2024-03-03T23:28:56.651696Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[191], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mSGD(\u001B[43mmodel\u001B[49m\u001B[38;5;241m.\u001B[39mparameters(), lr \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.1\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Połączmy to wszystko razem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:56.702848Z",
     "start_time": "2024-03-03T23:28:56.692287Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'XORDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[192], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m train_dataset \u001B[38;5;241m=\u001B[39m \u001B[43mXORDataset\u001B[49m(size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1000\u001B[39m)\n\u001B[1;32m      2\u001B[0m train_data_loader \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mDataLoader(train_dataset, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m128\u001B[39m, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'XORDataset' is not defined"
     ]
    }
   ],
   "source": [
    "train_dataset = XORDataset(size=1000)\n",
    "train_data_loader = data.DataLoader(train_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:56.783575Z",
     "start_time": "2024-03-03T23:28:56.775438Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SimpleClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[193], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mSimpleClassifier\u001B[49m(num_inputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m, num_hidden\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m, num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m      2\u001B[0m model\u001B[38;5;241m.\u001B[39mto(device)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'SimpleClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "model = SimpleClassifier(num_inputs=2, num_hidden=4, num_outputs=1)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:56.807990Z",
     "start_time": "2024-03-03T23:28:56.799880Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[194], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mSGD(\u001B[43mmodel\u001B[49m\u001B[38;5;241m.\u001B[39mparameters(), lr \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.1\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:56.898499Z",
     "start_time": "2024-03-03T23:28:56.888586Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[195], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m loss_module \u001B[38;5;241m=\u001B[39m \u001B[43mnn\u001B[49m\u001B[38;5;241m.\u001B[39mBCEWithLogitsLoss()\n",
      "\u001B[0;31mNameError\u001B[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "loss_module = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:56.951274Z",
     "start_time": "2024-03-03T23:28:56.940100Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[196], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241m.\u001B[39mtrain() \n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Training loop\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m100\u001B[39m):\n",
      "\u001B[0;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.train() \n",
    "\n",
    "# Training loop\n",
    "for epoch in range(100):\n",
    "    for data_inputs, data_labels in train_data_loader:\n",
    "\n",
    "        ## Step 1: Move input data to device (only strictly necessary if we use GPU)\n",
    "        data_inputs = data_inputs.to(device)\n",
    "        data_labels = data_labels.to(device)\n",
    "\n",
    "        ## Step 2: Run the model on the input data\n",
    "        preds = model(data_inputs)\n",
    "        preds = preds.squeeze(dim=1) # Output is [Batch size, 1], but we want [Batch size]\n",
    "\n",
    "        ## Step 3: Calculate the loss\n",
    "        loss = loss_module(preds, data_labels.float())\n",
    "\n",
    "        ## Step 4: Perform backpropagation\n",
    "        # Before calculating the gradients, we need to ensure that they are all zero. \n",
    "        # The gradients would not be overwritten, but actually added to the existing ones.\n",
    "        optimizer.zero_grad() \n",
    "        # Perform backpropagation\n",
    "        loss.backward()\n",
    "\n",
    "        ## Step 5: Update the parameters\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch: {epoch}, loss: {loss.item():.3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ewaluacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:57.007120Z",
     "start_time": "2024-03-03T23:28:56.998913Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'XORDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[197], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m test_dataset \u001B[38;5;241m=\u001B[39m \u001B[43mXORDataset\u001B[49m(size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m500\u001B[39m)\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# drop_last -> Don't drop the last batch although it is smaller than 128\u001B[39;00m\n\u001B[1;32m      3\u001B[0m test_data_loader \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mDataLoader(test_dataset, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m128\u001B[39m, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, drop_last\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'XORDataset' is not defined"
     ]
    }
   ],
   "source": [
    "test_dataset = XORDataset(size=500)\n",
    "# drop_last -> Don't drop the last batch although it is smaller than 128\n",
    "test_data_loader = data.DataLoader(test_dataset, batch_size=128, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:57.050653Z",
     "start_time": "2024-03-03T23:28:57.040616Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[198], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241m.\u001B[39meval() \u001B[38;5;66;03m# Set model to eval mode\u001B[39;00m\n\u001B[1;32m      2\u001B[0m true_preds, num_preds \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.\u001B[39m, \u001B[38;5;241m0.\u001B[39m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad(): \u001B[38;5;66;03m# Deactivate gradients for the following code\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.eval() # Set model to eval mode\n",
    "true_preds, num_preds = 0., 0.\n",
    "\n",
    "with torch.no_grad(): # Deactivate gradients for the following code\n",
    "    for data_inputs, data_labels in test_data_loader:\n",
    "\n",
    "        # Determine prediction of model on dev set\n",
    "        data_inputs, data_labels = data_inputs.to(device), data_labels.to(device)\n",
    "        preds = model(data_inputs)\n",
    "        preds = preds.squeeze(dim=1)\n",
    "        preds = torch.sigmoid(preds) # Sigmoid to map predictions between 0 and 1\n",
    "        pred_labels = (preds >= 0.5).long() # Binarize predictions to 0 and 1\n",
    "\n",
    "        # Keep records of predictions for the accuracy metric (true_preds=TP+TN, num_preds=TP+TN+FP+FN)\n",
    "        true_preds += (pred_labels == data_labels).sum()\n",
    "        num_preds += data_labels.shape[0]\n",
    "\n",
    "acc = true_preds / num_preds\n",
    "print(f\"Accuracy of the model: {100.0*acc:4.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:57.123828Z",
     "start_time": "2024-03-03T23:28:57.121875Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import to_rgba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:57.171722Z",
     "start_time": "2024-03-03T23:28:57.155391Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[200], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m get_ipython()\u001B[38;5;241m.\u001B[39mrun_line_magic(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmatplotlib\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minline\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m----> 3\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[43mtest_dataset\u001B[49m\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[1;32m      4\u001B[0m     label \u001B[38;5;241m=\u001B[39m test_dataset\u001B[38;5;241m.\u001B[39mlabel\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[1;32m      5\u001B[0m     data_0 \u001B[38;5;241m=\u001B[39m data[label \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m]\n",
      "\u001B[0;31mNameError\u001B[0m: name 'test_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "with torch.no_grad():\n",
    "    data = test_dataset.data.cpu().numpy()\n",
    "    label = test_dataset.label.cpu().numpy()\n",
    "    data_0 = data[label == 0]\n",
    "    data_1 = data[label == 1]\n",
    "\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.scatter(data_0[:,0], data_0[:,1], edgecolor=\"#333\", label=\"Class 0\")\n",
    "    plt.scatter(data_1[:,0], data_1[:,1], edgecolor=\"#333\", label=\"Class 1\")\n",
    "    plt.title(\"Dataset samples\")\n",
    "    plt.ylabel(r\"$x_2$\")\n",
    "    plt.xlabel(r\"$x_1$\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Let's make use of a lot of operations we have learned above\n",
    "    model.to(device)\n",
    "    c0 = torch.Tensor(to_rgba(\"C0\")).to(device)\n",
    "    c1 = torch.Tensor(to_rgba(\"C1\")).to(device)\n",
    "    x1 = torch.arange(-0.5, 1.5, step=0.01, device=device)\n",
    "    x2 = torch.arange(-0.5, 1.5, step=0.01, device=device)\n",
    "    xx1, xx2 = torch.meshgrid(x1, x2) # Meshgrid function as in numpy\n",
    "    model_inputs = torch.stack([xx1, xx2], dim=-1)\n",
    "    preds = model(model_inputs)\n",
    "    preds = torch.sigmoid(preds)\n",
    "    output_image = preds * c0[None,None] + (1 - preds) * c1[None,None] # Specifying \"None\" in a dimension creates a new one\n",
    "    output_image = output_image.cpu().numpy() # Convert to numpy array. This only works for tensors on CPU, hence first push to CPU\n",
    "    plt.imshow(output_image, origin='upper', extent=(-0.5, 1.5, -0.5, 1.5))\n",
    "    plt.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zapisywanie i wczytywanie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:57.245052Z",
     "start_time": "2024-03-03T23:28:57.236226Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[201], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m      2\u001B[0m state_dict \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mstate_dict()\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(state_dict)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "state_dict = model.state_dict()\n",
    "print(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:57.271287Z",
     "start_time": "2024-03-03T23:28:57.263167Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[202], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m      2\u001B[0m torch\u001B[38;5;241m.\u001B[39msave(state_dict, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msimple_model.tar\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "torch.save(state_dict, \"simple_model.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:57.355815Z",
     "start_time": "2024-03-03T23:28:57.345879Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[203], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m torch\u001B[38;5;241m.\u001B[39msave(\u001B[43mmodel\u001B[49m,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "torch.save(model,\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:57.499584Z",
     "start_time": "2024-03-03T23:28:57.435798Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'simple_model.tar'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[204], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Load state dict from the disk (make sure it is the same name as above)\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m state_dict \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msimple_model.tar\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Create a new model and load the state\u001B[39;00m\n\u001B[1;32m      5\u001B[0m new_model \u001B[38;5;241m=\u001B[39m SimpleClassifier(num_inputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m, num_hidden\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m, num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[0;32m~/ArtifficialNeuralNetworks/Introduction_lab_1_2/venv/lib/python3.11/site-packages/torch/serialization.py:998\u001B[0m, in \u001B[0;36mload\u001B[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001B[0m\n\u001B[1;32m    995\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m pickle_load_args\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[1;32m    996\u001B[0m     pickle_load_args[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m--> 998\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43m_open_file_like\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m opened_file:\n\u001B[1;32m    999\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_zipfile(opened_file):\n\u001B[1;32m   1000\u001B[0m         \u001B[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001B[39;00m\n\u001B[1;32m   1001\u001B[0m         \u001B[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001B[39;00m\n\u001B[1;32m   1002\u001B[0m         \u001B[38;5;66;03m# reset back to the original position.\u001B[39;00m\n\u001B[1;32m   1003\u001B[0m         orig_position \u001B[38;5;241m=\u001B[39m opened_file\u001B[38;5;241m.\u001B[39mtell()\n",
      "File \u001B[0;32m~/ArtifficialNeuralNetworks/Introduction_lab_1_2/venv/lib/python3.11/site-packages/torch/serialization.py:445\u001B[0m, in \u001B[0;36m_open_file_like\u001B[0;34m(name_or_buffer, mode)\u001B[0m\n\u001B[1;32m    443\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_open_file_like\u001B[39m(name_or_buffer, mode):\n\u001B[1;32m    444\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_path(name_or_buffer):\n\u001B[0;32m--> 445\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_open_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    446\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    447\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m mode:\n",
      "File \u001B[0;32m~/ArtifficialNeuralNetworks/Introduction_lab_1_2/venv/lib/python3.11/site-packages/torch/serialization.py:426\u001B[0m, in \u001B[0;36m_open_file.__init__\u001B[0;34m(self, name, mode)\u001B[0m\n\u001B[1;32m    425\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, name, mode):\n\u001B[0;32m--> 426\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'simple_model.tar'"
     ]
    }
   ],
   "source": [
    "# Load state dict from the disk (make sure it is the same name as above)\n",
    "state_dict = torch.load(\"simple_model.tar\")\n",
    "\n",
    "# Create a new model and load the state\n",
    "new_model = SimpleClassifier(num_inputs=2, num_hidden=4, num_outputs=1).to(device)\n",
    "new_model.load_state_dict(state_dict)\n",
    "# Verify that the parameters are the same\n",
    "print(\"Original model\\n\", model.state_dict())\n",
    "print(\"\\nLoaded model\\n\", new_model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zrób to sam. Polecane przećwiczyć przed kolejnymi ćwiczeniami.\n",
    "\n",
    "Spróbujmy przewidzieć ocenę wina na podstawie jego parametrów"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import certifi\n",
    "import ssl\n",
    "context = ssl.create_default_context(cafile=certifi.where())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:57.527632Z",
     "start_time": "2024-03-03T23:28:57.510219Z"
    }
   },
   "execution_count": 205
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:57.573577Z",
     "start_time": "2024-03-03T23:28:57.546615Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('winequality-white.csv', delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:57.648296Z",
     "start_time": "2024-03-03T23:28:57.625740Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n0               7.0              0.27         0.36            20.7      0.045   \n1               6.3              0.30         0.34             1.6      0.049   \n2               8.1              0.28         0.40             6.9      0.050   \n3               7.2              0.23         0.32             8.5      0.058   \n4               7.2              0.23         0.32             8.5      0.058   \n...             ...               ...          ...             ...        ...   \n4893            6.2              0.21         0.29             1.6      0.039   \n4894            6.6              0.32         0.36             8.0      0.047   \n4895            6.5              0.24         0.19             1.2      0.041   \n4896            5.5              0.29         0.30             1.1      0.022   \n4897            6.0              0.21         0.38             0.8      0.020   \n\n      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n0                    45.0                 170.0  1.00100  3.00       0.45   \n1                    14.0                 132.0  0.99400  3.30       0.49   \n2                    30.0                  97.0  0.99510  3.26       0.44   \n3                    47.0                 186.0  0.99560  3.19       0.40   \n4                    47.0                 186.0  0.99560  3.19       0.40   \n...                   ...                   ...      ...   ...        ...   \n4893                 24.0                  92.0  0.99114  3.27       0.50   \n4894                 57.0                 168.0  0.99490  3.15       0.46   \n4895                 30.0                 111.0  0.99254  2.99       0.46   \n4896                 20.0                 110.0  0.98869  3.34       0.38   \n4897                 22.0                  98.0  0.98941  3.26       0.32   \n\n      alcohol  quality  \n0         8.8        6  \n1         9.5        6  \n2        10.1        6  \n3         9.9        6  \n4         9.9        6  \n...       ...      ...  \n4893     11.2        6  \n4894      9.6        5  \n4895      9.4        6  \n4896     12.8        7  \n4897     11.8        6  \n\n[4898 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fixed acidity</th>\n      <th>volatile acidity</th>\n      <th>citric acid</th>\n      <th>residual sugar</th>\n      <th>chlorides</th>\n      <th>free sulfur dioxide</th>\n      <th>total sulfur dioxide</th>\n      <th>density</th>\n      <th>pH</th>\n      <th>sulphates</th>\n      <th>alcohol</th>\n      <th>quality</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7.0</td>\n      <td>0.27</td>\n      <td>0.36</td>\n      <td>20.7</td>\n      <td>0.045</td>\n      <td>45.0</td>\n      <td>170.0</td>\n      <td>1.00100</td>\n      <td>3.00</td>\n      <td>0.45</td>\n      <td>8.8</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6.3</td>\n      <td>0.30</td>\n      <td>0.34</td>\n      <td>1.6</td>\n      <td>0.049</td>\n      <td>14.0</td>\n      <td>132.0</td>\n      <td>0.99400</td>\n      <td>3.30</td>\n      <td>0.49</td>\n      <td>9.5</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8.1</td>\n      <td>0.28</td>\n      <td>0.40</td>\n      <td>6.9</td>\n      <td>0.050</td>\n      <td>30.0</td>\n      <td>97.0</td>\n      <td>0.99510</td>\n      <td>3.26</td>\n      <td>0.44</td>\n      <td>10.1</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7.2</td>\n      <td>0.23</td>\n      <td>0.32</td>\n      <td>8.5</td>\n      <td>0.058</td>\n      <td>47.0</td>\n      <td>186.0</td>\n      <td>0.99560</td>\n      <td>3.19</td>\n      <td>0.40</td>\n      <td>9.9</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7.2</td>\n      <td>0.23</td>\n      <td>0.32</td>\n      <td>8.5</td>\n      <td>0.058</td>\n      <td>47.0</td>\n      <td>186.0</td>\n      <td>0.99560</td>\n      <td>3.19</td>\n      <td>0.40</td>\n      <td>9.9</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4893</th>\n      <td>6.2</td>\n      <td>0.21</td>\n      <td>0.29</td>\n      <td>1.6</td>\n      <td>0.039</td>\n      <td>24.0</td>\n      <td>92.0</td>\n      <td>0.99114</td>\n      <td>3.27</td>\n      <td>0.50</td>\n      <td>11.2</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4894</th>\n      <td>6.6</td>\n      <td>0.32</td>\n      <td>0.36</td>\n      <td>8.0</td>\n      <td>0.047</td>\n      <td>57.0</td>\n      <td>168.0</td>\n      <td>0.99490</td>\n      <td>3.15</td>\n      <td>0.46</td>\n      <td>9.6</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4895</th>\n      <td>6.5</td>\n      <td>0.24</td>\n      <td>0.19</td>\n      <td>1.2</td>\n      <td>0.041</td>\n      <td>30.0</td>\n      <td>111.0</td>\n      <td>0.99254</td>\n      <td>2.99</td>\n      <td>0.46</td>\n      <td>9.4</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4896</th>\n      <td>5.5</td>\n      <td>0.29</td>\n      <td>0.30</td>\n      <td>1.1</td>\n      <td>0.022</td>\n      <td>20.0</td>\n      <td>110.0</td>\n      <td>0.98869</td>\n      <td>3.34</td>\n      <td>0.38</td>\n      <td>12.8</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>4897</th>\n      <td>6.0</td>\n      <td>0.21</td>\n      <td>0.38</td>\n      <td>0.8</td>\n      <td>0.020</td>\n      <td>22.0</td>\n      <td>98.0</td>\n      <td>0.98941</td>\n      <td>3.26</td>\n      <td>0.32</td>\n      <td>11.8</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n<p>4898 rows × 12 columns</p>\n</div>"
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ... Jakieś wstępne przetwarzanie danych?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:57.664850Z",
     "start_time": "2024-03-03T23:28:57.652545Z"
    }
   },
   "outputs": [],
   "source": [
    "train=df.sample(frac=0.8,random_state=200) #random state is a seed value\n",
    "test=df.drop(train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:57.934909Z",
     "start_time": "2024-03-03T23:28:57.926970Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:58.020676Z",
     "start_time": "2024-03-03T23:28:58.008641Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([7.6000e+00, 3.0000e-01, 3.7000e-01, 1.6000e+00, 8.7000e-02, 2.7000e+01,\n         1.7700e+02, 9.9438e-01, 3.0900e+00, 5.0000e-01, 9.8000e+00],\n        dtype=torch.float64),\n tensor(5., dtype=torch.float64))"
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = data.TensorDataset(torch.from_numpy(train.values[:,:-1]),torch.from_numpy(train.values[:,-1]))\n",
    "next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T23:28:58.076814Z",
     "start_time": "2024-03-03T23:28:58.075263Z"
    }
   },
   "execution_count": 210
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
