{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%reset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T21:59:02.190144Z",
     "start_time": "2024-04-11T21:59:00.453830Z"
    }
   },
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T21:59:03.180593Z",
     "start_time": "2024-04-11T21:59:03.177147Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T21:59:04.974001Z",
     "start_time": "2024-04-11T21:59:04.971082Z"
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T22:02:13.078681Z",
     "start_time": "2024-04-11T22:02:13.020814Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Found no valid file for the classes acoustic, battery, bean, beetle, bicycle, birch, bird, bomb, bread, bridge, camera, carbon, cat, corn, crab, crocodilian, echinoderm, elephant, fish, flower, frog, fungus, gauge, hammer, icecream, kangaroo, memorial, motor, nest, palm, pizza, pot, printer, saw, snake, spice, spider, spoon, squash, swine, tea, tomato, towel, truck, turtle, worm. Supported extensions are: .jpg, .jpeg, .png, .ppm, .bmp, .pgm, .tif, .tiff, .webp",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[32], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m DATA_PATH \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../train/\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 2\u001B[0m dataset \u001B[38;5;241m=\u001B[39m \u001B[43mdatasets\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mImageFolder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mroot\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mDATA_PATH\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtransform\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m idx_to_class \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m([k \u001B[38;5;28;01mfor\u001B[39;00m k, _ \u001B[38;5;129;01min\u001B[39;00m dataset\u001B[38;5;241m.\u001B[39mclass_to_idx\u001B[38;5;241m.\u001B[39mitems()])\n\u001B[1;32m      5\u001B[0m torch\u001B[38;5;241m.\u001B[39mmanual_seed(\u001B[38;5;241m42\u001B[39m)\n",
      "File \u001B[0;32m~/.virtualenvs/ArtifficialNeuralNetworks/lib/python3.10/site-packages/torchvision/datasets/folder.py:309\u001B[0m, in \u001B[0;36mImageFolder.__init__\u001B[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001B[0m\n\u001B[1;32m    301\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\n\u001B[1;32m    302\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    303\u001B[0m     root: \u001B[38;5;28mstr\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    307\u001B[0m     is_valid_file: Optional[Callable[[\u001B[38;5;28mstr\u001B[39m], \u001B[38;5;28mbool\u001B[39m]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    308\u001B[0m ):\n\u001B[0;32m--> 309\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    310\u001B[0m \u001B[43m        \u001B[49m\u001B[43mroot\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    311\u001B[0m \u001B[43m        \u001B[49m\u001B[43mloader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    312\u001B[0m \u001B[43m        \u001B[49m\u001B[43mIMG_EXTENSIONS\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mis_valid_file\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    313\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtransform\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    314\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtarget_transform\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtarget_transform\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    315\u001B[0m \u001B[43m        \u001B[49m\u001B[43mis_valid_file\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_valid_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    316\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimgs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msamples\n",
      "File \u001B[0;32m~/.virtualenvs/ArtifficialNeuralNetworks/lib/python3.10/site-packages/torchvision/datasets/folder.py:145\u001B[0m, in \u001B[0;36mDatasetFolder.__init__\u001B[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001B[0m\n\u001B[1;32m    143\u001B[0m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(root, transform\u001B[38;5;241m=\u001B[39mtransform, target_transform\u001B[38;5;241m=\u001B[39mtarget_transform)\n\u001B[1;32m    144\u001B[0m classes, class_to_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfind_classes(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mroot)\n\u001B[0;32m--> 145\u001B[0m samples \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmake_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mroot\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclass_to_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextensions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_valid_file\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    147\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloader \u001B[38;5;241m=\u001B[39m loader\n\u001B[1;32m    148\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mextensions \u001B[38;5;241m=\u001B[39m extensions\n",
      "File \u001B[0;32m~/.virtualenvs/ArtifficialNeuralNetworks/lib/python3.10/site-packages/torchvision/datasets/folder.py:189\u001B[0m, in \u001B[0;36mDatasetFolder.make_dataset\u001B[0;34m(directory, class_to_idx, extensions, is_valid_file)\u001B[0m\n\u001B[1;32m    184\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m class_to_idx \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    185\u001B[0m     \u001B[38;5;66;03m# prevent potential bug since make_dataset() would use the class_to_idx logic of the\u001B[39;00m\n\u001B[1;32m    186\u001B[0m     \u001B[38;5;66;03m# find_classes() function, instead of using that of the find_classes() method, which\u001B[39;00m\n\u001B[1;32m    187\u001B[0m     \u001B[38;5;66;03m# is potentially overridden and thus could have a different logic.\u001B[39;00m\n\u001B[1;32m    188\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe class_to_idx parameter cannot be None.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 189\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmake_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdirectory\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclass_to_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextensions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextensions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_valid_file\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_valid_file\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/ArtifficialNeuralNetworks/lib/python3.10/site-packages/torchvision/datasets/folder.py:102\u001B[0m, in \u001B[0;36mmake_dataset\u001B[0;34m(directory, class_to_idx, extensions, is_valid_file)\u001B[0m\n\u001B[1;32m    100\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m extensions \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    101\u001B[0m         msg \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSupported extensions are: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mextensions\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mif\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28misinstance\u001B[39m(extensions,\u001B[38;5;250m \u001B[39m\u001B[38;5;28mstr\u001B[39m)\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01melse\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(extensions)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m--> 102\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m(msg)\n\u001B[1;32m    104\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m instances\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: Found no valid file for the classes acoustic, battery, bean, beetle, bicycle, birch, bird, bomb, bread, bridge, camera, carbon, cat, corn, crab, crocodilian, echinoderm, elephant, fish, flower, frog, fungus, gauge, hammer, icecream, kangaroo, memorial, motor, nest, palm, pizza, pot, printer, saw, snake, spice, spider, spoon, squash, swine, tea, tomato, towel, truck, turtle, worm. Supported extensions are: .jpg, .jpeg, .png, .ppm, .bmp, .pgm, .tif, .tiff, .webp"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"../train/\"\n",
    "dataset = datasets.ImageFolder(root=DATA_PATH, transform=transform)\n",
    "idx_to_class = tuple([k for k, _ in dataset.class_to_idx.items()])\n",
    "\n",
    "torch.manual_seed(42)\n",
    "train_dataset, val_dataset = random_split(dataset,[0.8, 0.2])\n",
    "torch.manual_seed(torch.initial_seed()) # reset seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T21:58:47.541127Z",
     "start_time": "2024-04-11T21:58:47.431779Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[21], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m32\u001B[39m\n\u001B[0;32m----> 3\u001B[0m train_loader \u001B[38;5;241m=\u001B[39m DataLoader(\u001B[43mtrain_dataset\u001B[49m, batch_size\u001B[38;5;241m=\u001B[39mbatch_size, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, num_workers\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m6\u001B[39m)\n\u001B[1;32m      4\u001B[0m val_loader \u001B[38;5;241m=\u001B[39m DataLoader(val_dataset, batch_size\u001B[38;5;241m=\u001B[39mbatch_size, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, num_workers\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m6\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=6)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T21:58:47.542532Z",
     "start_time": "2024-04-11T21:58:47.542417Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peek data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# get some random training images\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "print(\" \".join(f\"{idx_to_class[labels[j]]}\" for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, output_size):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,64, kernel_size = 11,  stride = 4, padding = 2)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size =3, stride = 2)\n",
    "        self.conv2 = nn.Conv2d(64, 192, kernel_size = 5, padding = 2)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size = 3, stride = 2)\n",
    "        self.conv3 = nn.Conv2d(192, 384, kernel_size = 3, padding = 1)\n",
    "        self.conv3  = nn.Conv2d(384, 256, kernel_size = 3, padding = 1)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size = 3, stride = 2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6,6))\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc1 = nn.Linear(256*6*6, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 4096)\n",
    "        self.fc3 = nn.Linear(4096, output_size)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool3(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CNN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[22], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mCNN\u001B[49m(\u001B[38;5;28mlen\u001B[39m(dataset\u001B[38;5;241m.\u001B[39mclasses))\n",
      "\u001B[0;31mNameError\u001B[0m: name 'CNN' is not defined"
     ]
    }
   ],
   "source": [
    "model = CNN(len(dataset.classes))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T21:58:47.643953Z",
     "start_time": "2024-04-11T21:58:47.628370Z"
    }
   },
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[23], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m criterion \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mCrossEntropyLoss()\n\u001B[0;32m----> 2\u001B[0m optimizer   \u001B[38;5;241m=\u001B[39m optim\u001B[38;5;241m.\u001B[39mAdam(\u001B[43mmodel\u001B[49m\u001B[38;5;241m.\u001B[39mparameters(), lr \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0001\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer   = optim.Adam(model.parameters(), lr = 0.0001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T21:58:47.730303Z",
     "start_time": "2024-04-11T21:58:47.713872Z"
    }
   },
   "execution_count": 23
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
