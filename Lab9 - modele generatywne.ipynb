{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg', 'pdf') # For export\n",
    "from matplotlib.colors import to_rgb\n",
    "import matplotlib\n",
    "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
    "import seaborn as sns\n",
    "sns.reset_orig()\n",
    "sns.set()\n",
    "\n",
    "\n",
    "## PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "# Torchvision\n",
    "import torchvision\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:2\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przygotowanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations applied on each image => only make them a tensor\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Loading the training dataset. We need to split it into a training and validation part\n",
    "train_dataset = FashionMNIST(root=\"data/\", train=True, transform=transform, download=True)\n",
    "\n",
    "# Loading the test set\n",
    "test_set = FashionMNIST(root=\"data/\", train=False, transform=transform, download=True)\n",
    "\n",
    "# We define a set of data loaders that we can use for various purposes later.\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=256, shuffle=True, drop_last=True, pin_memory=True, num_workers=4)\n",
    "test_loader = data.DataLoader(test_set, batch_size=256, shuffle=False, drop_last=False, num_workers=4)\n",
    "\n",
    "def get_train_images(num):\n",
    "    return torch.stack([test_set[i][0] for i in range(10,10+num)], dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Budowanie autoenkodera wariacyjnego \n",
    "VAE tak samo jak zwykły autoenkoder zbudowany jest z enkodera który mapuje wejściowe obrazki **x** w niskowymiarową przestrzeń ukrytą **z**, oraz dekodera który odwraca tę operację i rekonstruuje wejście **x** z przestrzeni ukrytej **z**\n",
    "\n",
    "Zacznijmy od stworzenia enkodera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.fc_1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc_2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc_mean  = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_var   = nn.Linear (hidden_dim, latent_dim)\n",
    "        \n",
    "        self.LeakyReLU = nn.LeakyReLU(0.2)\n",
    "        \n",
    "        self.training = True\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        x       = self.LeakyReLU(self.fc_1(x))\n",
    "        x       = self.LeakyReLU(self.fc_2(x))\n",
    "        mean     = self.fc_mean(x)\n",
    "        log_var  = self.fc_var(x)                      # encoder produces mean and log of variance \n",
    "                                                       #             (i.e., parateters of simple tractable normal distribution \"q\"\n",
    "        \n",
    "        return mean, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim, output_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc_1 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.fc_2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc_3 = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        self.LeakyReLU = nn.LeakyReLU(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h     = self.LeakyReLU(self.fc_1(x))\n",
    "        h     = self.LeakyReLU(self.fc_2(h))\n",
    "        \n",
    "        x_hat = torch.sigmoid(self.fc_3(h))\n",
    "        x_hat = x_hat.view([-1, 1, 28, 28])\n",
    "        return x_hat\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uzupełnij metodę losowania nowych przykładów w przestrzeni ukrytej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, x_dim, hidden_dim, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = Encoder(input_dim=x_dim, hidden_dim=hidden_dim, latent_dim=latent_dim)\n",
    "        self.decoder = Decoder(latent_dim=latent_dim, hidden_dim = hidden_dim, output_dim = x_dim)\n",
    "\n",
    "        \n",
    "    def reparameterization(self, mean, var):\n",
    "        # Change to proper sampling\n",
    "        z = mean\n",
    "        return z\n",
    "        \n",
    "                \n",
    "    def forward(self, x):\n",
    "        mean, log_var = self.encoder(x)\n",
    "        z = self.reparameterization(mean, torch.exp(0.5 * log_var)) # takes exponential function (log var -> var)\n",
    "        x_hat = self.decoder(z)\n",
    "        return x_hat, mean, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(latent_dim=32, hidden_dim=256, x_dim=784).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Możemy zacząć trening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss(reduction=\"sum\")\n",
    "optimizer = optim.Adam(vae.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "for n in range(num_epochs):\n",
    "    losses_epoch = []\n",
    "    for x, _ in iter(train_loader):\n",
    "        x = x.to(device)\n",
    "        out, means, log_var = vae(x)\n",
    "        loss = criterion(out, x) \n",
    "        losses_epoch.append(loss.item())\n",
    "        loss.backward()               \n",
    "        optimizer.step()             \n",
    "        optimizer.zero_grad()  \n",
    "    L1_list = []\n",
    "#     if n % 10 == 0:\n",
    "    for x, _ in iter(test_loader):\n",
    "        x  = x.to(device)\n",
    "        out, _, _ = vae(x)\n",
    "        L1_list.append(torch.mean(torch.abs(out-x)).item())\n",
    "    print(f\"Epoch {n} loss {np.mean(np.array(losses_epoch))}, test L1 = {np.mean(L1_list)}\")\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_reconstructions(model, input_imgs, device):\n",
    "    # Reconstruct images\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        reconst_imgs, means, log_var = model(input_imgs.to(device))\n",
    "    reconst_imgs = reconst_imgs.cpu()\n",
    "    \n",
    "    # Plotting\n",
    "    imgs = torch.stack([input_imgs, reconst_imgs], dim=1).flatten(0,1)\n",
    "    grid = torchvision.utils.make_grid(imgs, nrow=4, normalize=False, range=(-1,1))\n",
    "    grid = grid.permute(1, 2, 0)\n",
    "    if len(input_imgs) == 4:\n",
    "        plt.figure(figsize=(10,10))\n",
    "    else:\n",
    "        plt.figure(figsize=(15,10))\n",
    "    plt.title(f\"Reconstructions\")\n",
    "    plt.imshow(grid)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "input_imgs = get_train_images(8)\n",
    "visualize_reconstructions(vae, input_imgs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(model, n_imgs, device):\n",
    "    # Generate images\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        generated_imgs = model.decoder(torch.randn([n_imgs, model.latent_dim]).to(device))\n",
    "    generated_imgs = generated_imgs.cpu()\n",
    "    \n",
    "    grid = torchvision.utils.make_grid(generated_imgs, nrow=4, normalize=False, range=(-1,1))\n",
    "    grid = grid.permute(1, 2, 0)\n",
    "    if len(input_imgs) == 4:\n",
    "        plt.figure(figsize=(10,10))\n",
    "    else:\n",
    "        plt.figure(figsize=(15,10))\n",
    "    plt.title(f\"Generations\")\n",
    "    plt.imshow(grid)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_images(vae, 16 , device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Co poszło nie tak?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(latent_dim=16, hidden_dim=256, x_dim=784).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss_function(x, x_hat, mean, log_var):\n",
    "    reproduction_loss = nn.functional.mse_loss(x_hat, x, reduction='sum')\n",
    "    KLD      = -0.5 * torch.sum(1+ log_var - mean.pow(2) - log_var.exp())\n",
    "\n",
    "    return reproduction_loss + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(vae.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "for n in range(num_epochs):\n",
    "    losses_epoch = []\n",
    "    for x, _ in iter(train_loader):\n",
    "        x = x.to(device)\n",
    "        out, means, log_var = vae(x)\n",
    "        loss = vae_loss_function(x, out, means, log_var) \n",
    "        losses_epoch.append(loss.item())\n",
    "        loss.backward()               # backward pass (compute parameter updates)\n",
    "        optimizer.step()              # make the updates for each parameter\n",
    "        optimizer.zero_grad()  \n",
    "    L1_list = []\n",
    "#     if n % 10 == 0:\n",
    "    for x, _ in iter(test_loader):\n",
    "        x  = x.to(device)\n",
    "        out, _, _ = vae(x)\n",
    "        L1_list.append(torch.mean(torch.abs(out-x)).item())\n",
    "    print(f\"Epoch {n} loss {np.mean(np.array(losses_epoch))}, test L1 = {np.mean(L1_list)}\")\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_images(vae, 16 , device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Przestrzeń ukryta VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_imgs(model, data_loader):\n",
    "    # Encode all images in the data_laoder using model, and return both images and encodings\n",
    "    img_list, embed_list = [], []\n",
    "    model.eval()\n",
    "    labels = []\n",
    "    for imgs, label in data_loader:\n",
    "        with torch.no_grad():\n",
    "            mean, var_log = model.encoder(imgs.to(device))\n",
    "        img_list.append(imgs)\n",
    "        embed_list.append(mean)\n",
    "        labels.append(label)\n",
    "    return (torch.cat(img_list, dim=0), torch.cat(embed_list, dim=0), torch.cat(labels, dim=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib.offsetbox import AnnotationBbox, OffsetImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_object = umap.UMAP(metric=\"cosine\", n_neighbors=100)\n",
    "train_img_embeds = embed_imgs(vae, train_loader)\n",
    "test_img_embeds = embed_imgs(vae, test_loader)\n",
    "train_embedded = umap_object.fit_transform(train_img_embeds[1][:5000].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_latent(train_embedded, train_img_embeds, n_data=5000):\n",
    "    data = pd.DataFrame(train_embedded[:n_data])\n",
    "    data[\"label\"] = train_img_embeds[2][:n_data].cpu().numpy()\n",
    "    examples = []\n",
    "    examples_locations = []\n",
    "    for i in np.random.randint(0,n_data,40):\n",
    "        examples.append(train_img_embeds[0][i].squeeze(0).cpu().numpy())\n",
    "        examples_locations.append(data.iloc[i])\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    # ax.scatter(noises_to_plot_tsne[0],noises_to_plot_tsne[1],c=noises_to_plot_tsne[\"batch\"],s=3,alpha=0.8)\n",
    "    sns.scatterplot(\n",
    "        x=0, y=1,\n",
    "        hue=\"label\",\n",
    "        palette=sns.color_palette(\"hls\", 10),\n",
    "        data=data,\n",
    "        legend=\"full\",\n",
    "        alpha=0.1\n",
    "    )\n",
    "    for location, example in zip(examples_locations, examples):\n",
    "        x, y = location[0], location[1]\n",
    "        label = int(location[\"label\"])\n",
    "        ab = AnnotationBbox(OffsetImage(example,cmap=plt.cm.gray_r, zoom=1), (x, y), frameon=True,\n",
    "                            bboxprops=dict(facecolor=sns.color_palette(\"hls\", 10)[label], boxstyle=\"round\"))\n",
    "        ax.add_artist(ab)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_latent(train_embedded, train_img_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(latent_dim=2, hidden_dim=256, x_dim=784).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(vae.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "for n in range(num_epochs):\n",
    "    losses_epoch = []\n",
    "    for x, _ in iter(train_loader):\n",
    "        x = x.to(device)\n",
    "        out, means, log_var = vae(x)\n",
    "        loss = vae_loss_function(x, out, means, log_var) \n",
    "        losses_epoch.append(loss.item())\n",
    "        loss.backward()               # backward pass (compute parameter updates)\n",
    "        optimizer.step()              # make the updates for each parameter\n",
    "        optimizer.zero_grad()  \n",
    "    L1_list = []\n",
    "#     if n % 10 == 0:\n",
    "    for x, _ in iter(test_loader):\n",
    "        x  = x.to(device)\n",
    "        out, _, _ = vae(x)\n",
    "        L1_list.append(torch.mean(torch.abs(out-x)).item())\n",
    "    print(f\"Epoch {n} loss {np.mean(np.array(losses_epoch))}, test L1 = {np.mean(L1_list)}\")\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_images(vae, 16 , device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_embeds = embed_imgs(vae, train_loader)\n",
    "test_img_embeds = embed_imgs(vae, test_loader)\n",
    "train_embedded = train_img_embeds[1][:5000].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_latent(train_embedded, train_img_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(train_embedded[:5000])\n",
    "data[\"label\"] = train_img_embeds[2][:5000].cpu().numpy()\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "# ax.scatter(noises_to_plot_tsne[0],noises_to_plot_tsne[1],c=noises_to_plot_tsne[\"batch\"],s=3,alpha=0.8)\n",
    "sns.scatterplot(\n",
    "    x=0, y=1,\n",
    "    hue=\"label\",\n",
    "    palette=sns.color_palette(\"hls\", 10),\n",
    "    data=data,\n",
    "    legend=\"full\",\n",
    "    alpha=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.fc_1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc_2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc_out  = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "        self.LeakyReLU = nn.LeakyReLU(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.LeakyReLU(self.fc_1(x))\n",
    "        x = self.LeakyReLU(self.fc_2(x))\n",
    "        x = self.fc_out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim, output_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc_1 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.fc_2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc_3 = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        self.LeakyReLU = nn.LeakyReLU(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h     = self.LeakyReLU(self.fc_1(x))\n",
    "        h     = self.LeakyReLU(self.fc_2(h))\n",
    "        \n",
    "        x_hat = torch.sigmoid(self.fc_3(h))\n",
    "        x_hat = x_hat.view([-1, 1, 28, 28])\n",
    "        return x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "latent_dim = 32\n",
    "generator = Generator(latent_dim=latent_dim, hidden_dim=256, output_dim=784).to(device)\n",
    "discriminator = Discriminator( hidden_dim=256, input_dim=784).to(device)\n",
    "\n",
    "# Optimizers\n",
    "generator_optimizer = torch.optim.Adam(generator.parameters(), lr=0.0001)\n",
    "generator_scheduler = optim.lr_scheduler.ExponentialLR(optimizer=generator_optimizer, gamma=0.99)\n",
    "discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.0001)\n",
    "discriminator_scheduler = optim.lr_scheduler.ExponentialLR(optimizer=discriminator_optimizer, gamma=0.99)\n",
    "\n",
    "# loss\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_noise = torch.randn(16, latent_dim,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "G_losses = []\n",
    "D_losses = []\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    # For each batch in the dataloader\n",
    "    discriminator_fake_acc = []\n",
    "    discriminator_real_acc = []\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        ## Train with all-real batch\n",
    "        discriminator_optimizer.zero_grad()\n",
    "        # Format batch\n",
    "        real_images = data[0].to(device)\n",
    "        b_size = real_images.size(0)\n",
    "        label = torch.ones((b_size,), dtype=torch.float, device=device) # Setting labels for real images\n",
    "        # Forward pass real batch through D\n",
    "        output = discriminator(real_images).view(-1)\n",
    "        # Calculate loss on all-real batch\n",
    "        error_discriminator_real = criterion(output, label)\n",
    "        # Calculate gradients for D in backward pass\n",
    "        discriminator_real_acc.append(output.mean().item())\n",
    "\n",
    "        ## Train with all-fake batch\n",
    "        # Generate batch of latent vectors\n",
    "        noise = torch.randn(b_size, latent_dim,device=device)\n",
    "        # Generate fake image batch with Generator\n",
    "        fake_images = generator(noise)\n",
    "        label_fake = torch.zeros((b_size,), dtype=torch.float, device=device)\n",
    "        # Classify all fake batch with Discriminator\n",
    "        output = discriminator(fake_images.detach()).view(-1)\n",
    "        # Calculate D's loss on the all-fake batch\n",
    "        error_discriminator_fake = criterion(output, label_fake)\n",
    "        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
    "        discriminator_fake_acc.append(output.mean().item())\n",
    "        # Compute error of D as sum over the fake and the real batches\n",
    "        error_discriminator = error_discriminator_real + error_discriminator_fake\n",
    "        error_discriminator.backward()\n",
    "        # Update D\n",
    "        discriminator_optimizer.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        generator_optimizer.zero_grad()\n",
    "        label = torch.ones((b_size,), dtype=torch.float, device=device)  # fake labels are real for generator cost\n",
    "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
    "        output = discriminator(fake_images).view(-1)\n",
    "        # Calculate G's loss based on this output\n",
    "        error_generator = criterion(output, label)\n",
    "        # Calculate gradients for G\n",
    "        error_generator.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        # Update G\n",
    "        generator_optimizer.step()\n",
    "\n",
    "        # Output training stats\n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(error_generator.item())\n",
    "        D_losses.append(error_discriminator.item())\n",
    "\n",
    "    print(f\"Epoch: {epoch}, discrimiantor fake error: {np.mean(discriminator_fake_acc):.3}, discriminator real acc: {np.mean(discriminator_real_acc):.3}\")\n",
    "    generator_scheduler.step()\n",
    "    discriminator_scheduler.step()\n",
    "    if epoch % 10 == 0:\n",
    "        with torch.no_grad():\n",
    "            fake = generator(fixed_noise).detach().cpu()\n",
    "        grid = torchvision.utils.make_grid(fake)\n",
    "        grid = grid.permute(1, 2, 0)\n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.title(f\"Generations\")\n",
    "        plt.imshow(grid)\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stwórzmy model warunkowany klasą\n",
    "Może się przydać F.one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot(torch.tensor([4,3,4]),10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ewaluacja modeli generatywnych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(Evaluator, self).__init__()\n",
    "\n",
    "        self.fc_1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc_2 = nn.Linear(hidden_dim, 50)\n",
    "        self.fc_out  = nn.Linear(50, 10)\n",
    "        \n",
    "        self.LeakyReLU = nn.LeakyReLU(0.2)\n",
    "        \n",
    "    def get_features(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.LeakyReLU(self.fc_1(x))\n",
    "        x = self.LeakyReLU(self.fc_2(x))\n",
    "        return x\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.get_features(x)\n",
    "        x = self.fc_out(x)\n",
    "        return x\n",
    "\n",
    "evaluator = Evaluator(28*28, 256).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "optimizer = torch.optim.Adam(evaluator.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=0.97)\n",
    "\n",
    "# loss\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 7\n",
    "for epoch in range(num_epochs):\n",
    "    for data, targets in iter(train_loader):\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        results = evaluator(data)\n",
    "        loss = criterion(results, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_correct = 0\n",
    "total_guesses = 0\n",
    "\n",
    "evaluator.eval()\n",
    "with torch.no_grad():\n",
    "    for data, targets in iter(test_loader):\n",
    "        # Sends data and targets to device\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # Acquires the network's best guesses at each class\n",
    "        results = evaluator(data)\n",
    "        best_guesses = torch.argmax(results, 1)\n",
    "\n",
    "        # Updates number of correct and total guesses\n",
    "        num_correct += torch.eq(targets, best_guesses).sum().item()\n",
    "        total_guesses += len(targets)\n",
    "\n",
    "print(\"Correctly guessed \", num_correct/total_guesses*100, \"% of the dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = vae_32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    fixed_noise = torch.randn(1000, latent_dim,device=device)\n",
    "    fixed_labels = torch.randint(10,(1000,),device=device)\n",
    "    fixed_labels = F.one_hot(fixed_labels, 10).float()\n",
    "#     generations_cond_gan = cond_generator(fixed_noise, fixed_labels)\n",
    "    generations_gan = generator(fixed_noise)\n",
    "    generations_vae = vae.decoder(fixed_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_data = [x[0] for x in list(test_set)[:1000]]\n",
    "orig_data = torch.cat(orig_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    dist_orig_data = evaluator.get_features(orig_data.to(device)).cpu()\n",
    "    dist_vae = evaluator.get_features(generations_vae.to(device)).cpu()\n",
    "    dist_gan = evaluator.get_features(generations_gan.to(device)).cpu()\n",
    "#     dist_cond_gan = evaluator.get_features(generations_cond_gan.to(device)).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for idx in range(5):\n",
    "    bins = 10\n",
    "    w = 0.3\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.hist([dist_orig_data[:,idx].numpy(),dist_vae[:,idx].numpy(),dist_gan[:,idx]], bins, alpha=0.5, label=['orig','vae','gan','cond_gan'],width=w)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show();\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Frechet Inception distance based on implementation from https://github.com/mseitzer/pytorch-fid\n",
    "\n",
    "import numpy as np\n",
    "from scipy import linalg\n",
    "\n",
    "\n",
    "def calculate_frechet_distance(distribution_1, distribution_2, eps=1e-6):\n",
    "    mu1 = np.mean(distribution_1, axis=0)\n",
    "    sigma1 = np.cov(distribution_1, rowvar=False)\n",
    "\n",
    "    mu2 = np.mean(distribution_2, axis=0)\n",
    "    sigma2 = np.cov(distribution_2, rowvar=False)\n",
    "\n",
    "    \"\"\"Numpy implementation of the Frechet Distance.\n",
    "    The Frechet distance between two multivariate Gaussians X_1 ~ N(mu_1, C_1)\n",
    "    and X_2 ~ N(mu_2, C_2) is\n",
    "            d^2 = ||mu_1 - mu_2||^2 + Tr(C_1 + C_2 - 2*sqrt(C_1*C_2)).\n",
    "    Stable version by Dougal J. Sutherland.\n",
    "    Params:\n",
    "    -- mu1   : Numpy array containing the activations of a layer of the\n",
    "               inception net (like returned by the function 'get_predictions')\n",
    "               for generated samples.\n",
    "    -- mu2   : The sample mean over activations, precalculated on an\n",
    "               representative data set.\n",
    "    -- sigma1: The covariance matrix over activations for generated samples.\n",
    "    -- sigma2: The covariance matrix over activations, precalculated on an\n",
    "               representative data set.\n",
    "    Returns:\n",
    "    --   : The Frechet Distance.\n",
    "    \"\"\"\n",
    "\n",
    "    mu1 = np.atleast_1d(mu1)\n",
    "    mu2 = np.atleast_1d(mu2)\n",
    "\n",
    "    sigma1 = np.atleast_2d(sigma1)\n",
    "    sigma2 = np.atleast_2d(sigma2)\n",
    "\n",
    "    assert mu1.shape == mu2.shape, \\\n",
    "        'Training and test mean vectors have different lengths'\n",
    "    assert sigma1.shape == sigma2.shape, \\\n",
    "        'Training and test covariances have different dimensions'\n",
    "\n",
    "    diff = mu1 - mu2\n",
    "\n",
    "    # Product might be almost singular\n",
    "    covmean, _ = linalg.sqrtm(sigma1.dot(sigma2), disp=False)\n",
    "    if not np.isfinite(covmean).all():\n",
    "        msg = ('fid calculation produces singular product; '\n",
    "               'adding %s to diagonal of cov estimates') % eps\n",
    "        print(msg)\n",
    "        offset = np.eye(sigma1.shape[0]) * eps\n",
    "        covmean = linalg.sqrtm((sigma1 + offset).dot(sigma2 + offset))\n",
    "\n",
    "    # Numerical error might give slight imaginary component\n",
    "    if np.iscomplexobj(covmean):\n",
    "        if not np.allclose(np.diagonal(covmean).imag, 0, atol=1e-3):\n",
    "            m = np.max(np.abs(covmean.imag))\n",
    "            raise ValueError('Imaginary component {}'.format(m))\n",
    "        covmean = covmean.real\n",
    "\n",
    "    tr_covmean = np.trace(covmean)\n",
    "\n",
    "    return (diff.dot(diff) + np.trace(sigma1) +\n",
    "            np.trace(sigma2) - 2 * tr_covmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_data_2 = [x[0] for x in list(test_set)[-1000:]]\n",
    "orig_data_2 = torch.cat(orig_data_2)\n",
    "with torch.no_grad():\n",
    "    dist_orig_data_2 = evaluator.get_features(orig_data_2.to(device)).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, obj in zip(['orig','vae','gan','cond_gan'],[dist_orig_data_2.numpy(),dist_vae.numpy(),dist_gan.numpy()]):\n",
    "    print(f\"FD {name}: {calculate_frechet_distance(dist_orig_data.numpy(),obj)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
